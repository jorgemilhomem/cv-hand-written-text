{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "df = pd.read_pickle('data/words_df_all.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import StringLookup\n",
    "batch_size = 64\n",
    "padding_token = 99\n",
    "image_width = 128\n",
    "image_height = 32\n",
    "# consider only SegmentationResluts == 'ok'\n",
    "df = df[df['SegmentationResult'] == 'ok']\n",
    "for i, img in enumerate(df['ImageData']):\n",
    "    if type(img) != np.ndarray:\n",
    "        # delete the current row from df\n",
    "        df.drop(i, inplace=True)\n",
    "df = df[df['ImageData'].notnull()]\n",
    "vocabulary = sorted(set(''.join(df['Transcription'].values)))\n",
    "# shuffle\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "# consider only words that do not contain spaces or pontuation\n",
    "punctuation = [' ', '.', ',', '!', '?', \"'\", '\"', '(', ')', '[', ']', '{', '}', '/', '\\\\', '|', '*', '+', '=', '_', '#', '@', '%', '&', '^', '~', '`', '<', '>', ':', ';']\n",
    "df = df[df['Transcription'].apply(lambda x: all(char not in x for char in punctuation))]\n",
    "# Split data into training and validation sets\n",
    "X = np.stack(df['ImageData'].values)  # Convert the list of images to a numpy array\n",
    "X = tf.convert_to_tensor(X)\n",
    "y = np.array(df['Transcription'].values)\n",
    "\n",
    "\n",
    "char_to_num = StringLookup(vocabulary=vocabulary, mask_token=None)\n",
    "num_to_char = StringLookup(\n",
    "    vocabulary=char_to_num.get_vocabulary(), mask_token=None, invert=True\n",
    ")\n",
    "\n",
    "def vectorize_label(label):\n",
    "    label = char_to_num(tf.strings.unicode_split(label, input_encoding=\"UTF-8\"))\n",
    "    length = tf.shape(label)[0]\n",
    "    pad_amount = max_len - length\n",
    "    label = tf.pad(label, paddings=[[0, pad_amount]], constant_values=padding_token)\n",
    "    return label\n",
    "\n",
    "# calculate the maximum length of the labels\n",
    "max_len = max([len(label) for label in y])\n",
    "for i in range(len(y)):\n",
    "    y[i] = vectorize_label(y[i])\n",
    "y = tf.convert_to_tensor(list(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "def process_images_labels(image, label):\n",
    "    return {\"image\": image, \"labels\": label}\n",
    "\n",
    "\n",
    "def prepare_dataset(X, y):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "    dataset = dataset.map(process_images_labels, num_parallel_calls=AUTOTUNE)\n",
    "    return dataset.batch(batch_size).cache().prefetch(AUTOTUNE)\n",
    "\n",
    "dataset = prepare_dataset(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the dataset. The buffer size should be equal to or larger than the size of the dataset for perfect shuffling.\n",
    "dataset = dataset.shuffle(buffer_size=len(X))\n",
    "\n",
    "# Assuming you know the size of the dataset, if not you can compute it\n",
    "total_size = len(X)  # Replace with actual size if not using the full dataset\n",
    "train_size = int(total_size * 0.8)\n",
    "val_size = int(total_size * 0.1)\n",
    "test_size = total_size - train_size - val_size  # Remaining data for testing\n",
    "\n",
    "# Define the training dataset\n",
    "train_dataset = dataset.take(train_size)\n",
    "\n",
    "# Skip over the training data and take the next chunk for validation\n",
    "val_dataset = dataset.skip(train_size).take(val_size)\n",
    "\n",
    "# Skip over the training and validation data for the test set\n",
    "test_dataset = dataset.skip(train_size + val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_images = []\n",
    "validation_labels = []\n",
    "\n",
    "for batch in val_dataset:\n",
    "    validation_images.append(batch[\"images\"])\n",
    "    validation_labels.append(batch[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dense, Dropout, Reshape, LSTM, Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTCLayer(keras.layers.Layer):\n",
    "    def __init__(self, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.loss_fn = keras.backend.ctc_batch_cost\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
    "        input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
    "        label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
    "\n",
    "        input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "        label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n",
    "        self.add_loss(loss)\n",
    "\n",
    "        # At test time, just return the computed predictions.\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image (InputLayer)          [(None, 32, 128, 1)]         0         []                            \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 30, 126, 96)          960       ['image[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (None, 15, 63, 96)           0         ['conv2d[0][0]']              \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 13, 61, 96)           83040     ['max_pooling2d[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, 6, 30, 96)            0         ['conv2d_1[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 4, 28, 96)            83040     ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPoolin  (None, 4, 14, 96)            0         ['conv2d_2[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 5376)                 0         ['max_pooling2d_2[0][0]']     \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 4225)                 2271782   ['flatten[0][0]']             \n",
      "                                                          5                                       \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 4225)                 0         ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " reshape (Reshape)           (None, 4225, 1)              0         ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " lstm (LSTM)                 (None, 4225, 128)            66560     ['reshape[0][0]']             \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)               (None, 128)                  131584    ['lstm[0][0]']                \n",
      "                                                                                                  \n",
      " dense2 (Dense)              (None, 4225)                 545025    ['lstm_1[0][0]']              \n",
      "                                                                                                  \n",
      " labels (InputLayer)         [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)         (None, 65, 65)               0         ['dense2[0][0]']              \n",
      "                                                                                                  \n",
      " ctc_loss (CTCLayer)         (None, 65, 65)               0         ['labels[0][0]',              \n",
      "                                                                     'reshape_1[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23628034 (90.13 MB)\n",
      "Trainable params: 23628034 (90.13 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_cnn_rnn_model(input_shape=(32, 128, 1), num_classes=len(vocabulary)+2, sequence_length=max_len):\n",
    "    # Define the input layers\n",
    "    inputs = keras.Input(shape=input_shape, name=\"image\")\n",
    "    labels = keras.layers.Input(name=\"labels\", shape=(None,))  # input for CTC\n",
    "    \n",
    "    # First CNN layer with 96 units\n",
    "    x = Conv2D(96, (3, 3), activation='relu')(inputs)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    # Second CNN layer with 96 units\n",
    "    x = Conv2D(96, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    # Third CNN layer with 96 units\n",
    "    x = Conv2D(96, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(1, 2))(x)\n",
    "\n",
    "    # Flatten the output of the CNN layers\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "\n",
    "    # Dense layer with sequence_length * num_classes units\n",
    "    x = Dense(sequence_length * num_classes, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "\n",
    "    # Reshape the output for the RNN layers\n",
    "    # (batch_size, time_steps, units)\n",
    "    x = Reshape((sequence_length*num_classes,1))(x)\n",
    "\n",
    "    # First RNN (LSTM) layer, 128 units, returns sequences for the next LSTM layer\n",
    "    x = LSTM(128, return_sequences=True)(x)\n",
    "\n",
    "    # Second RNN (LSTM) layer, 128 units, this time we do not return sequences\n",
    "    x = LSTM(128)(x)\n",
    "\n",
    "    \"\"\"# Final Dense layer\n",
    "    x = Dense(sequence_length * num_classes, activation='softmax')(x)\n",
    "\n",
    "    # Reshape the output to match the target shape\n",
    "    outputs = Reshape((sequence_length, num_classes))(x)\n",
    "\n",
    "    # Create the model\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))\"\"\"\n",
    "\n",
    "    # Compile the model with Adam optimizer and a learning rate of 0.001\n",
    "    # model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    #               loss='categorical_crossentropy',\n",
    "    #               metrics=['accuracy'])\n",
    "\n",
    "    # Final Dense layer\n",
    "    x = Dense(num_classes*sequence_length, activation='softmax', name=\"dense2\")(x)  # logits for CTC\n",
    "    x = Reshape((sequence_length, num_classes))(x)\n",
    "\n",
    "    # Define the CTC layer and get the loss\n",
    "    ctc_output = CTCLayer(name='ctc_loss')(labels, x)\n",
    "\n",
    "    # Create the model\n",
    "    model = Model(inputs=[inputs, labels], outputs=ctc_output)\n",
    "\n",
    "    # Compile the model with a dummy optimizer and loss since CTC loss is computed in the CTC layer\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))\n",
    "  \n",
    "    return model\n",
    "\n",
    "create_cnn_rnn_model(input_shape=(32, 128, 1), num_classes=len(vocabulary)+2, sequence_length=len(vocabulary)+2).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_edit_distance(labels, predictions):\n",
    "    # Get a single batch and convert its labels to sparse tensors.\n",
    "    saprse_labels = tf.cast(tf.sparse.from_dense(labels), dtype=tf.int64)\n",
    "\n",
    "    # Make predictions and convert them to sparse tensors.\n",
    "    input_len = np.ones(predictions.shape[0]) * predictions.shape[1]\n",
    "    predictions_decoded = keras.backend.ctc_decode(\n",
    "        predictions, input_length=input_len, greedy=True\n",
    "    )[0][0][:, :max_len]\n",
    "    sparse_predictions = tf.cast(\n",
    "        tf.sparse.from_dense(predictions_decoded), dtype=tf.int64\n",
    "    )\n",
    "\n",
    "    # Compute individual edit distances and average them out.\n",
    "    edit_distances = tf.edit_distance(\n",
    "        sparse_predictions, saprse_labels, normalize=False\n",
    "    )\n",
    "    return tf.reduce_mean(edit_distances)\n",
    "\n",
    "\n",
    "class EditDistanceCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, pred_model):\n",
    "        super().__init__()\n",
    "        self.prediction_model = pred_model\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        edit_distances = []\n",
    "\n",
    "        for i in range(len(validation_images)):\n",
    "            labels = validation_labels[i]\n",
    "            predictions = self.prediction_model.predict(validation_images[i])\n",
    "            edit_distances.append(calculate_edit_distance(labels, predictions).numpy())\n",
    "\n",
    "        print(\n",
    "            f\"Mean edit distance for epoch {epoch + 1}: {np.mean(edit_distances):.4f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " 499/1310 [==========>...................] - ETA: 29:57 - loss: 16.9144"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-30 04:47:29.736358: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 682/1310 [==============>...............] - ETA: 23:14 - loss: inf"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-30 04:54:18.008367: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1310/1310 [==============================] - ETA: 0s - loss: inf"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected input data to be non-empty.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[20], line 19\u001b[0m\n",
      "\u001b[1;32m     14\u001b[0m model_checkpoint \u001b[38;5;241m=\u001b[39m ModelCheckpoint(best_model_path, \n",
      "\u001b[1;32m     15\u001b[0m                                    monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, \n",
      "\u001b[1;32m     16\u001b[0m                                    save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \n",
      "\u001b[1;32m     17\u001b[0m                                    verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Train the model.\u001b[39;00m\n",
      "\u001b[0;32m---> 19\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43medit_distance_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_checkpoint\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m     24\u001b[0m \u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n",
      "\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n",
      "\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/keras/src/engine/data_adapter.py:1319\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute, pss_evaluation_shards)\u001b[0m\n",
      "\u001b[1;32m   1314\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_dataset_and_inferred_steps(\n",
      "\u001b[1;32m   1315\u001b[0m     strategy, x, steps_per_epoch, class_weight, distribute\n",
      "\u001b[1;32m   1316\u001b[0m )\n",
      "\u001b[1;32m   1318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;32m-> 1319\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected input data to be non-empty.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\n",
      "\u001b[0;31mValueError\u001b[0m: Expected input data to be non-empty."
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "epochs = 50  # To get good results this should be at least 50.\n",
    "\n",
    "model = create_cnn_rnn_model()\n",
    "prediction_model = keras.models.Model(\n",
    "    model.get_layer(name=\"image\").input, model.get_layer(name=\"dense2\").output\n",
    ")\n",
    "edit_distance_callback = EditDistanceCallback(prediction_model)\n",
    "\n",
    "# add callback to save the best model during the training and stop training when there is no improvement in the validation loss for 3 consecutive epochs\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "best_model_path = 'crnn.h5'\n",
    "model_checkpoint = ModelCheckpoint(best_model_path, \n",
    "                                   monitor='val_loss', \n",
    "                                   save_best_only=True, \n",
    "                                   verbose=1)\n",
    "# Train the model.\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=epochs,\n",
    "    callbacks=[edit_distance_callback, early_stopping, model_checkpoint],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
