{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "from keras import layers, models\n",
    "import requests\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data locally\n",
    "df = pd.read_pickle('data/words_df_all.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Load the data in Google Colab\\n\\n# first, upload the words_df_all.pkl.gz to Google Drive\\n# then, run the following code in Google Colab\\n# Mount Google Drive\\nfrom google.colab import drive\\ndrive.mount('/content/drive')\\n\\n# Read the file from Google Drive\\nfile_path = '/content/drive/MyDrive/words_df_all.pkl.gz'\\ndf = pd.read_pickle(file_path)\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Load the data in Google Colab\n",
    "\n",
    "# first, upload the words_df_all.pkl.gz to Google Drive\n",
    "# then, run the following code in Google Colab\n",
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Read the file from Google Drive\n",
    "file_path = '/content/drive/MyDrive/words_df_all.pkl.gz'\n",
    "df = pd.read_pickle(file_path)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WordID</th>\n",
       "      <th>SegmentationResult</th>\n",
       "      <th>GrayLevel</th>\n",
       "      <th>BoundingBox</th>\n",
       "      <th>GrammaticalTag</th>\n",
       "      <th>Transcription</th>\n",
       "      <th>ImageData</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a01-000u-00-00</td>\n",
       "      <td>ok</td>\n",
       "      <td>154</td>\n",
       "      <td>(408, 768, 27, 51)</td>\n",
       "      <td>AT</td>\n",
       "      <td>A</td>\n",
       "      <td>[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a01-000u-00-01</td>\n",
       "      <td>ok</td>\n",
       "      <td>154</td>\n",
       "      <td>(507, 766, 213, 48)</td>\n",
       "      <td>NN</td>\n",
       "      <td>MOVE</td>\n",
       "      <td>[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a01-000u-00-02</td>\n",
       "      <td>ok</td>\n",
       "      <td>154</td>\n",
       "      <td>(796, 764, 70, 50)</td>\n",
       "      <td>TO</td>\n",
       "      <td>to</td>\n",
       "      <td>[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a01-000u-00-03</td>\n",
       "      <td>ok</td>\n",
       "      <td>154</td>\n",
       "      <td>(919, 757, 166, 78)</td>\n",
       "      <td>VB</td>\n",
       "      <td>stop</td>\n",
       "      <td>[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a01-000u-00-04</td>\n",
       "      <td>ok</td>\n",
       "      <td>154</td>\n",
       "      <td>(1185, 754, 126, 61)</td>\n",
       "      <td>NPT</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           WordID SegmentationResult  GrayLevel           BoundingBox  \\\n",
       "0  a01-000u-00-00                 ok        154    (408, 768, 27, 51)   \n",
       "1  a01-000u-00-01                 ok        154   (507, 766, 213, 48)   \n",
       "2  a01-000u-00-02                 ok        154    (796, 764, 70, 50)   \n",
       "3  a01-000u-00-03                 ok        154   (919, 757, 166, 78)   \n",
       "4  a01-000u-00-04                 ok        154  (1185, 754, 126, 61)   \n",
       "\n",
       "  GrammaticalTag Transcription  \\\n",
       "0             AT             A   \n",
       "1             NN          MOVE   \n",
       "2             TO            to   \n",
       "3             VB          stop   \n",
       "4            NPT           Mr.   \n",
       "\n",
       "                                           ImageData  \n",
       "0  [[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...  \n",
       "1  [[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...  \n",
       "2  [[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...  \n",
       "3  [[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...  \n",
       "4  [[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**On shapes...**\n",
    "\n",
    "**CNNs**\n",
    "\n",
    "- Always have to give a 4D array as input to the CNN. So input data has a shape of (batch_size, height, width, depth).\n",
    "\n",
    "- The output of the CNN is also a 4D array. Where batch size would be the same as input batch size but the other 3 dimensions of the image might change depending upon the values of filter, kernel size, and padding we use. (batch_size, height, width, depth)\n",
    "\n",
    "- Input data to the dense layer 2D must be an array of shape (batch_size, units). And the output of the convolution layer is a 4D array. Thus we have to change the dimension of output received from the convolution layer to a 2D array.\n",
    "\n",
    "\n",
    "<img src=\"convnet_input.png\" width=\"500\" height=\"400\">\n",
    "\n",
    "**RNNs**\n",
    "\n",
    "- Always have to give a 3D array as an input to the LSTM network. \n",
    "\n",
    "- The first dimension represents the batch size, the second dimension represents the time-steps and the third dimension represents the number of units in one input sequence. For example, the input shape looks like (batch_size, time_steps, units).\n",
    "\n",
    "- The output of the LSTM could be a 2D array or 3D array depending upon the return_sequences argument.\n",
    "\n",
    "- return_sequence argument: Tells whether to return the output at each time step instead of the final time step. \n",
    "\n",
    "- If return_sequence is False, the output is a 2D array. (batch_size, units)\n",
    "\n",
    "- If return_sequence is True, the output is a 3D array. (batch_size, time_steps, units)\n",
    "\n",
    "\n",
    "<img src=\"LSTM_input.png\" width=\"500\" height=\"400\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to plot the model Training and Validation Loss and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Plotting the Training and Validation Loss and Accuracy\n",
    "def plot_history(history):\n",
    "    # Get training and test loss histories\n",
    "    training_loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    # Create count of the number of epochs\n",
    "    epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "    # Visualize loss history\n",
    "    plt.plot(epoch_count, training_loss, 'r--')\n",
    "    plt.plot(epoch_count, val_loss, 'b-')\n",
    "    plt.legend(['Training Loss', 'Val Loss'])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()\n",
    "\n",
    "    # Get training and test accuracy histories\n",
    "    training_accuracy = history.history['accuracy']\n",
    "    val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "    # Visualize accuracy history\n",
    "    plt.plot(epoch_count, training_accuracy, 'r--')\n",
    "    plt.plot(epoch_count, val_accuracy, 'b-')\n",
    "    plt.legend(['Training Accuracy', 'Val Accuracy'])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A: **1 character** words model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomize the order of the rows in the df\n",
    "df_char = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# consider only one-character words in the df\n",
    "df_char = df_char[df_char['Transcription'].apply(len) == 1]\n",
    "\n",
    "# consider only SegmentationResluts == 'ok'\n",
    "df_char = df_char[df_char['SegmentationResult'] == 'ok']\n",
    "\n",
    "# Split data into training and validation sets\n",
    "X = np.stack(df_char['ImageData'].values)  # Convert the list of images to a numpy array\n",
    "y = df_char['Transcription'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14172\n"
     ]
    }
   ],
   "source": [
    "print(len(df_char))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Encode** the characters to integers. \n",
    "\n",
    "Example: '!' -> 1, '\"' -> 2, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'!': 0, '\"': 1, '#': 2, '&': 3, \"'\": 4, '(': 5, ')': 6, '*': 7, ',': 8, '-': 9, '.': 10, '1': 11, '2': 12, '3': 13, '4': 14, '5': 15, '6': 16, '7': 17, '8': 18, '9': 19, ':': 20, ';': 21, '?': 22, 'A': 23, 'B': 24, 'C': 25, 'D': 26, 'E': 27, 'F': 28, 'G': 29, 'H': 30, 'I': 31, 'J': 32, 'K': 33, 'L': 34, 'N': 35, 'O': 36, 'V': 37, 'a': 38, 'c': 39, 'x': 40}\n",
      "[38  8  8 ...  8  8 38]\n"
     ]
    }
   ],
   "source": [
    "# get the vocabulary list\n",
    "vocabulary = sorted(set(''.join(y)))\n",
    "\n",
    "# create a dictionary mapping each character to the vocabulary list index. do not use 0.\n",
    "char_to_num = {char: idx for idx, char in enumerate(vocabulary)}\n",
    "\n",
    "print(char_to_num)\n",
    "\n",
    "# subsitute the characters in y with the corresponding number. example: '!' -> 1, '\"' -> 2, etc.\" each label value is an integer\n",
    "y = [char_to_num[char] for char in y]\n",
    "\n",
    "# y to np.array\n",
    "y = np.array(y)\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "print(len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!', '\"', '#', '&', \"'\", '(', ')', '*', ',', '-', '.', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'N', 'O', 'V', 'a', 'c', 'x']\n"
     ]
    }
   ],
   "source": [
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12754, 32, 128, 1)\n",
      "(12754,)\n",
      "(709, 32, 128, 1)\n",
      "(709,)\n",
      "(709, 32, 128, 1)\n",
      "(709,)\n"
     ]
    }
   ],
   "source": [
    "TRAIN_SPLIT = 0.9\n",
    "VAL_SPLIT = 0.05\n",
    "TEST_SPLIT = 0.05\n",
    "\n",
    "# split the data into training, validation and test sets\n",
    "X_train = X[:int(X.shape[0]*TRAIN_SPLIT)]\n",
    "y_train = y[:int(y.shape[0]*TRAIN_SPLIT)]\n",
    "\n",
    "X_val = X[int(X.shape[0]*TRAIN_SPLIT):int(X.shape[0]*(TRAIN_SPLIT+VAL_SPLIT))]\n",
    "y_val = y[int(y.shape[0]*TRAIN_SPLIT):int(y.shape[0]*(TRAIN_SPLIT+VAL_SPLIT))]\n",
    "\n",
    "X_test = X[int(X.shape[0]*(TRAIN_SPLIT+VAL_SPLIT)):]\n",
    "y_test = y[int(y.shape[0]*(TRAIN_SPLIT+VAL_SPLIT)):]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A: Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:From c:\\Users\\t.ferreira\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\t.ferreira\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.3503 - accuracy: 0.6549\n",
      "Epoch 1: val_loss improved from inf to 0.93468, saving model to best_model_char.h5\n",
      "100/100 [==============================] - 9s 82ms/step - loss: 1.3503 - accuracy: 0.6549 - val_loss: 0.9347 - val_accuracy: 0.7377\n",
      "Epoch 2/50\n",
      "  1/100 [..............................] - ETA: 7s - loss: 0.7455 - accuracy: 0.7969"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\t.ferreira\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - ETA: 0s - loss: 0.7945 - accuracy: 0.7714\n",
      "Epoch 2: val_loss improved from 0.93468 to 0.71796, saving model to best_model_char.h5\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.7945 - accuracy: 0.7714 - val_loss: 0.7180 - val_accuracy: 0.7983\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6386 - accuracy: 0.8169\n",
      "Epoch 3: val_loss improved from 0.71796 to 0.58879, saving model to best_model_char.h5\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6386 - accuracy: 0.8169 - val_loss: 0.5888 - val_accuracy: 0.8223\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5466 - accuracy: 0.8447\n",
      "Epoch 4: val_loss improved from 0.58879 to 0.54710, saving model to best_model_char.h5\n",
      "100/100 [==============================] - 8s 84ms/step - loss: 0.5466 - accuracy: 0.8447 - val_loss: 0.5471 - val_accuracy: 0.8378\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4911 - accuracy: 0.8559\n",
      "Epoch 5: val_loss improved from 0.54710 to 0.48921, saving model to best_model_char.h5\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.4911 - accuracy: 0.8559 - val_loss: 0.4892 - val_accuracy: 0.8618\n",
      "Epoch 6/50\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4481 - accuracy: 0.8691\n",
      "Epoch 6: val_loss improved from 0.48921 to 0.47763, saving model to best_model_char.h5\n",
      "100/100 [==============================] - 9s 88ms/step - loss: 0.4481 - accuracy: 0.8691 - val_loss: 0.4776 - val_accuracy: 0.8561\n",
      "Epoch 7/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.4190 - accuracy: 0.8770\n",
      "Epoch 7: val_loss improved from 0.47763 to 0.47484, saving model to best_model_char.h5\n",
      "100/100 [==============================] - 8s 82ms/step - loss: 0.4193 - accuracy: 0.8768 - val_loss: 0.4748 - val_accuracy: 0.8561\n",
      "Epoch 8/50\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.3870 - accuracy: 0.8863\n",
      "Epoch 8: val_loss improved from 0.47484 to 0.45106, saving model to best_model_char.h5\n",
      "100/100 [==============================] - 9s 88ms/step - loss: 0.3870 - accuracy: 0.8863 - val_loss: 0.4511 - val_accuracy: 0.8604\n",
      "Epoch 9/50\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.3652 - accuracy: 0.8891\n",
      "Epoch 9: val_loss improved from 0.45106 to 0.42136, saving model to best_model_char.h5\n",
      "100/100 [==============================] - 9s 88ms/step - loss: 0.3652 - accuracy: 0.8891 - val_loss: 0.4214 - val_accuracy: 0.8773\n",
      "Epoch 10/50\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.3383 - accuracy: 0.8963\n",
      "Epoch 10: val_loss improved from 0.42136 to 0.41898, saving model to best_model_char.h5\n",
      "100/100 [==============================] - 9s 90ms/step - loss: 0.3383 - accuracy: 0.8963 - val_loss: 0.4190 - val_accuracy: 0.8787\n",
      "Epoch 11/50\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.3206 - accuracy: 0.9008\n",
      "Epoch 11: val_loss did not improve from 0.41898\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 0.3206 - accuracy: 0.9008 - val_loss: 0.4303 - val_accuracy: 0.8815\n",
      "Epoch 12/50\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.3050 - accuracy: 0.9023\n",
      "Epoch 12: val_loss did not improve from 0.41898\n",
      "100/100 [==============================] - 9s 89ms/step - loss: 0.3050 - accuracy: 0.9023 - val_loss: 0.4377 - val_accuracy: 0.8773\n",
      "Epoch 13/50\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2878 - accuracy: 0.9070\n",
      "Epoch 13: val_loss did not improve from 0.41898\n",
      "100/100 [==============================] - 9s 90ms/step - loss: 0.2878 - accuracy: 0.9070 - val_loss: 0.4229 - val_accuracy: 0.8787\n"
     ]
    }
   ],
   "source": [
    "def create_model(num_classes):\n",
    "    model = Sequential([\n",
    "        # Convolutional layer learns 32 filters using a 3x3 kernel\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(32, 128, 1)),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        #Dropout(0.25),\n",
    "\n",
    "        # Adding a second convolutional layer with 64 filters\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        #Dropout(0.25),\n",
    "\n",
    "        # Flatten the 3D output to 1D and add a dense layer\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        #Dropout(0.5),\n",
    "        Dropout(0.1),\n",
    "\n",
    "        # Output layer with softmax activation for classification\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    # adam with a learning rate of 0.001\n",
    "\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "num_classes = len(char_to_num)\n",
    "model = create_model(num_classes)\n",
    "\n",
    "# Save the best model during the training\n",
    "best_model_path = 'best_model_char.h5'  \n",
    "model_checkpoint = ModelCheckpoint(best_model_path, \n",
    "                                   monitor='val_loss', \n",
    "                                   save_best_only=True, \n",
    "                                   verbose=1)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=50,  # You can set this to a higher number.\n",
    "    batch_size=128,\n",
    "    callbacks=[early_stopping, model_checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAG1CAYAAAAFuNXgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABQJUlEQVR4nO3de3zO9f/H8ce1jdlmm/NsmjM5hJxDB6KcEqUvIYekftUS6YCEpKh8OxOlorOkkookiUghJhVzPtsQdsLG9vn98f5uM2a2ua59ruva8367fW77XJ/rc32u167kenp/3geHZVkWIiIiIl7Cx+4CRERERJxJ4UZERES8isKNiIiIeBWFGxEREfEqCjciIiLiVRRuRERExKso3IiIiIhXUbgRERERr6JwIyIiIl5F4UZERES8iq3hZsWKFXTr1o2IiAgcDgfz58/P82tXrVqFn58fV199tcvqExEREc9ja7hJTk6mUaNGTJs2LV+vO3HiBAMGDKB9+/YuqkxEREQ8lcNdFs50OBx89dVX9OjR45Ln3nnnndSqVQtfX1/mz59PdHR0nt8nPT2dgwcPEhwcjMPhKHjBIiIiUmgsyyIxMZGIiAh8fHJvm/ErpJqcZtasWezcuZOPPvqIZ5999pLnp6SkkJKSkvn4wIED1KtXz5UlioiIiIvs27ePK664ItdzPCrcbNu2jVGjRvHLL7/g55e30idPnsyECRMuOL5v3z5CQkKcXaKIiIi4QEJCApGRkQQHB1/yXI8JN2lpafTt25cJEyZQu3btPL9u9OjRjBgxIvNxxocTEhKicCMiIuJh8tKlxGPCTWJiIuvWrWPDhg089NBDgOk/Y1kWfn5+/PDDD9x4440XvM7f3x9/f//CLldERERs4jHhJiQkhE2bNmU79uabb/LTTz8xb948qlWrZlNlIiIi4k5sDTdJSUls37498/GuXbuIjo6mTJkyVK5cmdGjR3PgwAE++OADfHx8uOqqq7K9vkKFCpQoUeKC4yIiIlJ02Rpu1q1bR7t27TIfZ/SNGThwILNnz+bQoUPs3bvXrvJERMSJ0tPTSU1NtbsMcWPFixe/5DDvvHCbeW4KS0JCAqGhocTHx6tDsYhIIUlNTWXXrl2kp6fbXYq4MR8fH6pVq0bx4sUveC4/398e0+dGREQ8k2VZHDp0CF9fXyIjI53yL3PxPhmT7B46dIjKlStf1kS7CjciIuJSZ8+e5eTJk0RERBAYGGh3OeLGypcvz8GDBzl79izFihUr8HUUn0VExKXS0tIAcrzVIHKujD8jGX9mCkrhRkRECoXW85NLcdafEYUbERER8SoKNyIiIoWkatWqvPrqq3k+/+eff8bhcHDixAmX1eSNFG5ERETO43A4ct2efvrpAl137dq13HfffXk+v3Xr1hw6dIjQ0NACvV9eeVuI0mgpERGR8xw6dChz/7PPPmPcuHHExMRkHitZsmTmvmVZpKWl4ed36a/U8uXL56uO4sWLU7FixXy9RtRy41ynTkF0tN1ViIjIZapYsWLmFhoaisPhyHy8ZcsWgoODWbRoEU2bNsXf35+VK1eyY8cOunfvTlhYGCVLlqR58+b8+OOP2a57/m0ph8PBO++8w2233UZgYCC1atViwYIFmc+f36Iye/ZsSpUqxeLFi6lbty4lS5akU6dO2cLY2bNnefjhhylVqhRly5Zl5MiRDBw4kB49ehT48zh+/DgDBgygdOnSBAYG0rlzZ7Zt25b5/J49e+jWrRulS5cmKCiI+vXrs3DhwszX9uvXj/LlyxMQEECtWrWYNWtWgWvJC4UbZ4mNhZAQaN7chBwREcldcvLFt9On837u+X/nXuw8Jxs1ahTPP/88mzdvpmHDhiQlJdGlSxeWLl3Khg0b6NSpE926dbvkMkITJkygV69e/Pnnn3Tp0oV+/fpx7Nixi55/8uRJ/vvf//Lhhx+yYsUK9u7dy2OPPZb5/AsvvMDHH3/MrFmzWLVqFQkJCcyfP/+yftdBgwaxbt06FixYwOrVq7Esiy5dunDmzBkAoqKiSElJYcWKFWzatIkXXnghs3Vr7Nix/PPPPyxatIjNmzczffp0ypUrd1n1XJJVxMTHx1uAFR8f79wLp6dbVliYZYFlrVrl3GuLiHiwU6dOWf/884916tSp7E/AxbcuXbKfGxh48XNvuCH7ueXK5XxeAc2aNcsKDQ3NfLxs2TILsObPn3/J19avX9964403Mh9XqVLFeuWVVzIfA9ZTTz2V+TgpKckCrEWLFmV7r+PHj2fWAljbt2/PfM20adOssLCwzMdhYWHWlClTMh+fPXvWqly5stW9e/eL1nn++5xr69atFmCtOue77ejRo1ZAQIA1d+5cy7Isq0GDBtbTTz+d47W7detm3X333Rd973Nd9M+Klb/vb7XcOIvDAS1amP3ff7e3FhERcblmzZple5yUlMRjjz1G3bp1KVWqFCVLlmTz5s2XbLlp2LBh5n5QUBAhISEcPnz4oucHBgZSo0aNzMfh4eGZ58fHxxMXF0eLjO8jwNfXl6ZNm+brdzvX5s2b8fPzo2XLlpnHypYty5VXXsnmzZsBePjhh3n22Wdp06YN48eP588//8w894EHHmDOnDlcffXVPPHEE/z6668FriWvFG6cKeM//Jo19tYhIuIJkpIuvn3xRfZzDx+++LmLFmU/d/funM9zsqCgoGyPH3vsMb766ismTZrEL7/8QnR0NA0aNLjkSujnLzPgcDhyXWA0p/Mtm9fAHjJkCDt37qR///5s2rSJZs2a8cYbbwDQuXNn9uzZwyOPPMLBgwdp3759tttorqBw40wZ4UYtNyIilxYUdPGtRIm8nxsQkLdzXWzVqlUMGjSI2267jQYNGlCxYkV2797t8vc9V2hoKGFhYaxduzbzWFpaGuvXry/wNevWrcvZs2f5/Zzvtn///ZeYmBjq1auXeSwyMpL777+fL7/8kkcffZSZM2dmPle+fHkGDhzIRx99xKuvvsrbb79d4HryQkPBnal5c/Nz1y44cgTyOeRPREQ8V61atfjyyy/p1q0bDoeDsWPH5toC4ypDhw5l8uTJ1KxZkzp16vDGG29w/PjxPC1tsGnTJoKDgzMfOxwOGjVqRPfu3bn33nt56623CA4OZtSoUVSqVInu3bsDMHz4cDp37kzt2rU5fvw4y5Yto27dugCMGzeOpk2bUr9+fVJSUvj2228zn3MVhRtnCg2FOnVgyxZza6prV7srEhGRQvLyyy8zePBgWrduTbly5Rg5ciQJCQmFXsfIkSOJjY1lwIAB+Pr6ct9999GxY0d8fX0v+drrr78+22NfX1/Onj3LrFmzGDZsGLfccgupqalcf/31LFy4MPMWWVpaGlFRUezfv5+QkBA6derEK6+8Api5ekaPHs3u3bsJCAjguuuuY86cOc7/xc/hsOy+UVfIEhISCA0NJT4+npCQEOe/wfTpZlji7bdD1arOv76IiIc5ffo0u3btolq1apQ4/3aTuFx6ejp169alV69eTJw40e5ycpXbn5X8fH+r5cbZHnjA7gpERKQI27NnDz/88AM33HADKSkpTJ06lV27dtG3b1+7Sys06lAsIiLiRXx8fJg9ezbNmzenTZs2bNq0iR9//NHl/VzciVpuXGH7dvjtN2jfHsLD7a5GRESKkMjISFatWmV3GbZSy40rDBwI/fvDeWuKiIiIiOsp3LiCJvMTERGxjcKNK2gZBhEREdso3LhCRstNdPSFK9uKiIiISyncuELVqmZ24jNnTMARERGRQqNw4wpaIVxERMQ2Cjeuok7FIiJFXtu2bRk+fLjdZRQ5Cjeu0qsXzJ8PL71kdyUiIpJP3bp1o1OnTjk+98svv+BwOPjzzz8v+31mz55NqVKlLvs6kp0m8XOVK680m4iIeJx77rmHnj17sn//fq644opsz82aNYtmzZrRsGFDm6qTS1HLjYiIyHluueUWypcvz+zZs7MdT0pK4vPPP+eee+7h33//pU+fPlSqVInAwEAaNGjAp59+6tQ69u7dS/fu3SlZsiQhISH06tWLuLi4zOc3btxIu3btCA4OJiQkhKZNm7Ju3TrArDHVrVs3SpcuTVBQEPXr12fhwoVOrc9dqeXGlTZuhK++gtq1oQgtWCYikhvLgpMn7XnvwEAz5uNS/Pz8GDBgALNnz2bMmDE4/veizz//nLS0NPr06UNSUhJNmzZl5MiRhISE8N1339G/f39q1KhBi4xBJZchPT09M9gsX76cs2fPEhUVRe/evfn5558B6NevH40bN2b69On4+voSHR1NsWLFAIiKiiI1NZUVK1YQFBTEP//8Q8mSJS+7Lk+gcONKK1fChAnQqZPCjYjI/5w8CXZ9xyYlQVBQ3s4dPHgwU6ZMYfny5bRt2xYwt6R69uxJaGgooaGhPPbYY5nnDx06lMWLFzN37lynhJulS5eyadMmdu3aRWRkJAAffPAB9evXZ+3atTRv3py9e/fy+OOPU6dOHQBq1aqV+fq9e/fSs2dPGjRoAED16tUvuyZPodtSrnTuiCnLsrcWERHJlzp16tC6dWvee+89ALZv384vv/zCPffcA0BaWhoTJ06kQYMGlClThpIlS7J48WL27t3rlPffvHkzkZGRmcEGoF69epQqVYrNmzcDMGLECIYMGUKHDh14/vnn2bFjR+a5Dz/8MM8++yxt2rRh/PjxTukA7SkUblypYUPw94djx+CcP3AiIkVZYKBpQbFjCwzMX6333HMPX3zxBYmJicyaNYsaNWpwww03ADBlyhRee+01Ro4cybJly4iOjqZjx46kpqa64FPL2dNPP83ff/9N165d+emnn6hXrx5fffUVAEOGDGHnzp3079+fTZs20axZM954441Cq81OCjeuVLw4NG5s9jWZn4gIYPq8BAXZs+Wlv825evXqhY+PD5988gkffPABgwcPzux/s2rVKrp3785dd91Fo0aNqF69Olu3bnXa51S3bl327dvHvn37Mo/9888/nDhxgnr16mUeq127No888gg//PADt99+O7Nmzcp8LjIykvvvv58vv/ySRx99lJkzZzqtPnemPjeu1rIl/PabCTf9+tldjYiI5EPJkiXp3bs3o0ePJiEhgUGDBmU+V6tWLebNm8evv/5K6dKlefnll4mLi8sWPPIiLS2N6POW6vH396dDhw40aNCAfv368eqrr3L27FkefPBBbrjhBpo1a8apU6d4/PHHueOOO6hWrRr79+9n7dq19OzZE4Dhw4fTuXNnateuzfHjx1m2bBl169a93I/EIyjcuJqWYRAR8Wj33HMP7777Ll26dCEiIiLz+FNPPcXOnTvp2LEjgYGB3HffffTo0YP4+Ph8XT8pKYnGGa38/1OjRg22b9/O119/zdChQ7n++uvx8fGhU6dOmbeWfH19+ffffxkwYABxcXGUK1eO22+/nQkTJgAmNEVFRbF//35CQkLo1KkTr7zyymV+Gp7BYVlFq6drQkICoaGhxMfHExIS4vo33LEDataEsmUhNhb8lCdFpGg5ffo0u3btolq1apQoUcLucsSN5fZnJT/f3+pz42rVq8OmTRAXp2AjIiJSCPRt62oOB1x1ld1ViIiIFBlquRERERGvonBTGPbtg/79zUzFIiIi4lK6LVUYgoLgo4/M/rFjUKaMvfWIiNigiI1fkQJw1p8RtdwUhjJlIGO9j7Vr7a1FRKSQ+fr6AhTqzL3imTL+jGT8mSkotdwUlhYtYNs2M99Nx452VyMiUmj8/PwIDAzkyJEjFCtWDB8f/btaLpSens6RI0cIDAzE7zJHFyvcFJaWLeHjjzWZn4gUOQ6Hg/DwcHbt2sWePXvsLkfcmI+PD5UrV85c4qKgFG4KS8YK4b//blYIv8z/cCIinqR48eLUqlVLt6YkV8WLF3dKy57CTWFp1MgspPnvv7BzJ9SoYXdFIiKFysfHRzMUS6HQjc/C4u8PTZtCgwZw9Kjd1YiIiHgttdwUphUrtASDiIiIi6nlpjAp2IiIiLicwo0dzpyBtDS7qxAREfFKtoabFStW0K1bNyIiInA4HMyfPz/X87/88ktuuukmypcvT0hICK1atWLx4sWFU6yz3HorhITAhg12VyIiIuKVbA03ycnJNGrUiGnTpuXp/BUrVnDTTTexcOFC/vjjD9q1a0e3bt3Y4ElB4cwZOH1a892IiIi4iK2dQDp37kznzp3zfP6rr76a7fGkSZP4+uuv+eabb2jcuLGTq3ORli3h++9NuImKsrsaERERr+PRPVzT09NJTEykTC4LUaakpJCSkpL5OCEhoTBKu7gWLczPNWvsrUNERMRLeXSH4v/+978kJSXRq1evi54zefJkQkNDM7fIyMhCrDAHGeEmJgaOH7e3FhERES/kseHmk08+YcKECcydO5cKFSpc9LzRo0cTHx+fue3bt68Qq8xBuXJZsxNrhXARERGn88hwM2fOHIYMGcLcuXPp0KFDruf6+/sTEhKSbbNdRuuNOhWLiIg4ncf1ufn0008ZPHgwc+bMoWvXrnaXUzA33wynTkHdunZXIiIi4nVsDTdJSUls37498/GuXbuIjo6mTJkyVK5cmdGjR3PgwAE++OADwNyKGjhwIK+99hotW7YkNjYWgICAAEJDQ235HQpk0CCziYiIiNPZeltq3bp1NG7cOHMY94gRI2jcuDHjxo0D4NChQ+zduzfz/LfffpuzZ88SFRVFeHh45jZs2DBb6hcRERH347Asy7K7iMKUkJBAaGgo8fHx9va/sSzYuxd8fMDuEVwiIiJuLj/f3x7ZodgrjBoFVavCK6/YXYmIiIhXUbixy1VXmZ8aMSUiIuJUCjd2adnS/Fy/3qw3JSIiIk6hcGOXmjWhVCmziOaff9pdjYiIiNdQuLGLj4/WmRIREXEBhRs7ZdyaUr8bERERp1G4sZOWYRAREXE6j1t+watccw2MGGF+ioiIiFMo3NipXDl46SW7qxAREfEqui0lIiIiXkXhxm4nT8JPP8G8eXZXIiIi4hV0W8puGzdC+/YQFgY9e4LDYXdFIiIiHk0tN3a7+mrw84O4OLOQpoiIiFwWhRu7BQRAo0ZmX0PCRURELpvCjTvQZH4iIiJOo3DjDrQMg4iIiNMo3LiDjJabP/7QCuEiIiKXSeHGHdSuDaGhcOoU/PWX3dWIiIh4NA0Fdwc+PvD++3DFFXDVVXZXIyIi4tEUbtxF9+52VyAiIuIVdFtKREREvIrCjbuwLJg5E+69FxIS7K5GRETEYyncuAuHAyZNgnfegXXr7K5GRETEYyncuJOM+W40mZ+IiEiBKdy4E81ULCIictkUbtzJueHGsuytRURExEMp3LiTxo3B1xdiY2H/frurERER8UgKN+4kMBAaNjT7ujUlIiJSIAo37ibj1tTWrfbWISIi4qEcllW0OnckJCQQGhpKfHw8ISEhdpdzoYMHoUQJKFPG7kpERETcRn6+v7X8gruJiLC7AhEREY+m21IiIiLiVRRu3NG770K7dvDhh3ZXIiIi4nEUbtzRjh3w88+wfLndlYiIiHgchRt3pJmKRURECkzhxh1lrDH199+QmGhvLSIiIh5G4cYdhYdDZKRZgkErhIuIiOSLwo27yrg1tWaNvXWIiIh4GIUbd6V+NyIiIgWicOOuWrY0sxS74yzKIiIibkwzFLurNm3g6FFwOOyuRERExKMo3LgrHzWqiYiIFIS+QT3BqVN2VyAiIuIxFG7c2U8/QeXK0Lmz3ZWIiIh4DN2WcmcVKsC+fXDsGKSlga+v3RWJiIi4PbXcuLO6daFkSUhOhn/+sbsaERERj6Bw4858faFZM7OvyfxERETyROHG3WkyPxERkXxRuHF3CjciIiL5onDj7jLCzV9/mb43IiIikiuNlnJ3ERFwyy1QtSqcPAlBQXZXJCIi4tYUbjzBN9/YXYGIiIjH0G0pERER8Sq2hpsVK1bQrVs3IiIicDgczJ8//5Kv+fnnn2nSpAn+/v7UrFmT2bNnu7xOt3DyJPz2m91ViIiIuD1bw01ycjKNGjVi2rRpeTp/165ddO3alXbt2hEdHc3w4cMZMmQIixcvdnGlNjt1CsqUgVat4OBBu6sRERFxa7b2uencuTOd87Fu0owZM6hWrRovvfQSAHXr1mXlypW88sordOzY0VVl2i8gAGrXhk2bzGR+PXrYXZGIiIjb8qg+N6tXr6ZDhw7ZjnXs2JHVq1df9DUpKSkkJCRk2zyS5rsRERHJE48KN7GxsYSFhWU7FhYWRkJCAqdOncrxNZMnTyY0NDRzi4yMLIxSna9FC/NT4UZERCRXHhVuCmL06NHEx8dnbvv27bO7pILJaLlZt86sEC4iIiI58qh5bipWrEhcXFy2Y3FxcYSEhBAQEJDja/z9/fH39y+M8lyrfn0zgV9iImzZYh6LiIjIBTyq5aZVq1YsXbo027ElS5bQqlUrmyoqROeuEK5bUyIiIhdla7hJSkoiOjqa6OhowAz1jo6OZu/evYC5pTRgwIDM8++//3527tzJE088wZYtW3jzzTeZO3cujzzyiB3lF77/+z94+WW47jq7KxEREXFbtt6WWrduHe3atct8PGLECAAGDhzI7NmzOXToUGbQAahWrRrfffcdjzzyCK+99hpXXHEF77zzjncPAz9Xnz52VyAiIuL2HJZlWXYXUZgSEhIIDQ0lPj6ekJAQu8sRERGRPMjP97dH9bkRYPt2+OAD2LrV7kpERETcksKNp3n8cRg4EBYssLsSERERt6Rw42ky5rtZs8beOkRERNyUwo2n0TIMIiIiuVK48TTNmoHDAXv3Qmys3dWIiIi4HYUbTxMcDPXqmX3dmhIREbmAwo0n0q0pERGRi1K48UQKNyIiIhflUQtnyv907Qpff50VckRERCSTwo0nqlTJbCIiInIB3ZYSERERr6KWGydLTwefwoiM//wDn30GFSpAVFQhvKGIiIhnUMuNk+zYAf/5D4wcWUhv+Pff8Mwz8O67hfSGIiIinkHhxkm2bYN58+D112H37kJ4w4zOxH/+CadOFcIbioiIeAaFGyfp2BHat4fUVHjqqUJ4w8hIqFgR0tJg/fpCeEMRERHPoHDjJA4HvPii2f/440LIGw6H5rsRERHJgcKNEzVpAnfdZfYffxwsy8Vv2KKF+allGERERDIp3DjZs8+Cvz/89BN8/72L30wtNyIiIhdQuHGyKlXg4YfN/hNPmC4xLtO8ubk99e+/EB/vwjcSERHxHAo3LjB6NJQuDX/9Be+/78I3CgmBmBg4fhxCQ134RiIiIp5D4cYFSpfOGjE1diycPOnCN6tVC3x9XfgGIiIinkXhxkWioqBqVTh4EF591e5qREREig6FGxfx94dJk8z+88/D4cMueqN//zVDtJo2NWs/iIiIFHEKNy7Uu7fJHImJMHGii94kJAS++MJMrLN1q4veRERExHMo3LiQjw9MmWL2Z8wwSzQ4XbFiJkGB5rsRERFB4cbl2rWDrl3h7FkzisolNN+NiIhIJoWbQvDCC6YV54svYPVqF7yBwo2IiEgmhZtCUL8+DB5s9l2yLENGuNm4EU6fdvLFRUREPIvCTSGZMAECAmDVKpg/38kXr1wZKlQw9742bHDyxUVERDyLwk0hiYiARx81+6NGwZkzTry4wwFt2kDDhpCc7MQLi4iIeB6HZbl87Wq3kpCQQGhoKPHx8YSEhBTqeycmQo0acOQIvPkmPPCAEy+enm469oiIiHih/Hx/69uwEAUHw9NPm/2nnzZhx2kUbERERACFm0J3771Qu7aZsThjDhynSk01m4iISBGlcFPIihUzyzEAvPSSWXvKafr1MzMWL1nixIuKiIh4FoUbG/ToAa1bm9XCx4934oX9/CAlRfPdiIhIkaZwYwOHI+uW1Hvvwd9/O+nCGfPdaBkGEREpwhRubNK6NfTsaQY5jRrlpIueG26K1iA4ERGRTAo3Npo0ydxJ+vZb+PlnJ1ywYUMoUQKOH3fRKp0iIiLur0DhZt++fezfvz/z8Zo1axg+fDhvv/220worCmrXhv/7P7P/+OOmFeeyFCsGTZqYfd2aEhGRIqpA4aZv374sW7YMgNjYWG666SbWrFnDmDFjeOaZZ5xaoLcbN87Mf7NuHcyd64QLtmhhfqpTsYiIFFEFCjd//fUXLf73JTp37lyuuuoqfv31Vz7++GNmz57tzPq8XoUKMHKk2R892gx2uizt28Ntt2X1vxERESliChRuzpw5g7+/PwA//vgjt956KwB16tTh0KFDzquuiHjkEbP21O7dZlmGy3LLLfDll3DXXc4oTURExOMUKNzUr1+fGTNm8Msvv7BkyRI6deoEwMGDBylbtqxTCywKAgNh4kSzP3Gi6Q8sIiIiBVOgcPPCCy/w1ltv0bZtW/r06UOjRo0AWLBgQebtKsmfgQOhfn0TbCZPvsyLWRbs2qURUyIiUiQVeFXwtLQ0EhISKF26dOax3bt3ExgYSIUKFZxWoLPZuSr4pSxcCF27gr8/xMRAlSoFvNCLL5qOPH37wscfO7VGERERO7h8VfBTp06RkpKSGWz27NnDq6++SkxMjFsHG3fXuTPceKPpVPzUU5dxoauvNj81YkpERIqgAoWb7t2788EHHwBw4sQJWrZsyUsvvUSPHj2YPn26UwssShwO0+gC8NFHsGFDAS/UvLn5uWMHHD3qlNpEREQ8RYHCzfr167nuuusAmDdvHmFhYezZs4cPPviA119/3akFFjVNm5q7SWAm9ivQTcPSpc0MgQBr1zqtNhEREU9QoHBz8uRJgoODAfjhhx+4/fbb8fHx4ZprrmHPnj1OLbAoeu45KF4cli6FxYsLeJGMeW50a0pERIqYAoWbmjVrMn/+fPbt28fixYu5+eabATh8+LDbddL1RFWrwtChZv+JJyAtrQAXUbgREZEiqkDhZty4cTz22GNUrVqVFi1a0KpVK8C04jRu3NipBRZVTz4JpUrBpk3w4YcFuEDGkHytEC4iIkVMgYeCx8bGcujQIRo1aoSPj8lIa9asISQkhDp16ji1SGdy56Hg53vpJXjsMahUCbZuNZP95VlqKowZY0LObbeZ5cdFREQ8lMuHggNUrFiRxo0bc/DgwcwVwlu0aJHvYDNt2jSqVq1KiRIlaNmyJWsusZr1q6++ypVXXklAQACRkZE88sgjnD59uqC/hluLijJz3Rw4AK+9ls8XFy8OU6bAf/6jYCMiIkVKgcJNeno6zzzzDKGhoVSpUoUqVapQqlQpJk6cSHp6ep6v89lnnzFixAjGjx/P+vXradSoER07duTw4cM5nv/JJ58watQoxo8fz+bNm3n33Xf57LPPePLJJwvya7i9EiVM52IwsxYfOWJvPSIiIp6gQOFmzJgxTJ06leeff54NGzawYcMGJk2axBtvvMHYsWPzfJ2XX36Ze++9l7vvvpt69eoxY8YMAgMDee+993I8/9dff6VNmzb07duXqlWrcvPNN9OnT59LtvZ4sj59oEkTSEzMWn8qz06dMkOuZs1ySW0iIiLuqEDh5v333+edd97hgQceoGHDhjRs2JAHH3yQmTNnMnv27DxdIzU1lT/++IMOHTpkFePjQ4cOHVi9enWOr2ndujV//PFHZpjZuXMnCxcupEuXLhd9n5SUFBISErJtnsTHx9xdApg+HbZvz8eLDx6EDh3g/vtNHxwREZEioEDh5tixYzn2ralTpw7Hjh3L0zWOHj1KWloaYWFh2Y6HhYURGxub42v69u3LM888w7XXXkuxYsWoUaMGbdu2zfW21OTJkwkNDc3cIiMj81SfO7nxRrM0w9mzZhRVnlWvDmXLmmCzcaPL6hMREXEnBQo3jRo1YurUqRccnzp1Kg0bNrzsoi7m559/ZtKkSbz55pusX7+eL7/8ku+++46JudyvGT16NPHx8Znbvn37XFafK734omnF+fxz+O23PL7I4cgaEv7++y6rTURExJ0UaBjNiy++SNeuXfnxxx8z57hZvXo1+/btY+HChXm6Rrly5fD19SUuLi7b8bi4OCpWrJjja8aOHUv//v0ZMmQIAA0aNCA5OZn77ruPMWPGZA5JP5e/vz/+/v75+fXc0lVXwaBB8N57ZlmGFStMdrmkoUNh0SKYNg3atoU77nBxpSIiIvYqUMvNDTfcwNatW7nttts4ceIEJ06c4Pbbb+fvv//mwzzOOFe8eHGaNm3K0qVLM4+lp6ezdOnSzMB0vpMnT14QYHx9fQEo4HQ9HuWZZyAgAFauhAUL8viizp3NNMcAgwfDtm0uq09ERMQtWE4UHR1t+fj45Pn8OXPmWP7+/tbs2bOtf/75x7rvvvusUqVKWbGxsZZlWVb//v2tUaNGZZ4/fvx4Kzg42Pr000+tnTt3Wj/88INVo0YNq1evXnl+z/j4eAuw4uPj8/6LuZExYywLLOvKKy0rNTWPLzpzxrKuu868sEULy0pPd2mNIiIizpaf729bZ3fr3bs3R44cYdy4ccTGxnL11Vfz/fffZ3Yy3rt3b7aWmqeeegqHw8FTTz3FgQMHKF++PN26deO5jMlgioAnnoC33oKYGHj3XTMQ6pL8/GDOHDOh37RpebyfJSIi4pkKvPxCTjZu3EiTJk1IK9BKj4XDk5ZfuJipU01XmgoVzNDw/y3QfmmWpWAjIiIeqVCWXxD7/N//Qa1acPgw/Pe/+XjhucFm7VqzKqeIiIiXyddtqdtvvz3X50+cOHE5tUgeFStmlmO44w4Tbu6/H8LD83GBb7+F22+HqlVh3Trw0BYsERGRnOSr5ebcyfBy2qpUqcKAAQNcVauc4/bboVUrOHkSnn46ny++5hoICzMjp4YMMberREREvIRT+9x4Am/oc5Nh1Sq49lozud+mTVCvXj5evHo1XH+9mfb49ddNJx4RERE3pT43RUSbNnDbbZCeDqNG5fPFrVplLVr16KPw++9Or09ERMQOCjcebvJk8PWFb76B5cvz+eJhw6BnTzhzBnr1gn//dUmNIiIihUnhxsNdeaUZPQVmWYb09Hy82OEwk+XUrAl798KMGS6pUUREpDAp3HiBceOgZEkzuvvzz/P54tBQmDcPXngBRo92SX0iIiKFSeHGC4SFZS0fNXo0pKTk8wKNGpkL5LDwqIiIiKfRt5mXGDHCzHWzaxdMn34ZF0pOhocfhkOHnFabiIhIYVK48RJBQWbVcICJE6HA8ykOHgxvvAF9+phh4iIiIh5G4caLDBoE9evDsWNmFFWBPPOM6cCzfLnpzCMiIuJhFG68iJ+f6RcM8NprZgBUvl15JbzzjtmfPBm++85p9YmIiBQGhRsv06ULtG1rOhWPHVvAi/TuDQ89ZPb794c9e5xVnoiIiMsp3HgZhyNr4uEPP4To6AJe6L//hebN4fhxM8FfaqqzShQREXEphRsv1KyZ6Q9sWVlDxPPN399MmlO6NOzeDdu3O7NEERERl1G48VLPPQfFi8OSJfDDDwW8SJUq8PXXsGFDPlflFBERsY/CjZeqVi2r28zjj0NaWgEvdN11EBGR9bhoLSIvIiIeSOHGi40ZA6VKwZ9/wosvOuGC8+aZsHPypBMuJiIi4hoKN16sTJms+W6efBJmzbqMiyUlmaagVasgKsop9YmIiLiCwo2Xu//+rE7FQ4bA/PkFvFDJkvDpp2b9qdmz4b33nFShiIiIcyncFAHPP29WVUhPhzvvhJ9/LuCF2rXLWuMhKgo2bnRWiSIiIk6jcFMEOBzw1lvQo4eZ3O/WW80AqAIZPRo6d4bTp+GOOyA+3pmlioiIXDaFmyLCz8/cVWrbFhIToWNH2LatABfy8TGzA1aubOa+uecejaASERG3onBThJQoYaatadIEjhyBm26CAwcKcKGyZWHuXChWDCIjL2OcuYiIiPMp3BQxISGwaBHUqmWWjOrY0awinm8tW0JMDLzyimkWEhERcRMKN0VQhQpm1uKICPj7b7jlFkhOLsCFqlXL2j9zRv1vRETELSjcFFFVq5qAU7o0rF5t+gYXeG3MgwfhxhvNauLp6c4sU0REJN8Uboqw+vXhu+8gMBC+/x4GDSpgNjl6FNatg8WLYdIkZ5cpIiKSLwo3RVyrVvDFF1mjqYYNK8Dgp4YN4c03zf748fDTT06vU0REJK8UboROneCDD8x8OFOnwsSJBbjI3XebLT0d+vQxt6pERERsoHAjgMkjr79u9sePz2qIyZepU6FBAzh82Fzw7Fmn1igiIpIXCjeS6aGHTLDJ2J8zJ58XCAw0K4cHB8OKFfD0084uUURE5JIUbiSb8ePNslGWBf37mz7C+VK7Nrz7rumtfNddLqlRREQkNw7LKlpz5yckJBAaGkp8fDwhISF2l+OW0tOhXz/TchMYCEuXwjXX5PMiZ86YGYxFREScID/f32q5kQv4+MD775vZi0+ehC5dzGR/+XJusPn9d7Nip4iISCFQuJEcFS9uhohfcw0cPw433wy7dxfgQlOnQuvWMGKEs0sUERHJkcKNXFRQkJnkr359M7L75pvNQKh8qV7d3Od6880C9FAWERHJP4UbyVWZMqZTcZUqsG0bdO4MCQn5uECXLvDkk2Z/yBDYssUldYqIiGRQuJFLqlTJrENVvjysXw/du8Pp0/m4wIQJ0LatWZ3zjjsKuEqniIhI3ijcSJ7Urm3WnwoOhp9/zuccfRlrO1SsaHomP/hgAdZ4EBERyRuFG8mzJk1gwQLw94f58+H++/ORUSpWNH1ufHzMWg9Ll7qyVBERKcIUbiRf2rbNyijvvgujR+fjxTfcAC++aEZQtW/vqhJFRKSI0yR+UiDvvQf33GP2X3wRHn+8gBc6e9bcthIREcmFJvETlxs8GF54wew/8QTMmlWAi5w4AY0bm6QkIiLiJAo3UmBPPJHVYjNkiOmHky/Tp8Nff5kmoHvvzecQLBERkZwp3MhleeEFuPtuM0/fnXeakVR5NnIkTJwIDge88w60aQO7drmqVBERKSIUbuSyOBzw9ttm7puUFLj1VtiwIY8v9vGBp54yswSWLWsm0WnaFBYudGnNIiLi3RRu5LL5+ZkRVDfcAImJZsHNbdvycYGbbjLBpkULs5BV167w4Ycuq1dERLybwo04RYkS8PXXpn/wkSMmrxw4kI8LVK4MK1aYCf4iI6FTJ5fVKiIi3k3hRpwmNBQWLYKaNWHPHtOCc+xYPi7g7w/TpkF0tFnrIUOBliMXEZGiSuFGnCosDJYsgYgIs9LCLbcUYCmpMmWy9mfPhiuvhBkztGSDiIjkie3hZtq0aVStWpUSJUrQsmVL1qxZk+v5J06cICoqivDwcPz9/alduzYL1QHVrVStavoIly4Nq1ebtTJTUwt4sR9/NC9+4AEYOBBOnnRmqSIi4oVsDTefffYZI0aMYPz48axfv55GjRrRsWNHDh8+nOP5qamp3HTTTezevZt58+YRExPDzJkzqVSpUiFXLpdy1VXw3XcQGGgW3Bw0yAwXz7cPP4QpU8DX1+xfc00+eyuLiEhRY+vyCy1btqR58+ZMnToVgPT0dCIjIxk6dCijRo264PwZM2YwZcoUtmzZQrFixQr0nlp+oXB9/z1062ZWWXjoIXj9dTN8PN+WL4fevSEuDkJC4P33oUcPZ5crIiJuyiOWX0hNTeWPP/6gQ4cOWcX4+NChQwdWr16d42sWLFhAq1atiIqKIiwsjKuuuopJkyaRlpZ20fdJSUkhISEh2yaFp1Mnswi4w2HWy5w4sYAXuuEGM1z82mshIQFuvx1iYpxaq4iIeAfbws3Ro0dJS0sjLCws2/GwsDBiY2NzfM3OnTuZN28eaWlpLFy4kLFjx/LSSy/x7LPPXvR9Jk+eTGhoaOYWGRnp1N9DLq1PH9NiAzB+PLz5ZgEvFBEBP/0EI0bA2LGmo7GIiMh5bO9QnB/p6elUqFCBt99+m6ZNm9K7d2/GjBnDjBkzLvqa0aNHEx8fn7nt27evECuWDA89ZIJNxv6cOQW8ULFi8NJL8PTTWcd27YJVqy63RBER8RK2hZty5crh6+tLXFxctuNxcXFUrFgxx9eEh4dTu3ZtfH19M4/VrVuX2NhYUi8yHMff35+QkJBsm9hj/HiIijIjuvv3hwULLmN0d0bHndOnzXCstm3h1Vc1XFxEROwLN8WLF6dp06YsXbo081h6ejpLly6lVatWOb6mTZs2bN++nfRzht1s3bqV8PBwihcv7vKa5fI4HOb21J13mg7G3bubUVXPPgs7dhTwomlpUKuWueAjj5iLJyY6tW4REfEstt6WGjFiBDNnzuT9999n8+bNPPDAAyQnJ3P33XcDMGDAAEaPHp15/gMPPMCxY8cYNmwYW7du5bvvvmPSpElERUXZ9StIPvn4mIFOQ4aYCYn/+cd0n6lZ04zyfv11uEiXq5wFBcGnn5oX+vnB3LlmjarNm132O4iIiHuzNdz07t2b//73v4wbN46rr76a6Ohovv/++8xOxnv37uXQoUOZ50dGRrJ48WLWrl1Lw4YNefjhhxk2bFiOw8bFfRUvDjNnmlHds2aZdah8fOD332HYMKhUCW6+2UxOHB+fhws6HDB0qBkuHhEBW7ZA8+Ym6IiISJFj6zw3dtA8N+4pNhY+/xw++QR++y3ruL+/WSS8b1/zs0SJS1zo8GFza2rZMmja1FzMz8+ltYuIiOvl5/tb4Ubczo4dZjTVxx9nv7sUEmKmt+nbF9q1yyWznD1rOvIMGmTWghAREY+ncJMLhRvPYVnw55+mNefTT+HcUfwVKpgJi/v2hZYt8zDr8UsvQZMmJhWJiIjHUbjJhcKNZ0pPh19/NUFn7lz499+s56pVMyGnb1+oVy+HF//0E7Rvbzr2TJoETzxRwDUgRETELgo3uVC48XxnzsCSJSbozJ8PyclZzzVqZGZEvvNOqFLlfwdPnoQHHzTDtMCsSTV7NoSGFm7hIiJSYAo3uVC48S7JyfDttyboLFpkgk+Ga681rTn/+Q+UK2uZIVpDh0Jqqhl7/sUX0LChfcWLiEieKdzkQuHGex07ZvLKJ5+YUeEZf7L9/MzQ8j59oHvkeoIH3g579kBAgAk8/frZW7iIiFySR6wKLuJsZcrAvfeaUeD79pk+xE2bmsFTCxeaJR/COjfhzsYxLGg8ntRTZ82TIiLiVdRyI14vJsaMtvrkE9i2Let46ZKp3NGnOH37wnXXga+PpY7GIiJuSrelcqFwU3RZFvzxhwk6n34K50x+TUTFNO5M+4S+42rSJKqVMo6IiJtRuMmFwo2AWW9zxQrTmjNvHpw4kfXcNeW389Qz/nT5v0iFHBERN6E+NyKX4Otr5vObOdMs/TB/biq9q6/Fn9P8dqQmtzwQSbMyO/jqha2cswi9iIh4AIUbKfL8/aH7f4ozZ0dzdn/7N4/VnE8gyaw/UYPbR9WmUandfDbHIi3N7kpFRCQvFG5EzlGxa1OmbOvBnlUHeLLhtwSTwF+JVbmzj4P69eGD9y3OntYIKxERd6ZwI5KDcq1r89zGW9izKZEJI5MpXdqMuho4yMGVwQeY2W8ZqfGn7C5TRERyoHAjkovSV1Vi3PNB7N4NkydDOf8Edp6twn2ftKNmmX+Z1u17Th86bneZIiJyDoUbkTwICYFRo2D3Pj9evu0Xwn3j2Jd+BQ9924lqlVJ4ue3XJG89YHeZIiKCwo1IvgSVD+SRL69j54myTB24lshih4i1KvLo8u5Uq1eC5ydbJCTYXaWISNGmcCNSACVK+hE1uznbEysy8+FNVC9xgCNpZRn9pIOqVWHC2DMcX7LO7jJFRIokhRuRy1Dc38GQ1xoQk1iJD963uPJKOH4cnn62GFVvrsWYKh9ydM6PWat4ioiIyynciDiBnx/0H+Dg779hzhy4qkIcCYQyaW9/qvRpxWNhHxD75pdaqFNEpBAo3Ig4ka8v9O4NGw+F8dXMozSpsI+TBPHSkYFUi+rMw2U+Yv+zs9WSIyLiQgo3Ii7g4wM9hpRjXWwk381J5JrI/ZwmgDcSB1F9XD/+734Hu3bZXaWIiHdSuBFxIYcDuvQO5tc9V/Djt6e5oeYBzljFePttqFUL7u6VzNbBz8P+/XaXKiLiNRRuRAqBwwHtu5bg522VWLECbr7ZrEw++/Mg6s56nL6VV/L3bU/Bli12lyoi4vEUbkQK2XXXweLF8Ntv0O2aI6Tjy6fWnVw1/1l61v2bDTc+Cr//bneZIiIeS+FGxCYtW8KC1eXZsAF6tvsXgC/pSZNlL9HtmsOsuXaEOh6LiBSAwo2Iza6+Gub9VJa//oK+XePxcaTzLd1oueplOnZy8MsvmHtYJ0/aXaqIiEdwWFbR+qdhQkICoaGhxMfHExISYnc5IhfYuhWeH5vMh18GcvasA4CG1ROptmc54TUCCW9V1WyVfAgPh/BwqFDBzLUjIuKt8vP9rXAj4qZ274bnn4f33oMzZ3I/1+EwAScj7Jy/VayYtV+iRKGULyLiVAo3uVC4EU9z6BD8/pvFoZU7OPRzDIf+Osqh1LIcIpxDhBNHGOn45vl6pUpdPASduwUHm9AkIuIOFG5yoXAjHi8lBb77Dj76CL79lrSqNTiy/B8OxTo4dAhiV23nkF8kh/7159Ahsm0pKXl/m8DAS7cElSwJxYtfuPn6KhiJiHMp3ORC4Ua8yrFj5v5Vkybm8alTJnmcPQs9ekD//tChA/j5YVlw4gQXBJ6ctsTEyyvL4cg59BTGFhICDRuanyLiPRRucqFwI15t82a49VbYvj3rWFgY9O0Ld90FjRvnqUklOfnSASg21mSp1NRL9wmyQ+3a0LRp1takiQKPiCdTuMmFwo14PcuCNWvgww/NEuX//pv13CuvwPDhLnnLM2dM0LF7O3wY9u3Luc5zA0+zZibr6a8BEc+gcJMLhRspUs6cge+/N/1zFiyAP/80i1oBrFwJMTFwxx0QGmpvnU525Aj88Uf2be/enM/NCDzNmpmfCjwi7knhJhcKN1JkJSWZHsAZevaEL780Y8NvvdXcturUCYoVs69GF8pv4MkIOwo8Iu5B4SYXCjci//Pyy/DOO6afToZy5eDOO01H5BYt7KutkJwfeNaty/mWlsNxYR8eBR6RwqVwkwuFG5FzWBZs2GD653z6KcTFmeNNmphv+yLo3MCzbp35mZfAk9GHJzi48GsWKQoUbnKhcCNyEWfPwo8/mv45114L999vjickmGHlvXqZrUwZW8u0Q0ECz7l9eBR4RC6fwk0uFG5E8um99+Cee8x+8eLQtavpn9O1K/j721ubjQ4fhvXrs8LOpQJPq1bQtq3ZqlQp7GpFPJ/CTS4UbkTy6dAh+OQTc+tq48as46VKQceOMHkyVKtmW3nu5PDhCzst5xR4qlbNCjoKOyJ5o3CTC4UbkcuwaZMJOR9/DAcPmmOHD0P58mb/889h/364/nq4+mqzDkMRd/iwad355Rf4+WdYuxbS0rKfo7AjcmkKN7lQuBFxgrQ0WLXKtOQMHZp1vEMHWLrU7AcHm747119vtmbNzG2tIi4pyXx0P/+ssCOSHwo3uVC4EXGh11+HH34wEwTGx2d/LizMtPb4+JjHaWlq2UFhRy7OssyfjxMnLr5ZlvnzULWq2SpVAj8/20p2KYWbXCjciBSCtDRzC2vFiqytWTNYuDDrnHr1TL+djJadNm28bqbkglDY8R6WZdZpyy2cnDgBx4/nfDw+/sL/9pfi6wuRkVlhJ2PLCEBXXOG54UfhJhcKNyI2sCzzN3WpUubxwYPmn5jn8vGBRo1M0OnWDdq3L/Qy3VFiIvz6q8KOXSwLjh0zC8VeLITktuU3nOSkWDHzv05OW3o67NkDu3ebn5daxNbX1wSc88NPxubO4UfhJhcKNyJuwLLM38YZrTrLl8OOHVnP338/TJ9u9lNTzTIR118PERG2lOtOFHac4/RpE1hiY7NWuc9pPy7u8le99/OD0qUvHlAutQUEmCkFLiU93dS8e/eF2549ZktNzf0avr7m3x25hR+7VmhRuMmFwo2ImzpwwAwpWrHCtNx07myOr14NrVub/Ro1sm5jXX+9GYKel7/1vZjCTpb0dPj330uHlthY06qSH6VLQ9my+Q8mpUvnPZy4Wnq6+d1zCj8ZAehS4cfHJ3vLz7n9fapWNbfEXBV+FG5yoXAj4mGWLoUnnoDoaPO387kqVYI33zQLfwqQv7DTurXp5lSsWPatePELj+X2vK+va7+8T526dAtLbKxpZTl7Nu/X9feHihUhPNz8vNh+hQpFY77K9HTzGeYWflJScr+Gj4/537JNG7OiizMp3ORC4UbEQ8XHm2/tjFtZa9ea+wW//mqm/wVYsADef98MSb/5ZtPSU8TlJew4Q0GDUU7PJSdnDy4JCfmrpVy5C4NKTsElNNQ9WlQ8RXq6mbcpt/Bz+rQ5t107+Okn576/wk0uFG5EvMTJk/D77+afiBnz5zzwAMyYkXVO9epw000m6Nx4Y1aH5iLs3LCzfr35MjpzJvctNTX7Yzu+NUqUuHQLS8WKZsYBu/qEFHWWlRV+HA5o0cK511e4yYXCjYgXi46Gb7+FJUvMN/i59yh8fU2/nrAw28rzFmlplw5AeQ1KOT2fEWTODS0hIWplKeo8LtxMmzaNKVOmEBsbS6NGjXjjjTdokYfIN2fOHPr06UP37t2ZP39+nt5L4UakiEhMNKOwfvjBhJ30dIiJyXq+b1/T+pPRslOzpr49RdyYR4Wbzz77jAEDBjBjxgxatmzJq6++yueff05MTAwVKlS46Ot2797NtddeS/Xq1SlTpozCjYjkLjHRLAkBpnmgTBnTuSNDlSom5Nx0k5ljp0wZe+oUkRx5VLhp2bIlzZs3Z+rUqQCkp6cTGRnJ0KFDGTVqVI6vSUtL4/rrr2fw4MH88ssvnDhxQuFGRPIuPR02bDAtOhnLRZw7mcn5vSHPnnXfmc1Eioj8fH/7FFJNOUpNTeWPP/6gQ4cOmcd8fHzo0KEDq1evvujrnnnmGSpUqMA999xzyfdISUkhISEh2yYiRZyPDzRtCqNGmRBz/LhZGmL4cKhf37TgZDhyxLTidOtm1s7assWeHrUikme2/lPk6NGjpKWlEXZeB7+wsDC2bNmS42tWrlzJu+++S3R0dJ7eY/LkyUyYMOFySxURbxYUZCYNzJg48Nz5dJYtM7e0vv3WbGBmMcu4hXXzzbqFJeJmbG25ya/ExET69+/PzJkzKVeuXJ5eM3r0aOLj4zO3ffv2ubhKEfF4Puf81XjHHeYW1osvmvlz/P1h/3547z3o0we++Sbr3KSkS89yJiIuZ2vLTbly5fD19SUuLi7b8bi4OCpWrHjB+Tt27GD37t1069Yt81j6//6F5efnR0xMDDXOm7TL398f/6IwtaSIuIaPD1x9tdkef9yMsFq50vTV+eEH03qT4a23YNw4uOGGrFadevU0CkukkNkabooXL07Tpk1ZunQpPXr0AExYWbp0KQ899NAF59epU4dNmzZlO/bUU0+RmJjIa6+9RmRkZGGULSJFWWCgCS3n9svJsGaNCT+LFpkNzGKfN90E114L/fsXjXn8RWxm+2ipzz77jIEDB/LWW2/RokULXn31VebOncuWLVsICwtjwIABVKpUicmTJ+f4+kGDBmm0lIi4B8uCTZuyRmGtWJE1H31AgOm74+trHk+bZtYVaNTIbBERauERyUV+vr9tH9vYu3dvjhw5wrhx44iNjeXqq6/m+++/z+xkvHfvXnx8PKprkIgUVQ4HNGxotkcfNcFm5Ur48UfTHycj2IBZJuKvv7Iely2bFXSaNoV+/Qq/fhEvYXvLTWFTy42IuIWXX4Z162DjRjNz8rmrWdarB3//nfX46afNBISNGpnglMsEpyLeyqNabkREiqQRI7L2T582YWbjRrOdG17S0sxIrVOnso5VrJjVynPddXDLLYVXt4gHUMuNiIg7O3nStPJs3GgWBt2xI/skgrfeCl9/bfYtCx5+GGrVygo/WgldvIRabkREvEVgIDz1VNbjpCTTaTmjladZs6znDh6E/y1lk6ly5aygc/PNpqVHxMsp3IiIeJKSJaFVK7Odz9cXxo7NCj579sDevWb75hvTCpQRbo4fhyefhGuugdattSq6eBXdlhIR8VYnTsCff2bd0urZE7p0Mc8tXw5t22adW66cCTmtW5vg1KyZaTUScRMetSp4YVO4EREBtm6FmTNh9Wozauv8ZSPeeAMyJlM9ccLcDrviikIvUySD+tyIiEjuateGKVPMfkqKWT9r9Wr49VdYtcq04GT44gsYMgQiI7Nad1q3Nv14ihWzp36RXKjlRkREssv4WsjogzNhAkycmH0uHjCzLrdoYdbUuvLKwq1RihzdlsqFwo2ISAEkJcHataZl59dfTSvP8ePmuaNHzQzLYG5nrV+f1bpTt272VdZFCkjhJhcKNyIiTpCebmZW/vNP6N076/iNN8KyZVmPQ0OzRmS1bg3t2mVfhkIkjxRucqFwIyLiQkuWmJFYq1fD779DcnLWc6VLm1aejJacX34xC4ZWr65h6HJJ6lAsIiL2uOkmswGcPWsmHMy4lRUYmP0WVf/+Zi6eChWyd1Ru0sT05xEpILXciIhI4UtOhg4d4I8/4MyZ7M85HNCrF8yZk3Xsp5+galWoUkW3tYootdyIiIh7Cwoyt65OnzYBJ6N159df4fDh7GtiJSdD+/Zmv3hxM5ty7dpZW7NmZli6yP8o3IiIiH1KlIA2bcwGZhj60aPZW3OOHoX69WH7djMnzz//mC3DPffAO++Y/dOnzZw8tWub4em1a5uFREuWLLzfSWyncCMiIu7D4YDy5bMfq1IF/vrLzLOzb5+ZXTkmxvzcutWMxsqwfTt8/PGF161UyQSdgQPNBmbEV1qaJiL0Qgo3IiLiGXx9Tb+bqlXNCuc5KV0aJk/OCj4xMabl58ABs3XokHXu1q3QoIEZrXVuS0/GFh6uUVweSuFGRES8R6VKMGpU9mPHjsG2bSbMNG6cdXzrVjOiKyMIfftt9tc9+yyMGWP24+Jg8WKoVs2EofBwTU7oxhRuRETEu5UpAy1bmu1ct9ySdZvr/Ftdu3aZjssZ1q3Lup0F4O9vWpAywk7//lm3xyxLLT42U7gREZGiycfHrHR+xRVmZuVzpaZmrbEFZt6dDh1g507Yu9d0bI6JMRuYDtEZ4WbRIrjrLhN6MsLPuT+rVDGjvsRlFG5ERETOd374uPHGrAB09izs32+Czq5d5mezZlnn7txp1t364w+zne+jj6BfP7P/55/w9dfZA1BYmFp+LpPCjYiISH74+WV1bM7J4MFwww1Zwef8n9WqZZ27ciWMG5f99QEBWUFn3Dho3twcT0oyrUnBwa74rbyKwo2IiIgzBQaaUVgNGlz4nGVlv91VuzbcfXdW8Nm/H06dyprL59zO0R9+CA8+COXKmeCTsdWqZbarrzaTI4rCjYiISKFxOLLfcurQIfvw9NRU06cnI+zUq5f13KFD5ufRo2Zbsyb7tZcvh+uvN/vLlpktI/jUqgVly7rmd3JDWltKRETEU8THZ7/NtX27Gea+fbtZziI83Jz3xBMwZUr215YunRV0nnvOdGwGM5GhB6zXlZ/vb4UbERERb/P11/Dddyb4bNtmJjA81759ZpQYwJNPwsyZ2Vt5atUyt8xq1nSbPj5aOFNERKQo697dbBmSk2HHjqxWnoiIrOe2bs261bV69YXX2rMHKlc2+ytWwJEjJvzUrGn6F7khtdyIiIgUZYmJWbe3MratW83PxEQ4eTJrNubevWHu3KzXVqqUvbXnoYfMaC8X0G2pXCjciIiI5FFiYvbbUuPGmWUotm0zc/mcq1gxE4T8XHNTSLelRERE5PKd39/mmWfMBvDvv9lbexITXRZs8ss9qhARERHPUras2TKWnXAjWtJUREREvIrCjYiIiHgVhRsRERHxKgo3IiIi4lUUbkRERMSrKNyIiIiIV1G4EREREa+icCMiIiJeReFGREREvIrCjYiIiHgVhRsRERHxKgo3IiIi4lUUbkRERMSrKNyIiIiIV/Gzu4DCZlkWAAkJCTZXIiIiInmV8b2d8T2emyIXbhITEwGIjIy0uRIRERHJr8TEREJDQ3M9x2HlJQJ5kfT0dA4ePEhwcDAOh8PuclwuISGByMhI9u3bR0hIiN3luD19Xnmnzyrv9FnlnT6rvCtqn5VlWSQmJhIREYGPT+69aopcy42Pjw9XXHGF3WUUupCQkCLxh99Z9HnlnT6rvNNnlXf6rPKuKH1Wl2qxyaAOxSIiIuJVFG5ERETEqyjceDl/f3/Gjx+Pv7+/3aV4BH1eeafPKu/0WeWdPqu802d1cUWuQ7GIiIh4N7XciIiIiFdRuBERERGvonAjIiIiXkXhRkRERLyKwo2Xmjx5Ms2bNyc4OJgKFSrQo0cPYmJi7C7LIzz//PM4HA6GDx9udylu6cCBA9x1112ULVuWgIAAGjRowLp16+wuy+2kpaUxduxYqlWrRkBAADVq1GDixIl5WhenKFixYgXdunUjIiICh8PB/Pnzsz1vWRbjxo0jPDycgIAAOnTowLZt2+wp1ma5fVZnzpxh5MiRNGjQgKCgICIiIhgwYAAHDx60r2A3oHDjpZYvX05UVBS//fYbS5Ys4cyZM9x8880kJyfbXZpbW7t2LW+99RYNGza0uxS3dPz4cdq0aUOxYsVYtGgR//zzDy+99BKlS5e2uzS388ILLzB9+nSmTp3K5s2beeGFF3jxxRd544037C7NLSQnJ9OoUSOmTZuW4/Mvvvgir7/+OjNmzOD3338nKCiIjh07cvr06UKu1H65fVYnT55k/fr1jB07lvXr1/Pll18SExPDrbfeakOlbsSSIuHw4cMWYC1fvtzuUtxWYmKiVatWLWvJkiXWDTfcYA0bNszuktzOyJEjrWuvvdbuMjxC165drcGDB2c7dvvtt1v9+vWzqSL3BVhfffVV5uP09HSrYsWK1pQpUzKPnThxwvL397c+/fRTGyp0H+d/VjlZs2aNBVh79uwpnKLckFpuioj4+HgAypQpY3Ml7isqKoquXbvSoUMHu0txWwsWLKBZs2b85z//oUKFCjRu3JiZM2faXZZbat26NUuXLmXr1q0AbNy4kZUrV9K5c2ebK3N/u3btIjY2Ntv/i6GhobRs2ZLVq1fbWJlniI+Px+FwUKpUKbtLsU2RWzizKEpPT2f48OG0adOGq666yu5y3NKcOXNYv349a9eutbsUt7Zz506mT5/OiBEjePLJJ1m7di0PP/wwxYsXZ+DAgXaX51ZGjRpFQkICderUwdfXl7S0NJ577jn69etnd2luLzY2FoCwsLBsx8PCwjKfk5ydPn2akSNH0qdPnyKzmGZOFG6KgKioKP766y9Wrlxpdyluad++fQwbNowlS5ZQokQJu8txa+np6TRr1oxJkyYB0LhxY/766y9mzJihcHOeuXPn8vHHH/PJJ59Qv359oqOjGT58OBEREfqsxCXOnDlDr169sCyL6dOn212OrXRbyss99NBDfPvttyxbtowrrrjC7nLc0h9//MHhw4dp0qQJfn5++Pn5sXz5cl5//XX8/PxIS0uzu0S3ER4eTr169bIdq1u3Lnv37rWpIvf1+OOPM2rUKO68804aNGhA//79eeSRR5g8ebLdpbm9ihUrAhAXF5fteFxcXOZzkl1GsNmzZw9Lliwp0q02oHDjtSzL4qGHHuKrr77ip59+olq1anaX5Lbat2/Ppk2biI6OztyaNWtGv379iI6OxtfX1+4S3UabNm0umFJg69atVKlSxaaK3NfJkyfx8cn+V6yvry/p6ek2VeQ5qlWrRsWKFVm6dGnmsYSEBH7//XdatWplY2XuKSPYbNu2jR9//JGyZcvaXZLtdFvKS0VFRfHJJ5/w9ddfExwcnHmfOjQ0lICAAJurcy/BwcEX9EUKCgqibNmy6qN0nkceeYTWrVszadIkevXqxZo1a3j77bd5++237S7N7XTr1o3nnnuOypUrU79+fTZs2MDLL7/M4MGD7S7NLSQlJbF9+/bMx7t27SI6OpoyZcpQuXJlhg8fzrPPPkutWrWoVq0aY8eOJSIigh49ethXtE1y+6zCw8O54447WL9+Pd9++y1paWmZf9+XKVOG4sWL21W2veweriWuAeS4zZo1y+7SPIKGgl/cN998Y1111VWWv7+/VadOHevtt9+2uyS3lJCQYA0bNsyqXLmyVaJECat69erWmDFjrJSUFLtLcwvLli3L8e+ogQMHWpZlhoOPHTvWCgsLs/z9/a327dtbMTEx9hZtk9w+q127dl307/tly5bZXbptHJal6TJFRETEe6jPjYiIiHgVhRsRERHxKgo3IiIi4lUUbkRERMSrKNyIiIiIV1G4EREREa+icCMiIiJeReFGRIo8h8PB/Pnz7S5DRJxE4UZEbDVo0CAcDscFW6dOnewuTUQ8lNaWEhHbderUiVmzZmU75u/vb1M1IuLp1HIjIrbz9/enYsWK2bbSpUsD5pbR9OnT6dy5MwEBAVSvXp158+Zle/2mTZu48cYbCQgIoGzZstx3330kJSVlO+e9996jfv36+Pv7Ex4ezkMPPZTt+aNHj3LbbbcRGBhIrVq1WLBggWt/aRFxGYUbEXF7Y8eOpWfPnmzcuJF+/fpx5513snnzZgCSk5Pp2LEjpUuXZu3atXz++ef8+OOP2cLL9OnTiYqK4r777mPTpk0sWLCAmjVrZnuPCRMm0KtXL/7880+6dOlCv379OHbsWKH+niLiJHav3CkiRdvAgQMtX19fKygoKNv23HPPWZZlVri///77s72mZcuW1gMPPGBZlmW9/fbbVunSpa2kpKTM57/77jvLx8fHio2NtSzLsiIiIqwxY8ZctAbAeuqppzIfJyUlWYC1aNEip/2eIlJ41OdGRGzXrl07pk+fnu1YmTJlMvdbtWqV7blWrVoRHR0NwObNm2nUqBFBQUGZz7dp04b09HRiYmJwOBwcPHiQ9u3b51pDw4YNM/eDgoIICQnh8OHDBf2VRMRGCjciYrugoKALbhM5S0BAQJ7OK1asWLbHDoeD9PR0V5QkIi6mPjci4vZ+++23Cx7XrVsXgLp167Jx40aSk5Mzn1+1ahU+Pj5ceeWVBAcHU7VqVZYuXVqoNYuIfdRyIyK2S0lJITY2NtsxPz8/ypUrB8Dnn39Os2bNuPbaa/n4449Zs2YN7777LgD9+vVj/PjxDBw4kKeffpojR44wdOhQ+vfvT1hYGABPP/00999/PxUqVKBz584kJiayatUqhg4dWri/qIgUCoUbEbHd999/T3h4eLZjV155JVu2bAHMSKY5c+bw4IMPEh4ezqeffkq9evUACAwMZPHixQwbNozmzZsTGBhIz549efnllzOvNXDgQE6fPs0rr7zCY489Rrly5bjjjjsK7xcUkULlsCzLsrsIEZGLcTgcfPXVV/To0cPuUkTEQ6jPjYiIiHgVhRsRERHxKupzIyJuTXfORSS/1HIjIiIiXkXhRkRERLyKwo2IiIh4FYUbERER8SoKNyIiIuJVFG5ERETEqyjciIiIiFdRuBERERGvonAjIiIiXuX/Aa9va4wuWOSxAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAGwCAYAAABB4NqyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABd2klEQVR4nO3dd1hT1/8H8HeIEoaAA0FwrzpRrCh1W0VxFEed1F3Ht9Y96p61ilWL1PHTanG1ddTWWq3VVlHrHhVHrYpbXOBmyjC5vz9OE4gEJRC4CXm/nicPyc3NySfUmrfnnHuOQpIkCURERERWxEbuAoiIiIjyGgMQERERWR0GICIiIrI6DEBERERkdRiAiIiIyOowABEREZHVYQAiIiIiq1NA7gLMkUajwYMHD+Dk5ASFQiF3OURERJQFkiQhLi4Onp6esLF5cx8PA5ABDx48QOnSpeUug4iIiLLh7t27KFWq1BvPYQAywMnJCYD4BTo7O8tcDREREWVFbGwsSpcurfsefxMGIAO0w17Ozs4MQERERBYmK9NXOAmaiIiIrA4DEBEREVkdBiAiIiKyOpwDlANqtRqpqalyl0GUqYIFC0KpVMpdBhGR2WEAygZJkhAVFYUXL17IXQrRWxUuXBglSpTgmlZEROkwAGWDNvy4ubnBwcGBXyxkliRJQmJiIh49egQA8PDwkLkiIiLzwQBkJLVarQs/xYoVk7scojeyt7cHADx69Ahubm4cDiMi+g8nQRtJO+fHwcFB5kqIskb7Z5Xz1YiI0jAAZROHvchS8M8qEVFGDEBERERkdRiAiIiIyOowAFG2lStXDiEhIVk+/+DBg1AoFFw+gIiIZMcAZAUUCsUbb7NmzcpWu6dPn8aQIUOyfH7Dhg3x8OFDuLi4ZOv9sqNq1apQqVSIiorKs/ckIqI3UKuB5GS5q2AAsgYPHz7U3UJCQuDs7Kx3bPz48bpzJUnCq1evstRu8eLFjboaztbWNk8X5Dty5AhevnyJrl27Yv369Xnynm/Cq7CIyCr99hsQFAT07g3UqQMUKgSsWSN3VQxAJpWQkPktKSnr5758+fZzjVCiRAndzcXFBQqFQvf4ypUrcHJywu7du1G3bl2oVCocOXIEN27cQMeOHeHu7o5ChQqhXr162Ldvn167rw+BKRQKfPvtt+jcuTMcHBxQuXJl7NixQ/f860Ng69atQ+HChfHHH3+gWrVqKFSoENq0aYOHDx/qXvPq1SuMHDkShQsXRrFixTBx4kT069cPnTp1euvnDg0NxUcffYQ+ffpgjYH/2e7du4fAwEAULVoUjo6O8PHxwcmTJ3XP79y5E/Xq1YOdnR1cXV3RuXNnvc+6fft2vfYKFy6MdevWAQBu374NhUKBLVu2oFmzZrCzs8MPP/yAp0+fIjAwECVLloSDgwO8vLywadMmvXY0Gg0WLFiASpUqQaVSoUyZMpg7dy4AoEWLFhg+fLje+Y8fP4atrS3CwsLe+jshIjI5tRq4cQPYsUMEndmz9Z8fNw6YMgX44Qfg3DnxfXj5siylpscAZEqFCmV+69JF/1w3t8zPbdtW/9xy5TKeY2KTJk3C/PnzcfnyZdSqVQvx8fFo164dwsLCcPbsWbRp0wYBAQGIjIx8YzuzZ89G9+7dceHCBbRr1w69evXCs2fPMj0/MTERixYtwnfffYdDhw4hMjJSr0fqyy+/xA8//IC1a9fi6NGjiI2NzRA8DImLi8PWrVvRu3dvtGrVCjExMTh8+LDu+fj4eDRr1gz379/Hjh07cP78eUyYMAEajQYAsGvXLnTu3Bnt2rXD2bNnERYWhvr167/1fV83adIkjBo1CpcvX4a/vz+SkpJQt25d7Nq1CxcvXsSQIUPQp08fnDp1SveayZMnY/78+Zg+fTouXbqEjRs3wt3dHQAwaNAgbNy4Ecnpuo+///57lCxZEi1atDC6PiKibFm1CujTB3j3XcDJCahUCejYUQSd4GBAktLODQgAPvoImDsX2L4duHYNWLxYttJ1JMogJiZGAiDFxMRkeO7ly5fSpUuXpJcvX2Z8ofhPbvjWrp3+uQ4OmZ/brJn+ua6uGc/JprVr10ouLi66xwcOHJAASNu3b3/ra2vUqCEtXbpU97hs2bLS4sWLdY8BSNOmTdM9jo+PlwBIu3fv1nuv58+f62oBIF2/fl33muXLl0vu7u66x+7u7tLChQt1j1+9eiWVKVNG6tix4xtrXbVqleTt7a17PGrUKKlfv366x998843k5OQkPX361ODrGzRoIPXq1SvT9gFIv/zyi94xFxcXae3atZIkSdKtW7ckAFJISMgb65QkSWrfvr00btw4SZIkKTY2VlKpVNLq1asNnvvy5UupSJEi0pYtW3THatWqJc2aNSvT9t/4Z5aI6HVqtSRdvy5JO3ZIUlCQJPXuLUktWuif07at/neSSiVJ3t6S9NFHkjR3riQlJ8tS+pu+v1/HrTBMKT4+8+de34Lgv/2ZDLJ5rWPu9u1sl5RVPj4+eo/j4+Mxa9Ys7Nq1Cw8fPsSrV6/w8uXLt/YA1apVS3ff0dERzs7Our2oDHFwcEDFihV1jz08PHTnx8TEIDo6Wq/nRalUom7durqemsysWbMGvXv31j3u3bs3mjVrhqVLl8LJyQnnzp1DnTp1ULRoUYOvP3fuHAYPHvzG98iK13+varUa8+bNw48//oj79+8jJSUFycnJurlUly9fRnJyMlq2bGmwPTs7O92QXvfu3REeHo6LFy/qDTUSEWWJRqP/ffPll8CPP4rhqdenYgDA48dA8eLifp8+QOPGQPXqQI0aQIUKGb/nzBwDkCk5Osp/bjY5vvYe48ePx969e7Fo0SJUqlQJ9vb26Nq1K1JSUt7YTsGCBfUeKxSKN4YVQ+dL6btOs+HSpUs4ceIETp06hYkTJ+qOq9VqbN68GYMHD9btkZWZtz1vqE5Dk5xf/70uXLgQX3/9NUJCQuDl5QVHR0eMHj1a93t92/sCYhjM29sb9+7dw9q1a9GiRQuULVv2ra8jIiul0QC3bgGXLgH//ituly4BV64ADx4A2itz798HwsPFfZUKqFpVhJsaNUTQSf/3WWBg3n8OE2MAIoOOHj2K/v376yb+xsfH43Ye9ESl5+LiAnd3d5w+fRpNmzYFIEJMeHg4vL29M31daGgomjZtiuXLl+sdX7t2LUJDQzF48GDUqlUL3377LZ49e2awF6hWrVoICwvDgAEDDL5H8eLF9SZrX7t2DYmJiW/9TEePHkXHjh11vVMajQZXr15F9erVAQCVK1eGvb09wsLCMGjQIINteHl5wcfHB6tXr8bGjRuxbNmyt74vEVkoSRK9MSpVWg/LtWuilyY2FoiLy/jziy+AkiXFuV9/DUyebLhHBxDtvPeeuN+/P9CihcX26BhL9gC0fPlyLFy4EFFRUahduzaWLl2a6WTT1NRUBAUFYf369bh//z6qVKmCL7/8Em3atMl2m2RY5cqVsW3bNgQEBEChUGD69OlvHXbKDSNGjEBQUBAqVaqEqlWrYunSpXj+/Hmml9Knpqbiu+++w+eff46aNWvqPTdo0CAEBwfj33//RWBgIObNm4dOnTohKCgIHh4eOHv2LDw9PdGgQQPMnDkTLVu2RMWKFdGzZ0+8evUKv//+u65HqUWLFli2bBkaNGgAtVqNiRMnZujNMqRy5cr46aefcOzYMRQpUgTBwcGIjo7WBSA7OztMnDgREyZMgK2tLRo1aoTHjx/j33//xcCBA/U+y/Dhw+Ho6Kh3dRoRmZEXL8SwkaGQEhsLDB0qJhADQGioGH4ydJ5GA1y9ClSuLM5dtw6YNy/z9x02LC0AJSenBaiqVdOGrLS3ChXSXvfuu+JmJWQNQFu2bMHYsWOxcuVK+Pr6IiQkBP7+/oiIiICbm1uG86dNm4bvv/8eq1evRtWqVfHHH3+gc+fOOHbsGOrUqZOtNsmw4OBgfPzxx2jYsCFcXV0xceJExMbG5nkdEydORFRUFPr27QulUokhQ4bA398fykz+ZbJjxw48ffrUYCioVq0aqlWrhtDQUAQHB+PPP//EuHHj0K5dO7x69QrVq1fX9Ro1b94cW7duxZw5czB//nw4OzvreqEA4KuvvsKAAQPQpEkTeHp64uuvv8aZM2fe+nmmTZuGmzdvwt/fHw4ODhgyZAg6deqEmJgY3TnTp09HgQIFMGPGDDx48AAeHh745JNP9NoJDAzE6NGjERgYCDs7uyz9LonIRCQJuHtXDCFdvpz28/Zt4O+/AVdXcd60acBrPdF6PvwwLQDduAH8+Wfm56b/+7dCBcDXF3B2Fq9//aeHR9q5vXoBnTqJ1xSQvc/DrCiknE64yAFfX1/Uq1dP14Wv0WhQunRpjBgxApMmTcpwvqenJ6ZOnYphw4bpjnXp0gX29vb4/vvvs9UmACQnJ+tdVhwbG4vSpUsjJiYGzs7OeucmJSXh1q1bKF++PL94ZKDRaFCtWjV0794dc+bMkbsc2dy+fRsVK1bE6dOn8e5b/sXGP7NE2ZSSIoabqlRJCw+zZgGLFmW+Htv164D2wo6pU4GlSw2HFGdnMVRVurQ498wZMS/n9XO09x0dgTxaRNaSxcbGwsXFxeD39+tki4MpKSk4c+YMJk+erDtmY2MDPz8/HD9+3OBrkpOTM/wFbm9vjyNHjmS7TQAICgrC7NcXbiKzcOfOHfz5559o1qwZkpOTsWzZMty6dQsfffSR3KXJIjU1FU+fPsW0adPw3nvvvTX8EFEWxMaKHpz0vTmXLwM3b4pF/i5dAqpVE+fa24vwU6CAWPumWjVxq1pVPNYOPQFi3Zv/FjF9q7p1xY3yjGwB6MmTJ1Cr1boF3rTc3d1x5coVg6/x9/dHcHAwmjZtiooVKyIsLAzbtm2DWq3OdpuAWHhu7NixusfaHiCSn42NDdatW4fx48dDkiTUrFkT+/btQzXtX0ZW5ujRo3j//ffxzjvv4KeffpK7HCLLIUniiidtwOnaFShRQjz39dfAjBmGX+fkBDx8mBaA+vYVC/5VrAhkYd4fmS+LGhD8+uuvMXjwYFStWhUKhQIVK1bEgAEDDG5zYAyVSgWVSmWiKsmUSpcujaNHj8pdhtlo3rx5jpcJILIKly6JrRnS9+zExaU9X64c8MEH4n61aoCnp+jF0fbmaHt2PDz0h548PPTn2JDFki0Aubq6QqlUIjo6Wu94dHQ0SmhT+WuKFy+O7du3IykpCU+fPoWnpycmTZqECv/NYs9Om0REZIHi4oCICP2AM24c0KiReP7cOXH5d3pKpei5qVpVzK3R6tJF9AiRVZEtANna2qJu3boICwvTbWyp0WgQFhaWYbPH19nZ2aFkyZJITU3Fzz//jO7du+e4TSIiMnP//CP2mTp40PAK+U2bpgWgOnXEFVDpe3MqVhSXg7+Ok4utkqxDYGPHjkW/fv3g4+OD+vXrIyQkBAkJCbrF5/r27YuSJUsiKCgIAHDy5Encv38f3t7euH//PmbNmgWNRoMJEyZkuU0iIrIAT54ABw6Ioap69cSxhASxBo6Wu7v+sJWfX9pz1aoB/10dTGSIrAGoR48eePz4MWbMmIGoqCh4e3tjz549uknMkZGRsEm3T0lSUpJuHZVChQqhXbt2+O6771C4cOEst0lERGYoNhY4dAjYv1/czp8Xx4cMSQtAPj5it/FmzcT9TPbyI8oKWdcBMldvWkeAa6qQpeGfWTJriYli+4W//xaXnKfn5QV89BGQyRpuRK+ziHWAyPI0b94c3t7eCAkJkbsUIrI0qanA6dOidycxMW0rBwcH4PlzEX4qVgRathSBqHlzMcRFlEsYgKxAQEAAUlNTsWfPngzPHT58GE2bNsX58+dRq1Ytk7zfy5cvUbJkSdjY2OD+/ftcYoDIGmk0Yhhr/34gLEwMb2lXT3Z0FCsq29qKx+vWicvQy5aVq1qyQgxAVmDgwIHo0qUL7t27h1KlSuk9t3btWvj4+Jgs/ADAzz//jBo1akCSJGzfvh09evQwWdvGkiQJarUaBbgHDlHukiT9q6k+/BD49Vf9c4oVA95/X/TypB/uatAgb2okSsfm7aeQpfvggw9QvHhxrEt/9QSA+Ph4bN26FQMHDsTTp08RGBiIkiVLwsHBAV5eXti0aVO23i80NBS9e/dG7969ERoamuH5f//9Fx988AGcnZ3h5OSEJk2a4MaNG7rn16xZgxo1akClUsHDw0O3hMHt27ehUChw7tw53bkvXryAQqHAwYMHAQAHDx6EQqHA7t27UbduXahUKhw5cgQ3btxAx44d4e7ujkKFCqFevXrYt2+fXl3JycmYOHEiSpcuDZVKhUqVKiE0NBSSJKFSpUpYtGiR3vnnzp2DQqHA9evXs/V7IrJ4t28Da9aIy81LlgTSr8FWv75YRfmDD8Sl6+fOAY8eAVu3Ap98IraUIJIR/1lsApIkhrTzmoND1pavKFCgAPr27Yt169Zh6tSpUPz3oq1bt0KtViMwMBDx8fGoW7cuJk6cCGdnZ+zatQt9+vRBxYoVUb9+/SzXdOPGDRw/fhzbtm2DJEkYM2YM7ty5g7L/dW3fv38fTZs2RfPmzbF//344Ozvj6NGjePXqFQBgxYoVGDt2LObPn4+2bdsiJiYmWytBT5o0CYsWLUKFChVQpEgR3L17F+3atcPcuXOhUqmwYcMGBAQEICIiAmXKlAEgll04fvw4lixZgtq1a+PWrVt48uQJFAoFPv74Y6xduxbjx4/XvcfatWvRtGlTVKpUyej6iCzSkydix3LtlVq3buk/f/AgoO3xHTUKmDCBO5CT+ZIog5iYGAmAFBMTk+G5ly9fSpcuXZJevnypOxYfL0kiBuXtLT4+65/p8uXLEgDpwIEDumNNmjSRevfunelr2rdvL40bN073uFmzZtKoUaPe+D5TpkyROnXqpHvcsWNHaebMmbrHkydPlsqXLy+lpKQYfL2np6c0depUg8/dunVLAiCdPXtWd+z58+d6n+vAgQMSAGn79u1vrFOSJKlGjRrS0qVLJUmSpIiICAmAtHfvXoPn3r9/X1IqldLJkyclSZKklJQUydXVVVq3bt1b30duhv7MEr1VQoIkXb8uSc+epR3bsEH/LyGlUpIaNpSkadMkaf9+SeKfMZLZm76/X8chMCtRtWpVNGzYULdv2vXr13H48GEMHDgQAKBWqzFnzhx4eXmhaNGiKFSoEP744w9ERkZm+T3UajXWr1+P3r1764717t0b69atg0ajASCGjZo0aYKCBjYRfPToER48eICWLVvm5KMCAHx8fPQex8fHY/z48ahWrRoKFy6MQoUK4fLly7rPd+7cOSiVSjRr1sxge56enmjfvr3u97dz504kJyejW7duOa6VKM9Ikrji6sWLtGP37oktJD76SMzPqVoVcHERE5UrVQLSD2O3aAF4e4vzd+0SbR09CsyZI17LZRbIgrBv0gQcHID4eHne1xgDBw7EiBEjsHz5cqxduxYVK1bUfeEvXLgQX3/9NUJCQuDl5QVHR0eMHj0aKSkpWW7/jz/+wP379zNMelar1QgLC0OrVq1g/4Zx/zc9B0C3KKaUbumq1NRUg+c6OjrqPR4/fjz27t2LRYsWoVKlSrC3t0fXrl11n+9t7w0AgwYNQp8+fbB48WKsXbsWPXr0gIOx/xGIcoNaLS4z1waQ6Gjg22/FLubpb1FRQFKS2Pl89mxxbmKimKNjiL09kH6OW8mSwNmzuftZiPIIA5AJKBTiH0vmrnv37hg1ahQ2btyIDRs2YOjQobr5QEePHkXHjh11vTcajQZXr15F9erVs9x+aGgoevbsialTp+odnzt3LkJDQ9GqVSvUqlUL69evR2pqaoZeICcnJ5QrVw5hYWF4//33M7RfvHhxAMDDhw9Rp04dANCbEP0mR48eRf/+/dG5c2cAokfodrq9hLy8vKDRaPDXX3/BL/1y+um0a9cOjo6OWLFiBfbs2YNDhw5l6b2Jsi39lVVPnwJbtmQMNA8fisAzdSrw+efi3NhYYNq0zNt9/jztfsmSokfHw0Nciq7d7dzDQ0xi5j5ZlE8xAFmRQoUKoUePHpg8eTJiY2PRv39/3XOVK1fGTz/9hGPHjqFIkSIIDg5GdHR0lgPQ48ePsXPnTuzYsQM1a9bUe65v377o3Lkznj17huHDh2Pp0qXo2bMnJk+eDBcXF5w4cQL169dHlSpVMGvWLHzyySdwc3ND27ZtERcXh6NHj2LEiBGwt7fHe++9h/nz56N8+fJ49OgRpr3pL/l0KleujG3btiEgIAAKhQLTp0/XDcsBQLly5dCvXz98/PHHuknQd+7cwaNHj3Sb7SqVSvTv3x+TJ09G5cqV0YCX7pIpaDTAiRPA778DkZH6AWfYsLRQ8/y5eJyZhw/T7nt6AgMG6IcZ7a1ECf0rsBwdgdeucCSyBgxAVmbgwIEIDQ1Fu3bt4OnpqTuu3WPN398fDg4OGDJkCDp16oSYmJgstbthwwY4OjoanL/TsmVL2Nvb4/vvv8fIkSOxf/9+fPbZZ2jWrBmUSiW8vb3R6L8dnPv164ekpCQsXrwY48ePh6urK7p27apra82aNRg4cCDq1q2LKlWqYMGCBWjduvVb6wsODsbHH3+Mhg0bwtXVFRMnTkRsbKzeOStWrMCUKVPw6aef4unTpyhTpgymTJmS4fc3b948bq5LpnH1qlgT5949w88/eJB238MD6NTJcKDx8ADc3NLOdXQUl6cTUaa4F5gB3AuMMnP48GG0bNkSd+/etZgNdvln1kxIktjvKjparI0DiHk7Hh5ASgoQEADUqqUfbkqVAtJt9kxEb8a9wIhMLDk5GY8fP8asWbPQrVs3iwk/JDNJAsLDgR9/FLfbt4EyZYD27cXcmoIFgX37xJVXDKdEeYoBiCgLNm3ahIEDB8Lb2xsbNmyQuxwyd//8A2zcKELPzZtpxx0dgYYNxSRlFxdxzNtblhKJrB0DEFEW9O/fX2/SOJEe7UwC7RVT33wDLF8u7tvbiyGvHj2Atm2NX7+CiHIFAxARUXZdvJg2vLV6NdCkiTgeGCiuyurRQwx3WcI6GZRtGo1YpSA+XkzbMrDOK5khBqBs4txxshT8s2pily+nhZ5Ll9KO//hjWgBq1EjcyKJpg82DByLPPnigfz/9z/+2M0SBAkCFCsA77wBVquj/LFGCyyqZEwYgI2kX70tMTMzS6sFEckv8b6deQ9uPkBGiooBWrUSvj5atLdCmDdC9u7iKiyxCdoJNVtjaigv6rl4Vt99+03/eyUkEodfDUeXK4jnKWwxARlIqlShcuDAePXoEAHBwcNCtpkxkTiRJQmJiIh49eoTChQtDqVTKXZJluXZN3Nq1E4/d3cXk5YIFgdatxfBWhw5pk5lJdumDjaFAo71vbLApXlysLaldKDv9T+19d3fR+3P/floAiohI+3n7NhAXB5w5I26v8/DI2GNUpQpQrhyH1HIL1wEy4G3rCEiShKioKLxIv6EgkZkqXLgwSpQowaCeFTduAFu3iuGss2eBYsVEz0+B//6tePq02CC0SBF568znJElsURYXJ27x8Wn3tbfo6LwLNra2Of9MycnigsD0oUgblP7797RB2iE1Q+HI3d18h9Q0mrT/bob++8XHA3XqAPXrm/Z9uQ5QLlMoFPDw8ICbm1umm3ESmYOCBQuy5+dt7twRe2z9+KP+P82VSsDHB3j8WHwTAkC9evLUaObSB5bMvuxeP/amc+PjxRdodrm5ZR5oTB1sskqlAqpVE7fXPX8uOhvThyLt/Zcv0469Tjuk9no4ys6QWlYCizHHEhLe/p5Tp5o+ABmDASgHlEolv1yILN033wBBQeK+Ugm0aCHm9HTqBLi6ylqa3PbuFTdD4SX9l11OA0tmFAqgUCHxZa79qb1l1nuT18HGFIoUEUHg9TCg0WR/SM3TMy0UOTiYJrBkh1Kp/99NeytUSKz/KScOgRlgTBcaEVmA1FTg+HHgjz/EbfZscXk6AJw/D4wdK0LPhx+Kb1Yrd/s2MHo08Ouvxr3uTYElO8ccHAAbm9z4hJYvu0Nqb/N6YMnqf7PMjqtUeTtMZ8z3NwOQAQxARPnA9evAn3+KwLN/v/inrlbv3sB338lXm5lKSgIWLgTmzRP3CxQA+vYVu3cwsFiO14fUUlKyHmrs7Mx3XlFWcA4QEVkfjSbt2/fePTERIj1XV3EZu7+/uJGe3buBESPEPHAAeP99YNkyoHp1eesi42U2pEb6GICIyDKp1WJ3dW0vT/HiwC+/iOdKlQK8vMRVXK1bi8Dj7c3uCQNeH+7y9ASCg8WIoCX3BBC9DQMQEVmOu3fTAs++faKvX8vRUfT1a2fAnj0rJjSQQYaGu8aMAaZP56J8ZB0YgIjIfCUliUkJWn37AgcPpj12cQH8/EQvT+vW+pf/MPxkisNdRAxARGRONBrgwoW0Xp5jx4DIyLQrs9q1E5e/aIe16tVLW6SQ3orDXURpeBWYAbwKjCgPPXkC7NkjAs/evWKJ3/S2bgW6dhX3JYnf1NmQlAQsWgTMnZs23DV6NDBjBoe7KH/hVWBEZL6Sk8W6PIUKice7dgH9+6c97+AgxmT8/UVPzzvvpD3H8GM0DncRGcYARES5S5KAK1fShrUOHgTmzAHGjRPPt2olNgXSBp6GDcXqaZQjt2+LSc3bt4vHHh5iuKtHD+ZIIoABiIhyy4kTQGioCD137+o/d/Jk2n1PTyA8PG9ry8c43EWUNQxARGR60dFAkyZpW3OrVEDTpmlXa3l5yVtfPvX6cFfz5mK4q0YNWcsiMksMQESUc69eAYcPiwkmgNiR8uOPxVyfHj1EGHJwkLfGfIzDXUTGYwAiouxLTATWrhVjLrdvA//8A9SsKZ5buZLfvrnM0HDXqFHAzJkc7iJ6GwYgIjLe8+fA8uXAkiXA48fimKurGHvRBiCGn1y1ezcwcqTY8xXgcBeRsRiAiCjrYmLEFVzffJO2u3q5csD48cCAARzmygOGhru++gro2ZOZk8gYDEBElHW2tsB334nw4+UFTJoklhHmasy57vXhLqUy7eourtdKZDz+rUVEmTt5Evj+e+Drr8VO6vb2QEiI2IOrbVt2OeQRDncRmR4DEBHpkySxaOH8+Wkbj7ZoAXTuLO4HBspWmrXhcBdR7mEAIiLh1Svgp5+AL78Ezp0TxwoUAHr3ZldDHtMOd82bB7x8yeEuotzAAERk4e7dE70ET54Adeum3SpVEqNWWRIVBTRqBNy8KR47OgJDhoiGS5fOtdopoz17xGKG2uGuZs3EcJf24joiMg0GICILduYM0KED8OCBeKwdsQJET8G7774hFL16lTZ52d0dKFpUXOU1ahQwbJh4THnG0HDXokVixJHDXUSmp5AkSZK7CHMTGxsLFxcXxMTEwJn9zWSmtm8HevUSaxHWqCEmyZ4/L0LRuXNi0/XXOTsD79ZIRt3UE6h7cyt89gahoreTCEXXr4tvXUfHPP4k1uX5c+DqVSAiQv/n5cti4WylMm0xQ/71Q2QcY76/GYAMYAAicyZJYiLshAnifuvWwI8/iguztFJTgUuXRBg6cwb4+2/g/DkNklMyjoml7yny8RE/K1Y0YviMMkhOFmtCvh5yIiLEUGVmONxFlDMMQDnEAETmKjUV+PRT4NtvxeNPPxVXqL9xGZ7Tp4H585G6bScuoRrOoC7OeATgb6fmOH+nMJKTM46vaEORNhAxFGWk0Yj5V1evZgw5d+6I5zPj6QlUqQK8847+z4oVOdxFlBMMQDnEAETm6PlzoFs3ICxMBJHFi8Vk2Td+YT58KCYxq9XicYcOwMSJQMOGAPR7iv7+W/w8fz7z4bP084msJRRph6xeDznXrokrtDLj5GQ45FSuDBQqlHf1E1kTBqAcYgAic3PjBvDBB8CVK2KKzubN4nEGajVw7JjYfV2rf3/x87PPsnQ5uzGhyMUl40RrSwxF2iErQ3NztFudGVKggPi82oCTPuy4u7M3hyivMQDlEAMQmZOjR4FOncTckVKlgN9+A2rXfu2kpCRg/Xpg4UJxKfulS0DVquI5ScrxN3F2Q1GtWmLxaHMiSSLUpA85t28bP2T1zjtA+fLcBYTInDAA5RADEJmLH34APv4YSEkRgWLnTnGhls61a2JC0Lp1wKNH4lixYsCaNWK4KxdpQ5E2EL0pFFkCDlkRWT4GoBxiACK5SRIwe7a4AWIXiu++S3eFemSk2H19//60F5UuLXZlHzhQtkvZXw9FV66kTT8yJy4uGcMOh6yILB8DUA4xAJGckpJEr8+mTeLxhAlAUBBgkxAnuim0J5UsKWbotmkjVm1u3x4oWFC+womIZGbM9zdHr4nMyKNHYr7P8eNibsnKpakY6PQj8P4qsdxzRISYYWxnJ8bHqlUDypaVu2wiIovDAERkJi5dEp04t28DhZ3V+LnVSrSYOgN49kycYGMD/PNP2gzoNm1kq5WIyNLJfrHq8uXLUa5cOdjZ2cHX1xenTp164/khISGoUqUK7O3tUbp0aYwZMwZJSUm652fNmgWFQqF3q6q9GobITO3dCzRoIMJPRbt7OB5bAy1+Hi7CT5kyYjLQnTsGLv8iIqLskLUHaMuWLRg7dixWrlwJX19fhISEwN/fHxEREXBzc8tw/saNGzFp0iSsWbMGDRs2xNWrV9G/f38oFAoEBwfrzqtRowb27dune1yA16mSGfvm/9QYNlIJtRpo7BWDX/7xhqvyBRDQScztad1abBBFREQmI2syCA4OxuDBgzFgwAAAwMqVK7Fr1y6sWbMGkyZNynD+sWPH0KhRI3z00UcAgHLlyiEwMBAnT57UO69AgQIoUaJE7n8AouxKTIR681ZMmGaL4IeBAIDevYFvVztDtXom0KWLWHyGiIhyhWxDYCkpKThz5gz8/PzSirGxgZ+fH44fP27wNQ0bNsSZM2d0w2Q3b97E77//jnbt2umdd+3aNXh6eqJChQro1asXIiMj31hLcnIyYmNj9W5EueL8eWDYMMSXqIQPBxbWhZ85s9XYsAFQ2SnE/hYMP0REuUq2HqAnT55ArVbD3d1d77i7uzuuXLli8DUfffQRnjx5gsaNG0OSJLx69QqffPIJpkyZojvH19cX69atQ5UqVfDw4UPMnj0bTZo0wcWLF+GkvYT4NUFBQZitXXCFKDds2QIEBwOnTuEeSiIAu3AOdaAq8Arrl8Wjx/8Ky10hEZFVkX0StDEOHjyIefPm4f/+7/8QHh6Obdu2YdeuXZgzZ47unLZt26Jbt26oVasW/P398fvvv+PFixf48ccfM2138uTJiImJ0d3u3r2bFx+H8rv0S2yFhwOnTiG8QD342l/AOdRB8eISDhwqwPBDRCQD2XqAXF1doVQqER0drXc8Ojo60/k706dPR58+fTBo0CAAgJeXFxISEjBkyBBMnToVNgZ2YCxcuDDeeecdXL9+PdNaVCoVVCpVDj4N0X9iY8UKhqtWAfPmAf7+4viQIfg1+j18tLUTEhMVqF4d+O03BcqXl7dcIiJrJVsPkK2tLerWrYuwsDDdMY1Gg7CwMDRo0MDgaxITEzOEHOV/V8dktqB1fHw8bty4AQ+9DZSITEiSgFOngEGDxNydTz4RPT7ffqt7+qvtFdF5Q2ckJirQurXYsJ3hh4hIPrJeBTZ27Fj069cPPj4+qF+/PkJCQpCQkKC7Kqxv374oWbIkgoKCAAABAQEIDg5GnTp14Ovri+vXr2P69OkICAjQBaHx48cjICAAZcuWxYMHDzBz5kwolUoEBgbK9jkpn3r1SvT0rFolJjdrVa0KDB4M9O2L1FRg2DBg9Wrx1CefAEuXcgdxIiK5yfrXcI8ePfD48WPMmDEDUVFR8Pb2xp49e3QToyMjI/V6fKZNmwaFQoFp06bh/v37KF68OAICAjB37lzdOffu3UNgYCCePn2K4sWLo3Hjxjhx4gSKFy+e55+P8jmlEvi//wP+/RdQqYBu3cS6PY0bAwoFXrwAurYFwsLEJpvBwcCoUdxwk4jIHHAzVAO4GSoZlJICrFghunS0XTibNwPR0UCfPkDRorpTb94U21pcuSI2Zt+0CQgIkKluIiIrwc1QiUwtORno3h3YsQO4cAEIDRXHe/bMcOrRo2JD0ydPxIbtv/0GeHvnabVERPQWFnUZPJEskpLEysw7doihru7dMz1140agRQsRfurWFXOjGX6IiMwPAxDRmyQlAZ07A7t2AXZ2ojtHe2l7OpIk9ivt1UuMlHXqBPz1Fxd0JiIyVxwCI8pMYqJIMnv3Ag4OIvy8/36G05KSgIEDRe8PAEyYAAQFAQaWpSIiIjPBAERkiCSJoa69e8Us5t9/B5o2zXDa48ciIx07JuZFr1ghlgMiIiLzxn+jEhmi+G9TUldX4I8/DIafS5cAX18RflxcgD17GH6IiCwFe4CIMuPvD9y6BRQqlOGpffuArl2BmBigQgUxRahqVRlqJCKibGEPEJFWbKxINRERaccMhJ9Vq4A2bUT4adQIOHmS4YeIyNIwABEBwIsXQOvWwM8/ixCk0WQ45cEDYMAA4H//A9RqccVXWJgYJSMiIsvCAET0/DnQqpXoyilaFNiwQe8Srrg4YMYMoHJlYN06cWz2bOC778SyQEREZHk4B4is29OnIvycPSu6cvbtA2rXBiD2Ov32W2DmTODRI3F6gwbAokVAw4Yy1kxERDnGAETW68kTwM9P7ORevDiwfz9QsyYkSSz6PHFi2nSgSpWA+fOBDz/kZqZERPkBAxBZr3HjRPhxdxfhp3p1nDoFjB8PHD4sTnF1FT1A//sfULCgvOUSEZHpMACR9QoJAZ49AxYuxE3bqpjSE9iyRTxlZweMGSN6gVxcZK2SiIhyAQMQWZfERLGtBQAUKYKn63Zi7lxg2TIgNVUMb/XtC8yZA5QuLW+pRESUe3gVGFmP+/eBOnWAr79GUhKwcKGY27N4sQg/2rnQ69Yx/BAR5XfsASLrcPcu8P770Ny4iU1zbmJqsAZ3IkX+r1VLhKHWrWWukYiI8gwDEOV/d+4A77+PA7fKYrztLwh/6gU8BUqWBL74AujTB1Aq5S6SiIjyEgMQ5W+3buHfRkMw8eES7MIHQArg5ARMmgSMHp02HYiIiKwLAxDlWw+P38aMViewJmEPNFCiQAEJ//ufAjNmAG5ucldHRERyYgCifCc+XszpWTS/JBJTAgEAH7Z7iaDF9njnHZmLIyIis8AARPnGq1dAaKhYuDA6GgAKokGFKCxcXBCNOhSTuzwiIjIjDEBk8SQJ2LlTLFp45Yo4VrGi2LqiS5cS3LqCiIgy4DpAZNFOnwaaNwc6dhThp5jiKb4uvxiXTsaha1fu20VERIYxAJFFunULCAwE6tcHDh0C7FQaTLL/GjekChhZ+DvYIkXuEomIyIxxCIwsyrNn0G1dkZIienj6tH+KLw43R+mYi4CPD/Dnn0CRInKXSkREZowBiCxCUpIIPXPnAi9eiGN+fsDC/v/Ce3hjIOYF4OsL7NkDFC4sY6VERGQJGIDIrGk0wObNwJQpYkFnAPDy+m/risKnoPBvDcTEAA0bArt3A87O8hZMREQWgXOAyGwdPCjm+PTqJcKPpyewZo3YsNTfH1A4OgAFCwKNG4ueH4YfIiLKIvYAkdnRaMRaPl98IR47OYlL3MeMeW3ripo1xQzo0qWBQoVkqZWIiCwTAxCZlZcvgf79gR9/FI+HDAHmzEm3dcWhQyIhNW8uHlerJkOVRERk6RiAyGxER4v1fE6eFCNb33wDDBiQ7oQDB4APPhD3Dx8G3n1XljqJiMjyMQCRWbh4UWSbO3fEFezbtqV18gAA9u0DOnQQXURt2rDnh4iIcoSToEl2f/whLuK6cweoVAk4ceK18PPHH0BAgAg/7dsDv/wC2NvLVS4REeUDDEAkqxUrRKaJiwOaNhXhR2/H9t9/Fz0/SUni588/A3Z2stVLRET5AwMQyUKtBkaPBj79VNzv108s4Fws/abtJ08CnTqJJZ87dwa2bgVUKpkqJiKi/IRzgCjPxcUBH30E/PabeDx3LjB5soGNS999F2jXTsyI3rhR/CQiIjIBBiDKU3fviuk858+LkawNG4Bu3TI5uWBBcT28jQ1QgH9UiYjIdDgERnnmzBmxXdf584C7u1jp2WD4uXIFkCRx39aW4YeIiEyOAYjyxC+/AE2aAA8figWcT54UYSiDO3eAunXFTqfaXU+JiIhMjAGIcpUkiY1Lu3RJW8Ln6FGgbNlMTh4+HEhMBF69Alxc8rxeIiKyDgxAlGtSU8VWFhMmiGwzbBiwc+cb9izdvl3MjC5YUFwfn2FWNBERkWlwcgXliufPga5dgf37xRzmkBBgxIg3vCAuLu2Ezz4DqlfPizKJiMhKMQCRyd24IRY3jIgQm7Rv3iwev9GMGcD9+0CFCsC0aXlSJxERWS8GIDKpI0fE2oVPnwKlSokRrdq13/Ki8HBgyRJxf/lybnNBRES5jgGITOb774GBA8XCzT4+wI4dgIdHFl6oVgNVqgBeXmKWNBERUS5jAKIckyRg5kxgzhzx+MMPge++AxwcsthAvXrAuXPi6i8iIqI8wABEOZKUBAwYIOb5AMDEicC8eWLis1FsbcWNiIgoDzAAUbY9eiTm+xw/LhZrXrVKhKEsGzQIqFwZGDuW+3wREVGeYgCibPn3X+CDD4Dbt4EiRYCffwbef9+IBv78EwgNFV1FbdsCtWrlVqlEREQZcCFEMtqffwING4rwU7Gi6AEyKvy8fAkMHSrujxzJ8ENERHmOAYiMsnIl0K4dEBsr9vY6cUJcwGWUuXOBmzeBkiWBzz/PlTqJiIjehAGIskStFlN1hg4V9/v2BfbuBVxdjWzo8mVgwQJxf8kSwMnJ5LUSERG9DecA0VvFxwMffST28QKAL74ApkzJxlZdkiQSVGqqmEDUubPJayUiIsoKBiB6o3v3gIAAsUyPSgVs2AB0757Nxs6fB44dEwsELVvGzU6JiEg2DECUqTNngA4dgAcPADc34Ndfgffey0GD3t7AhQvAP/8AZcuaqkwiIiKjyT4HaPny5ShXrhzs7Ozg6+uLU6dOvfH8kJAQVKlSBfb29ihdujTGjBmDpKSkHLVJGW3fDjRtKsJPjRrAyZM5DD9aVasC3bqZoCEiIqLsMzoAlStXDp9//jkiIyNz/OZbtmzB2LFjMXPmTISHh6N27drw9/fHo0ePDJ6/ceNGTJo0CTNnzsTly5cRGhqKLVu2YMqUKdluk/RJEvDVV2I7i8REoHVr4OhRoFy5HDR66hTw99+mKpGIiCjnJCMtXrxYql27tqRUKiU/Pz9p06ZNUlJSkrHNSJIkSfXr15eGDRume6xWqyVPT08pKCjI4PnDhg2TWrRooXds7NixUqNGjbLdpiExMTESACkmJibLr8kPUlIkafBgSRIxSJI+/VSSUlNz2GhysiRVqyZJCoUkbd5skjqJiIgMMeb72+geoNGjR+PcuXM4deoUqlWrhhEjRsDDwwPDhw9HeHh4lttJSUnBmTNn4OfnpztmY2MDPz8/HD9+3OBrGjZsiDNnzuiGtG7evInff/8d7dq1y3abAJCcnIzY2Fi9m7V58UIsyLx6tVic+euvxTzlAjmdJbZokbj0vXhx0Z1ERERkBrI9B+jdd9/FkiVL8ODBA8ycORPffvst6tWrB29vb6xZswaSJL3x9U+ePIFarYa7u7vecXd3d0RFRRl8zUcffYTPP/8cjRs3RsGCBVGxYkU0b95cNwSWnTYBICgoCC4uLrpb6dKls/IryDdu3gQaNADCwgBHRzHZeeRIE1ykdeNG2hbxwcFizwwiIiIzkO0AlJqaih9//BEdOnTAuHHj4OPjg2+//RZdunTBlClT0KtXL1PWCQA4ePAg5s2bh//7v/9DeHg4tm3bhl27dmGO9ks2myZPnoyYmBjd7e7duyaq2Py9egW0aQNcuQKUKiXm+3zwgQkaliRg2DCxXXzLlmIhISIiIjNh9ABHeHg41q5di02bNsHGxgZ9+/bF4sWLUbVqVd05nTt3Rr169d7YjqurK5RKJaKjo/WOR0dHo0SJEgZfM336dPTp0weDBg0CAHh5eSEhIQFDhgzB1KlTs9UmAKhUKqhUqjfWm1/99BNw7ZpY0fnkScDT00QNb90K/PEHYGsL/N//cc0fIiIyK0b3ANWrVw/Xrl3DihUrcP/+fSxatEgv/ABA+fLl0bNnzze2Y2tri7p16yIsLEx3TKPRICwsDA0aNDD4msTERNjY6JesVCoBAJIkZatNayZJwJdfivsjRpgw/MTGAqNGiftTpgDvvGOihomIiEzD6B6gmzdvouxbFrFzdHTE2rVr39rW2LFj0a9fP/j4+KB+/foICQlBQkICBgwYAADo27cvSpYsiaCgIABAQEAAgoODUadOHfj6+uL69euYPn06AgICdEHobW1Smr17xQrPDg5itMpkChUCZs8G1q4FJk0yYcNERESmYXQAevToEaKiouDr66t3/OTJk1AqlfDx8clyWz169MDjx48xY8YMREVFwdvbG3v27NFNYo6MjNTr8Zk2bRoUCgWmTZuG+/fvo3jx4ggICMDcuXOz3CalmT9f/Bw8GChWzIQN29gAQ4aIhjn0RUREZkghve1yrdfUr18fEyZMQNeuXfWOb9u2DV9++SVOnjxp0gLlEBsbCxcXF8TExMDZ2VnucnLF6dNA/friMvcbN4AyZUzQ6KtXQHKyuJSMiIgojxnz/W30HKBLly7h3XffzXC8Tp06uHTpkrHNkUy0c38CA00UfgCxcFD16sDu3SZqkIiIKHcYHYBUKlWGq6wA4OHDhyiQ41XzKC9cvQps2ybuT5hgokbv3QOmTwciIwErWkaAiIgsk9EBqHXr1rp1c7RevHiBKVOmoFWrViYtjnLHokXiCrD27YGaNU3U6MiRQHw80LAh8N8yBURERObK6DlA9+/fR9OmTfH06VPUqVMHAHDu3Dm4u7tj7969+WIV5fw8B+jhQ7GxaUoKcOgQ0KSJCRrduRPo0EFMKAoPB7y8TNAoERGRcYz5/jZ6zKpkyZK4cOECfvjhB5w/fx729vYYMGAAAgMDUbBgwWwXTXnj669F+GnQAGjc2AQNJiQAw4eL+2PHMvwQEZFFMLoHyBrk1x6gmBgx4Tk2Fti+HejY0QSNTpwILFgAlC0L/PsvrwAjIiLZ5GoPkNalS5cQGRmJlJQUveMdOnTIbpOUy775RoSfatWAgAATNChJaROely1j+CEiIouRrZWgO3fujH/++QcKhUK367vivwXv1Gq1aSskk0hOBkJCxP0JE8RahTmmUAAbN4qhLyMWwCQiIpKb0V+Do0aNQvny5fHo0SM4ODjg33//xaFDh+Dj44ODBw/mQolkCt99JyZAlyqVCxuzM/wQEZGFMToAHT9+HJ9//jlcXV1hY2MDGxsbNG7cGEFBQRg5cmRu1Eg5pFYDCxeK+2PGiA3acyQ6WlzqHhWV49qIiIjkYHQAUqvVcHJyAgC4urriwYMHAICyZcsiIiLCtNWRSfz6q1j8sHBhsT1Xjo0bB4SG5kJXEhERUd4weg5QzZo1cf78eZQvXx6+vr5YsGABbG1tsWrVKlSoUCE3aqQckKS0bS+GDQP+y67ZFxYG/PCDmP+jbZiIiMjCGB2Apk2bhoSEBADA559/jg8++ABNmjRBsWLFsGXLFpMXSDnz11/AqVOAnZ1YrDlHkpKAoUPF/WHDgHr1clwfERGRHIwOQP7+/rr7lSpVwpUrV/Ds2TMUKVJEdyUYmQ9tJ82AAYCbWw4bmz8fuHYN8PAAvvgix7URERHJxag5QKmpqShQoAAuXryod7xo0aIMP2bo/Hlgzx5xyfv48TlsLCICCAoS90NCABeXnJZHREQkG6MCUMGCBVGmTBmu9WMhFiwQP7t1A3I8PWv2bLGHRps2okEiIiILZvRVYFOnTsWUKVPw7Nmz3KiHTOT2bUA7JWviRBM0+M034hr65cvFBGgiIiILZvQcoGXLluH69evw9PRE2bJl4fja9gfh4eEmK46y76uvxPo/rVoBdeqYoEEnJyA42AQNERERyc/oANSpU6dcKINM6fFjsUwPYILen2PHxNbx7PUhIqJ8xOgANHPmzNyog0xo2TLg5Uugbl2gRYscNHTsGNCoEdCsGfDnnyZYQpqIiMg8mGJLTDIjCQkiAAGi9yfbHTepqcD//ifuV6zI8ENERPmK0T1ANjY2b7zknVeIyevbb4Fnz4BKlYAPP8xBQ4sXAxcvAsWKccVnIiLKd4wOQL/88ove49TUVJw9exbr16/H7NmzTVYYGS81NW2e8vjxgFKZzYZu3wZmzRL3Fy0CXF1NUB0REZH5UEiSJJmioY0bN2LLli349ddfTdGcrGJjY+Hi4oKYmBg4OzvLXU6Wffcd0Lcv4O4uMoydXTYakSSgQwfgt9/E3J8DBzgBmoiILIIx398mmwP03nvvISwszFTNkZEkKW3hw1Gjshl+AOCXX0T4KVgQWLGC4YeIiPIlo4fADHn58iWWLFmCkiVLmqI5yobffxdTdpyc0vYrzZZSpYBatYCAAKBaNZPVR0REZE6MDkCvb3oqSRLi4uLg4OCA77//3qTFUdZp5yn/739A4cI5aKh+feDvvwGNxhRlERERmSWjA9DixYv1ApCNjQ2KFy8OX19fFClSxKTFUdYcPw4cPixGrUaPzmYjGo3YNRUQDREREeVjRgeg/v3750IZlBPa3p8+fYBsjUKq1cD774t9MyZMAFQqk9ZHRERkboyeBL127Vps3bo1w/GtW7di/fr1JimKsu7yZeDXX8Vc5c8+y2YjK1eKLqRFi8QiQkRERPmc0QEoKCgIrgbWhXFzc8O8efNMUhRl3cKF4mfHjkDVqtloQJKAuXPF/aAgwMPDZLURERGZK6MDUGRkJMqXL5/heNmyZREZGWmSoihr7t0DtPPOs73p6dWrwMOHYthr4ECT1UZERGTOjA5Abm5uuHDhQobj58+fR7FixUxSFGVNSIhY/blpU+C997LZyOHD4ud773HuDxERWQ2jA1BgYCBGjhyJAwcOQK1WQ61WY//+/Rg1ahR69uyZGzWSAc+fA998I+5nu/cHAA4dEj+bNs1xTURERJbC6KvA5syZg9u3b6Nly5YoUEC8XKPRoG/fvpwDlIdWrADi4wEvL6Bt2xw0xABERERWKNt7gV27dg3nzp2Dvb09vLy8ULZsWVPXJhtz3wvs5UugXDng0SOx/1fv3tlsKCVF7Jp65IgIQoUKmbJMIiKiPGXM97fJNkPNT8w9AK1cKba7KFMGuH6d6xYSEREBubwZapcuXfClduW9dBYsWIBu3boZ2xwZSa0Wy/UAwLhxDD9ERETZYXQAOnToENq1a5fheNu2bXFIO5+Ecs3PPwM3bgDFipngqvWTJ4GkJJPURUREZEmMDkDx8fGwtbXNcLxgwYKIjY01SVFkmCSlbXsxfDjg6JiDxqKjxaXvRYqI2dRERERWxOgA5OXlhS1btmQ4vnnzZlSvXt0kRZFhYWFAeDhgby8CUI5o1/955x1OfiYiIqtj9GXw06dPx4cffogbN26gRYsWAICwsDBs3LgRP/30k8kLpDTa3p9BgwADu5EYh5e/ExGRFTM6AAUEBGD79u2YN28efvrpJ9jb26N27drYv38/ihYtmhs1EoAzZ4B9+wClEhg71gQNMgAREZEVMzoAAUD79u3Rvn17AOKSs02bNmH8+PE4c+YM1Gq1SQskYcEC8bNnT7EGUI48fw5otzNp0iSHjREREVkeo+cAaR06dAj9+vWDp6cnvvrqK7Ro0QInTpwwZW30nxs3AO3o4oQJJmjw6FExo7pyZaBECRM0SEREZFmM6gGKiorCunXrEBoaitjYWHTv3h3JycnYvn07J0DnokWLAI1GbHlRq5YJGuTwFxERWbks9wAFBASgSpUquHDhAkJCQvDgwQMsXbo0N2sjiKvV164V93O06Wl6/foBX30F9OplogaJiIgsS5Z7gHbv3o2RI0di6NChqFy5cm7WROksWQIkJ4sle0zWYVOjhrgRERFZqSz3AB05cgRxcXGoW7cufH19sWzZMjx58iQ3a7N6cXHA//2fuD9xIqBQyFsPERFRfpHlAPTee+9h9erVePjwIf73v/9h8+bN8PT0hEajwd69exEXF5ebdVqlVauAFy+AqlWBDh1M1OiOHcCGDcDDhyZqkIiIyPIYfRWYo6MjPv74Yxw5cgT//PMPxo0bh/nz58PNzQ0dTPYtTSkpwOLF4v5nnwE22b5e7zWLF4s5QDt3mqhBIiIiy5Ojr9UqVapgwYIFuHfvHjZt2mSqmgjADz8A9+8Dnp4mnKucnAxolyrgFWBERGTFTNKvoFQq0alTJ+zYscMUzVk9jSZt4cMxYwCVykQN//232P29eHGgShUTNUpERGR5TDWwQia0cydw5Qrg4gIMGWLChtOv/8MZ1UREZMUYgMyMJKVtevrpp4Czswkb1+4Az+EvIiKycgxAZubIEeD4cTHsNWqUCRtWq0XjAAMQERFZPbMIQMuXL0e5cuVgZ2cHX19fnDp1KtNzmzdvDoVCkeGm3ZwVAPr375/h+TZt2uTFR8kxbe9P//6Au7sJG758WSws5OICeHmZsGEiIiLLk63d4E1py5YtGDt2LFauXAlfX1+EhITA398fERERcHNzy3D+tm3bkJKSonv89OlT1K5dG926ddM7r02bNlir3UMCgMpkM4lzzz//ALt2iUvex483ceM1a4p9Na5dA5RKEzdORERkWWQPQMHBwRg8eDAGDBgAAFi5ciV27dqFNWvWYNKkSRnOL1q0qN7jzZs3w8HBIUMAUqlUKJHFnc6Tk5ORnJysexwbG2vsxzAJ7ZVfXboAlSrlwhu4uYkbERGRlZN1CCwlJQVnzpyBn5+f7piNjQ38/Pxw/PjxLLURGhqKnj17wtHRUe/4wYMH4ebmhipVqmDo0KF4+vRppm0EBQXBxcVFdytdunT2PlAO3LkDaJdSMtmmp0RERGSQrAHoyZMnUKvVcH9tsou7uzuioqLe+vpTp07h4sWLGDRokN7xNm3aYMOGDQgLC8OXX36Jv/76C23btoVarTbYzuTJkxETE6O73b17N/sfKpuCg8U85ZYtgbp1Tdz4lSuAnx+wcKGJGyYiIrJMsg+B5URoaCi8vLxQv359veM9e/bU3ffy8kKtWrVQsWJFHDx4EC1btszQjkqlknWO0NOnwLffivu50vtz8CAQFibuf/ZZLrwBERGRZZG1B8jV1RVKpRLR0dF6x6Ojo986fychIQGbN2/GwIED3/o+FSpUgKurK65fv56jenPLsmVAYiJQp47oqDG59AsgEhERkbwByNbWFnXr1kWYtncCgEajQVhYGBo0aPDG127duhXJycno3bv3W9/n3r17ePr0KTw8PHJcs6klJABLl4r7EyfmwgLNkpQWgJo0MXHjRERElkn2dYDGjh2L1atXY/369bh8+TKGDh2KhIQE3VVhffv2xeTJkzO8LjQ0FJ06dUKxYsX0jsfHx+Ozzz7DiRMncPv2bYSFhaFjx46oVKkS/P398+QzGWPNGjEEVqGCuPrL5G7dEruqFiwI+PrmwhsQERFZHtnnAPXo0QOPHz/GjBkzEBUVBW9vb+zZs0c3MToyMhI2Nvo5LSIiAkeOHMGff/6ZoT2lUokLFy5g/fr1ePHiBTw9PdG6dWvMmTPH7NYCSk0FvvpK3B8/HiiQG/81tL0/9eoBDg658AZERESWRyFJkiR3EeYmNjYWLi4uiImJgbNJN+PS98MPQO/eYmme27cBe/tceJOPPwbWrgUmTQKCgnLhDYiIiMyDMd/fsg+BWStJSlv4cOTIXAo/gOhWcnLi/B8iIqJ02ANkQF70AO3eDbRrBxQqBERGAkWK5MrbCK9eiZ+5MsZGRERkHoz5/uY3oky0m54OGZLL4Qdg8CEiInoNh8BkcPIk8Ndf4sKsMWNy8Y0SEnKxcSIiIsvFACQDbe9Pr15AqVK5+EbvvQdUrgyEh+fimxAREVkejo3ksYgIYPt2cX/ChFx8o6dPgYsXxX0ZNnclIiIyZ+wBymMLF4orwDp0AKpVy8U3OnJE/KxeHShePBffiIiIyPIwAOWhBw+A774T93Nl09P0uP0FERFRphiA8lBICJCSAjRuDDRsmMtvxg1QiYiIMsU5QHmoc2fg8mXgk09y+Y3i4tImPrMHiIiIKAMGoDzUoAGwc2cevNGxY4BGA5QvzwnQREREBjAA5UclSohuJk5+JiIiMogBKD+qXRtYsULuKoiIiMwWJ0ETERGR1WEAym/u3AGOHxeXmxEREZFBDED5zYYN4hr7AQPkroSIiMhsMQDlN9r1fxo1krcOIiIiM8YAlJ+kpopL4AEugEhERPQGDED5ydmzQGIiUKSI2AOMiIiIDGIAyk/S7/9lw/+0REREmeG3ZH7C/b+IiIiyhAEov9BogMOHxX0GICIiojfiStD5ya5dIgTVqSN3JURERGaNASi/sLER6/80bCh3JURERGaPQ2BERERkdRiA8gNJAj77DNi0CUhKkrsaIiIis8chsPzg+nVg0SJApQI6d5a7GiIiIrPHHqD8QHv5u68vYGcnby1EREQWgAEoP+D6P0REREZhAMoPGICIiIiMwgBk6SIjgdu3AaUSaNBA7mqIiIgsAgOQpdOu/vzuu0ChQvLWQkREZCEYgCzdxYviJ4e/iIiIsoyXwVu6oCBg+HC5qyAiIrIoDED5QcmScldARERkUTgERkRERFaHAciSTZsGtGsH/Pmn3JUQERFZFAYgS7ZrF7B7N/DihdyVEBERWRQGIEv14gVw/ry436SJrKUQERFZGgYgS3X0qNgFvnJlwMND7mqIiIgsCgOQpdJuf8HeHyIiIqMxAFkq7v9FRESUbQxAligxEfj7b3GfAYiIiMhoXAjREj1+LILPvXtAuXJyV0NERGRxGIAsUdmyQFgYoNEACoXc1RAREVkcDoFZMhv+5yMiIsoOfoNamlevxBAYERERZRsDkKU5fRpwcwOaN5e7EiIiIovFAGRptJe/Fysmbx1EREQWjAHI0nD9HyIiohxjALIkajVw5Ii4zwBERESUbQxAluTCBSA2FnB2BmrVkrsaIiIii8UAZEm0w1+NGwNKpby1EBERWTAGIEvC+T9EREQmwZWgLUlgIFC4MNCqldyVEBERWTSz6AFavnw5ypUrBzs7O/j6+uLUqVOZntu8eXMoFIoMt/bt2+vOkSQJM2bMgIeHB+zt7eHn54dr167lxUfJXV27AqGhwLvvyl0JERGRRZM9AG3ZsgVjx47FzJkzER4ejtq1a8Pf3x+PHj0yeP62bdvw8OFD3e3ixYtQKpXo1q2b7pwFCxZgyZIlWLlyJU6ePAlHR0f4+/sjKSkprz4WERERmTGFJEmSnAX4+vqiXr16WLZsGQBAo9GgdOnSGDFiBCZNmvTW14eEhGDGjBl4+PAhHB0dIUkSPD09MW7cOIwfPx4AEBMTA3d3d6xbtw49e/Z8a5uxsbFwcXFBTEwMnJ2dc/YBTeX33wF3d6B2baAARy6JiIheZ8z3t6w9QCkpKThz5gz8/Px0x2xsbODn54fjx49nqY3Q0FD07NkTjo6OAIBbt24hKipKr00XFxf4+vpm2mZycjJiY2P1bmZFkoAhQwAfn7SJ0ERERJRtsgagJ0+eQK1Ww93dXe+4u7s7oqKi3vr6U6dO4eLFixg0aJDumPZ1xrQZFBQEFxcX3a106dLGfpTcdfs2cP++6Pl57z25qyEiIrJ4ss8ByonQ0FB4eXmhfv36OWpn8uTJiImJ0d3u3r1rogpNRNvrU68e4OAgby1ERET5gKwByNXVFUqlEtHR0XrHo6OjUaJEiTe+NiEhAZs3b8bAgQP1jmtfZ0ybKpUKzs7OejezwvV/iIiITErWAGRra4u6desiLCxMd0yj0SAsLAwNGjR442u3bt2K5ORk9O7dW+94+fLlUaJECb02Y2NjcfLkybe2abYYgIiIiExK9suJxo4di379+sHHxwf169dHSEgIEhISMGDAAABA3759UbJkSQQFBem9LjQ0FJ06dUKxYsX0jisUCowePRpffPEFKleujPLly2P69Onw9PREp06d8upjmc6DB8D164BCATRsKHc1RERE+YLsAahHjx54/PgxZsyYgaioKHh7e2PPnj26ScyRkZGwsdHvqIqIiMCRI0fw559/GmxzwoQJSEhIwJAhQ/DixQs0btwYe/bsgZ2dXa5/HpM7fFj8rF1brAJNREREOSb7OkDmyKzWAXr5Ejh1Svxs00beWoiIiMyYMd/fsvcA0VvY2wPNmsldBRERUb5i0ZfBExEREWUHA5A5O3QIGDUK2LdP7kqIiIjyFQ6BmbOdO4ElS4CkJCDd1h5ERESUM+wBMmdc/4eIiChXMACZq/h44MwZcZ8BiIiIyKQYgMzV8eOAWg2UKweY2+asREREFo4ByFxx+IuIiCjXMACZKwYgIiKiXMMAZI40GuDhQ3GfAYiIiMjkeBm8ObKxASIigDt3gLJl5a6GiIgo32EAMlcKhZgATURERCbHITBzxP1piYiIchUDkLl59Ur0/HTsCDx7Jnc1RERE+RKHwMzN2bNAZCQQFwcULix3NURERPkSe4DMjfby9yZNxGRoIiIiMjl+w5obrv9DRESU6xiAzIlGAxw+LO4zABEREeUaBiBz8u+/wPPngKMjUKeO3NUQERHlWwxA5kQ7/NWoEVCA89OJiIhyCwOQOXF1FZOf/fzkroSIiChfYzeDOenRQ9yIiIgoV7EHiIiIiKwOA5C5uHtXTIAmIiKiXMcAZC6mTQOKFQO+/lruSoiIiPI9BiBzceiQ2AS1alW5KyEiIsr3GIDMwd27wO3bYuuLhg3lroaIiCjfYwAyB9rVn999F3BykrcWIiIiK8AAZA64/xcREVGeYgAyBwxAREREeYoBSG6PHwOXL4v7jRvLWwsREZGV4ErQclOpgFWrgBs3xGXwRERElOsYgOTm7AwMHix3FURERFaFQ2BERERkdRiA5BQbCyxbBly4IHclREREVoVDYHI6ehQYMQKoVAm4dk3uaoiIiKwGe4DkxMvfiYiIZMEAJCcGICIiIlkwAMklMRE4fVrcZwAiIiLKUwxAcjl5EkhNBUqVAsqVk7saIiIiq8IAJJf0w18Khby1EBERWRkGILkcOSJ+cviLiIgoz/EyeLn88gtw/DhQs6bclRAREVkdBiC5FCoEtGoldxVERERWiUNgREREZHXYAySH8ePFxOdPPgEqVpS7GiIiIqvDAJTX1Gpg9WqxD1hgoNzVEBERWSUOgeW1CxdE+HFyAmrXlrsaIiIiq8QAlNe06/80agQolfLWQkREZKUYgPLa4cPiJ9f/ISIikg0DUF6SJG6ASkREZAYYgPJSRATw+DFgZwf4+MhdDRERkdXiVWB56d49oEQJoGpVQKWSuxoiIiKrxQCUl/z8gAcPgJgYuSshIiKyahwCy2sKBVC4sNxVEBERWTUGICIiIrI6sgeg5cuXo1y5crCzs4Ovry9OnTr1xvNfvHiBYcOGwcPDAyqVCu+88w5+//133fOzZs2CQqHQu1WtWjW3PwYRERFZEFnnAG3ZsgVjx47FypUr4evri5CQEPj7+yMiIgJubm4Zzk9JSUGrVq3g5uaGn376CSVLlsSdO3dQ+LUhpRo1amDfvn26xwUKcKoTERERpZE1GQQHB2Pw4MEYMGAAAGDlypXYtWsX1qxZg0mTJmU4f82aNXj27BmOHTuGggULAgDKlSuX4bwCBQqgRIkSWa4jOTkZycnJusexsbFGfhIiIiKyJLINgaWkpODMmTPw8/NLK8bGBn5+fjh+/LjB1+zYsQMNGjTAsGHD4O7ujpo1a2LevHlQq9V65127dg2enp6oUKECevXqhcjIyDfWEhQUBBcXF92tdOnSOf+AREREZLZkC0BPnjyBWq2Gu7u73nF3d3dERUUZfM3Nmzfx008/Qa1W4/fff8f06dPx1Vdf4YsvvtCd4+vri3Xr1mHPnj1YsWIFbt26hSZNmiAuLi7TWiZPnoyYmBjd7e7du6b5kERERGSWLGpyjEajgZubG1atWgWlUom6devi/v37WLhwIWbOnAkAaNu2re78WrVqwdfXF2XLlsWPP/6IgQMHGmxXpVJBxYUJiYiIrIZsAcjV1RVKpRLR0dF6x6OjozOdv+Ph4YGCBQtCmW4X9WrVqiEqKgopKSmwtbXN8JrChQvjnXfewfXr1037AYiIiMhiyTYEZmtri7p16yIsLEx3TKPRICwsDA0aNDD4mkaNGuH69evQaDS6Y1evXoWHh4fB8AMA8fHxuHHjBjw8PEz7AYiIiMhiyboO0NixY7F69WqsX78ely9fxtChQ5GQkKC7Kqxv376YPHmy7vyhQ4fi2bNnGDVqFK5evYpdu3Zh3rx5GDZsmO6c8ePH46+//sLt27dx7NgxdO7cGUqlEoGBgXn++YiIiMg8yToHqEePHnj8+DFmzJiBqKgoeHt7Y8+ePbqJ0ZGRkbCxSctopUuXxh9//IExY8agVq1aKFmyJEaNGoWJEyfqzrl37x4CAwPx9OlTFC9eHI0bN8aJEydQvHjxPP98REREZJ4UkiRJchdhbmJjY+Hi4oKYmBg4OzvLXQ4RERFlgTHf37JvhUFERESU1xiAiIiIyOpY1DpAeUU7KsgtMYiIiCyH9ns7K7N7GIAM0K4azS0xiIiILE9cXBxcXFzeeA4nQRug0Wjw4MEDODk5QaFQyF1OrouNjUXp0qVx9+5dTvp+C/6uso6/K+Pw95V1/F1lnbX9riRJQlxcHDw9PfWuIjeEPUAG2NjYoFSpUnKXkeecnZ2t4n8QU+DvKuv4uzIOf19Zx99V1lnT7+ptPT9anARNREREVocBiIiIiKwOAxBBpVJh5syZUKlUcpdi9vi7yjr+rozD31fW8XeVdfxdZY6ToImIiMjqsAeIiIiIrA4DEBEREVkdBiAiIiKyOgxAREREZHUYgKxYUFAQ6tWrBycnJ7i5uaFTp06IiIiQuyyLMH/+fCgUCowePVruUszS/fv30bt3bxQrVgz29vbw8vLC33//LXdZZketVmP69OkoX7487O3tUbFiRcyZMydL+xhZg0OHDiEgIACenp5QKBTYvn273vOSJGHGjBnw8PCAvb09/Pz8cO3aNXmKldmbflepqamYOHEivLy84OjoCE9PT/Tt2xcPHjyQr2AzwABkxf766y8MGzYMJ06cwN69e5GamorWrVsjISFB7tLM2unTp/HNN9+gVq1acpdilp4/f45GjRqhYMGC2L17Ny5duoSvvvoKRYoUkbs0s/Pll19ixYoVWLZsGS5fvowvv/wSCxYswNKlS+UuzSwkJCSgdu3aWL58ucHnFyxYgCVLlmDlypU4efIkHB0d4e/vj6SkpDyuVH5v+l0lJiYiPDwc06dPR3h4OLZt24aIiAh06NBBhkrNiET0n0ePHkkApL/++kvuUsxWXFycVLlyZWnv3r1Ss2bNpFGjRsldktmZOHGi1LhxY7nLsAjt27eXPv74Y71jH374odSrVy+ZKjJfAKRffvlF91ij0UglSpSQFi5cqDv24sULSaVSSZs2bZKhQvPx+u/KkFOnTkkApDt37uRNUWaIPUCkExMTAwAoWrSozJWYr2HDhqF9+/bw8/OTuxSztWPHDvj4+KBbt25wc3NDnTp1sHr1arnLMksNGzZEWFgYrl69CgA4f/48jhw5grZt28pcmfm7desWoqKi9P5fdHFxga+vL44fPy5jZZYhJiYGCoUChQsXlrsU2XAzVAIAaDQajB49Go0aNULNmjXlLscsbd68GeHh4Th9+rTcpZi1mzdvYsWKFRg7diymTJmC06dPY+TIkbC1tUW/fv3kLs+sTJo0CbGxsahatSqUSiXUajXmzp2LXr16yV2a2YuKigIAuLu76x13d3fXPUeGJSUlYeLEiQgMDLSaDVINYQAiAKJn4+LFizhy5IjcpZilu3fvYtSoUdi7dy/s7OzkLsesaTQa+Pj4YN68eQCAOnXq4OLFi1i5ciUD0Gt+/PFH/PDDD9i4cSNq1KiBc+fOYfTo0fD09OTvinJFamoqunfvDkmSsGLFCrnLkRWHwAjDhw/Hb7/9hgMHDqBUqVJyl2OWzpw5g0ePHuHdd99FgQIFUKBAAfz1119YsmQJChQoALVaLXeJZsPDwwPVq1fXO1atWjVERkbKVJH5+uyzzzBp0iT07NkTXl5e6NOnD8aMGYOgoCC5SzN7JUqUAABER0frHY+OjtY9R/q04efOnTvYu3evVff+AAxAVk2SJAwfPhy//PIL9u/fj/Lly8tdktlq2bIl/vnnH5w7d0538/HxQa9evXDu3DkolUq5SzQbjRo1yrCcwtWrV1G2bFmZKjJfiYmJsLHR/2tYqVRCo9HIVJHlKF++PEqUKIGwsDDdsdjYWJw8eRINGjSQsTLzpA0/165dw759+1CsWDG5S5Idh8Cs2LBhw7Bx40b8+uuvcHJy0o2bu7i4wN7eXubqzIuTk1OGuVGOjo4oVqwY50y9ZsyYMWjYsCHmzZuH7t2749SpU1i1ahVWrVold2lmJyAgAHPnzkWZMmVQo0YNnD17FsHBwfj444/lLs0sxMfH4/r167rHt27dwrlz51C0aFGUKVMGo0ePxhdffIHKlSujfPnymD59Ojw9PdGpUyf5ipbJm35XHh4e6Nq1K8LDw/Hbb79BrVbr/r4vWrQobG1t5SpbXnJfhkbyAWDwtnbtWrlLswi8DD5zO3fulGrWrCmpVCqpatWq0qpVq+QuySzFxsZKo0aNksqUKSPZ2dlJFSpUkKZOnSolJyfLXZpZOHDggMG/o/r16ydJkrgUfvr06ZK7u7ukUqmkli1bShEREfIWLZM3/a5u3bqV6d/3Bw4ckLt02SgkiUuOEhERkXXhHCAiIiKyOgxAREREZHUYgIiIiMjqMAARERGR1WEAIiIiIqvDAERERERWhwGIiIiIrA4DEBEREVkdBiAioixQKBTYvn273GUQkYkwABGR2evfvz8UCkWGW5s2beQujYgsFDdDJSKL0KZNG6xdu1bvmEqlkqkaIrJ07AEiIougUqlQokQJvVuRIkUAiOGpFStWoG3btrC3t0eFChXw008/6b3+n3/+QYsWLWBvb49ixYphyJAhiI+P1ztnzZo1qFGjBlQqFTw8PDB8+HC95588eYLOnTvDwcEBlStXxo4dO3L3QxNRrmEAIqJ8Yfr06ejSpQvOnz+PXr16oWfPnrh8+TIAICEhAf7+/ihSpAhOnz6NrVu3Yt++fXoBZ8WKFRg2bBiGDBmCf/75Bzt27EClSpX03mP27Nno3r07Lly4gHbt2qFXr1549uxZnn5OIjIRubejJyJ6m379+klKpVJydHTUu82dO1eSJEkCIH3yySd6r/H19ZWGDh0qSZIkrVq1SipSpIgUHx+ve37Xrl2SjY2NFBUVJUmSJHl6ekpTp07NtAYA0rRp03SP4+PjJQDS7t27TfY5iSjvcA4QEVmE999/HytWrNA7VrRoUd39Bg0a6D3XoEEDnDt3DgBw+fJl1K5dG46OjrrnGzVqBI1Gg4iICCgUCjx48AAtW7Z8Yw21atXS3Xd0dISzszMePXqU3Y9ERDJiACIii+Do6JhhSMpU7O3ts3RewYIF9R4rFApoNJrcKImIchnnABFRvnDixIkMj6tVqwYAqFatGs6fP4+EhATd80ePHoWNjQ2qVKkCJycnlCtXDmFhYXlaMxHJhz1ARGQRkpOTERUVpXesQIECcHV1BQBs3boVPj4+aNy4MX744QecOnUKoaGhAIBevXph5syZ6NevH2bNmoXHjx9jxIgR6NOnD9zd3QEAs2bNwieffAI3Nze0bdsWcXFxOHr0KEaMGJG3H5SI8gQDEBFZhD179sDDw0PvWJUqVXDlyhUA4gqtzZs349NPP4WHhwc2bdqE6tWrAwAcHBzwxx9/YNSoUahXrx4cHBzQpUsXBAcH69rq168fkpKSsHjxYowfPx6urq7o2rVr3n1AIspTCkmSJLmLICLKCYVCgV9++QWdOnWSuxQishCcA0RERERWhwGIiIiIrA7nABGRxeNIPhEZiz1AREREZHUYgIiIiMjqMAARERGR1WEAIiIiIqvDAERERERWhwGIiIiIrA4DEBEREVkdBiAiIiKyOv8P+Hhh2Dc/FNkAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper Parameter Tuning - 1 Character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(num_classes):\n",
    "    model = Sequential([\n",
    "        # Convolutional layer learns 32 filters using a 3x3 kernel\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(32, 128, 1)),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        #Dropout(0.25),\n",
    "\n",
    "        # Adding a second convolutional layer with 64 filters\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        #Dropout(0.25),\n",
    "\n",
    "        # Flatten the 3D output to 1D and add a dense layer\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        #Dropout(0.5),\n",
    "        Dropout(0.1),\n",
    "\n",
    "        # Output layer with softmax activation for classification\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    # adam with a learning rate of 0.001sparse_categorical_crossentropy\n",
    "\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Building Function to be used under Keras Tuner.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder_hyper_1char(hp):\n",
    "    seq_to_seq_model = Sequential()\n",
    "    \n",
    "    seq_to_seq_model.add(Conv2D(hp.Int('Input CNN units', min_value=64, max_value=128, step=32), kernel_size=(3, 3), input_shape=(32, 128, 1), activation=\"relu\", padding=\"SAME\"))\n",
    "    seq_to_seq_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    for i in range(hp.Int(\"layers\", 1 , 3)):\n",
    "        seq_to_seq_model.add(Conv2D(hp.Int('CNN units ' + str(i), min_value=64, max_value=128, step=32), kernel_size=(3, 3), activation=\"relu\", padding=\"SAME\"))\n",
    "        seq_to_seq_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    seq_to_seq_model.add(Flatten())\n",
    "    seq_to_seq_model.add(Dense(hp.Int('dense_units', min_value=64, max_value=256, step=64), activation='relu'))\n",
    "    seq_to_seq_model.add(Dropout(0.1))\n",
    "    seq_to_seq_model.add(Dense(num_classes, activation=\"softmax\"))\n",
    "\n",
    "    seq_to_seq_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return seq_to_seq_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuner using a max of 20 trials (combinations). Using Val accuracy as objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_1char = kt.RandomSearch(\n",
    "    model_builder_hyper_1char,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,  #Number of experiments\n",
    "    directory='my_dir_hyper_1char',\n",
    "    project_name='seq_to_seq_model_1char',\n",
    "    seed=24\n",
    ")\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "tuner_1char.search(X_train, y_train, epochs=50, validation_data=(X_val, y_val), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trials Summary Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_1char.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New Model with the best Hyper-Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps_1char = tuner_1char.get_best_hyperparameters(num_trials=10)[0]\n",
    "seq_to_seq_model_1char = tuner_1char.hypermodel.build(best_hps_1char)\n",
    "\n",
    "seq_to_seq_model_1char.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best hyperparameters:\", best_hps_1char.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model during the training\n",
    "best_hyper_model_path = 'best_hyper_model_1char.h5'  # Specify the path where you want to save the best model\n",
    "model_checkpoint = ModelCheckpoint(best_hyper_model_path, \n",
    "                                   monitor='val_loss', \n",
    "                                   save_best_only=True, \n",
    "                                   verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the new hyper tuned model to training data\n",
    "history_2 = seq_to_seq_model_1char.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),  # replace with your validation data\n",
    "    epochs=50,  # Set a high number because early stopping will halt the training\n",
    "    batch_size=64,  # Adjust based on your data and computing resources\n",
    "    callbacks=[early_stopping, model_checkpoint]  # Add the model checkpoint callback here\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A: Testing the model with test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'num_to_char = {num: char for char, num in char_to_num.items()}\\npredictions = model.predict(X_test)\\npredicted_classes = np.argmax(predictions, axis=1)\\npredicted_transcriptions = [num_to_char[num] for num in predicted_classes]\\nreal_transcriptions = [num_to_char[num] for num in y_test]\\nfor real, predicted in zip(real_transcriptions, predicted_transcriptions):\\n    print(f\"Real: {real}\")\\n    print(f\"Predicted: {predicted}\\n\")\\n'"
      ]
     },
     "execution_count": 674,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"num_to_char = {num: char for char, num in char_to_num.items()}\n",
    "predictions = model.predict(X_test)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "predicted_transcriptions = [num_to_char[num] for num in predicted_classes]\n",
    "real_transcriptions = [num_to_char[num] for num in y_test]\n",
    "for real, predicted in zip(real_transcriptions, predicted_transcriptions):\n",
    "    print(f\"Real: {real}\")\n",
    "    print(f\"Predicted: {predicted}\\n\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 9ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WordID</th>\n",
       "      <th>Real</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Correct</th>\n",
       "      <th>ImageData</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>j01-059-05-08</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>[[[0.0], [0.0], [0.0], [1.0], [1.0], [1.0], [1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e04-119-01-03</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m01-049-01-04</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n03-103-02-03</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d05-040-04-02</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          WordID Real Predicted  Correct  \\\n",
       "0  j01-059-05-08    -         -        1   \n",
       "1  e04-119-01-03    a         a        1   \n",
       "2  m01-049-01-04    a         a        1   \n",
       "3  n03-103-02-03    a         a        1   \n",
       "4  d05-040-04-02    a         a        1   \n",
       "\n",
       "                                           ImageData  \n",
       "0  [[[0.0], [0.0], [0.0], [1.0], [1.0], [1.0], [1...  \n",
       "1  [[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...  \n",
       "2  [[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...  \n",
       "3  [[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...  \n",
       "4  [[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a reverse mapping from number to character\n",
    "num_to_char = {num: char for char, num in char_to_num.items()}\n",
    "\n",
    "# Uncoment the lines below to run test data vs the hypertuned model.\n",
    "\"\"\"\n",
    "from keras.models import load_model\n",
    "model = load_model('best_hyper_model_1char.h5')\n",
    "\"\"\"\n",
    "\n",
    "# Uncoment the lines below to run test data vs the baseline model.\n",
    "\"\"\"\n",
    "from keras.models import load_model\n",
    "model = load_model('best_model_char.h5')\n",
    "\"\"\"\n",
    "\n",
    "# Make predictions on the test data - Use This if su\n",
    "predictions = model.predict(X_test)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Decode the predictions into actual characters\n",
    "predicted_transcriptions = [num_to_char.get(num, '') for num in predicted_classes]\n",
    "real_transcriptions = [num_to_char.get(num, '') for num in y_test]\n",
    "\n",
    "# Determine if the prediction is correct (1) or not (0)\n",
    "correct_predictions = [1 if real == pred else 0 for real, pred in zip(real_transcriptions, predicted_transcriptions)]\n",
    "\n",
    "# Get the indices for the test set\n",
    "test_indices = range(int(len(df_char) * (TRAIN_SPLIT + VAL_SPLIT)), len(df_char))\n",
    "\n",
    "# Ensure that the lengths of your test labels and indices match\n",
    "assert len(test_indices) == len(y_test), \"Mismatch in test set size and actual labels\"\n",
    "\n",
    "# Extract WordIDs and ImgageData for the test set using the correct indices\n",
    "test_word_ids = df.iloc[test_indices]['WordID'].values\n",
    "test_img_data = df.iloc[test_indices]['ImageData'].values\n",
    "\n",
    "# Ensure that every list you're going to put into the DataFrame is of the same length\n",
    "assert len(test_word_ids) == len(test_img_data) == len(predicted_transcriptions) == len(real_transcriptions), \"Mismatch in the length of data columns\"\n",
    "\n",
    "# Create the DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    'WordID': test_word_ids,\n",
    "    'Real': real_transcriptions,\n",
    "    'Predicted': predicted_transcriptions,\n",
    "    'Correct': correct_predictions,\n",
    "    'ImageData': test_img_data\n",
    "})\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct\n",
      "1    141\n",
      "0     15\n",
      "Name: count, dtype: int64\n",
      "Correct\n",
      "1    0.903846\n",
      "0    0.096154\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(results_df['Correct'].value_counts())\n",
    "print(results_df['Correct'].value_counts() / len(results_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WordID</th>\n",
       "      <th>Real</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Correct</th>\n",
       "      <th>ImageData</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b02-013-07-06</td>\n",
       "      <td>I</td>\n",
       "      <td>,</td>\n",
       "      <td>0</td>\n",
       "      <td>[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>b02-013-08-05</td>\n",
       "      <td>\"</td>\n",
       "      <td>'</td>\n",
       "      <td>0</td>\n",
       "      <td>[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>b02-013-09-06</td>\n",
       "      <td>,</td>\n",
       "      <td>I</td>\n",
       "      <td>0</td>\n",
       "      <td>[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>b02-013-09-07</td>\n",
       "      <td>A</td>\n",
       "      <td>\"</td>\n",
       "      <td>0</td>\n",
       "      <td>[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>b02-035-00-00</td>\n",
       "      <td>,</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           WordID Real Predicted  Correct  \\\n",
       "0   b02-013-07-06    I         ,        0   \n",
       "7   b02-013-08-05    \"         '        0   \n",
       "15  b02-013-09-06    ,         I        0   \n",
       "16  b02-013-09-07    A         \"        0   \n",
       "17  b02-035-00-00    ,         a        0   \n",
       "\n",
       "                                            ImageData  \n",
       "0   [[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...  \n",
       "7   [[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...  \n",
       "15  [[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...  \n",
       "16  [[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...  \n",
       "17  [[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...  "
      ]
     },
     "execution_count": 687,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect = results_df[results_df['Correct'] == 0]\n",
    "incorrect.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1807\n"
     ]
    }
   ],
   "source": [
    "print(len(results_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('results_char.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.86      0.81        28\n",
      "           1       0.86      0.72      0.78       169\n",
      "           2       0.80      0.50      0.62         8\n",
      "           3       1.00      0.50      0.67         4\n",
      "           4       0.17      0.01      0.02        80\n",
      "           5       0.71      0.59      0.65        17\n",
      "           6       0.70      0.39      0.50        18\n",
      "           8       0.78      0.90      0.84       563\n",
      "           9       0.84      0.95      0.89        40\n",
      "          10       0.90      0.90      0.90       510\n",
      "          11       0.00      0.00      0.00         5\n",
      "          12       0.00      0.00      0.00         3\n",
      "          13       1.00      0.67      0.80         3\n",
      "          14       0.00      0.00      0.00         1\n",
      "          15       0.00      0.00      0.00         1\n",
      "          18       0.00      0.00      0.00         2\n",
      "          20       0.76      0.94      0.84        17\n",
      "          21       0.83      0.88      0.86        17\n",
      "          22       0.70      0.94      0.80        17\n",
      "          23       0.57      0.47      0.52        17\n",
      "          28       0.00      0.00      0.00         1\n",
      "          30       0.00      0.00      0.00         1\n",
      "          31       0.67      0.61      0.64        79\n",
      "          35       0.00      0.00      0.00         1\n",
      "          39       0.82      0.98      0.89       204\n",
      "          40       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.82      1807\n",
      "   macro avg       0.50      0.45      0.46      1807\n",
      "weighted avg       0.79      0.82      0.79      1807\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# print evaluation metrics\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predictions.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1 or more characters** words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "df = pd.read_pickle('data/words_df_all.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consider only SegmentationResluts == 'ok'\n",
    "df = df[df['SegmentationResult'] == 'ok']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a01-096u-04-02\n",
      "m03-062-07-02\n"
     ]
    }
   ],
   "source": [
    "for i, img in enumerate(df['ImageData']):\n",
    "    if type(img) != np.ndarray:\n",
    "        print(df['WordID'][i])\n",
    "        # delete the current row from df\n",
    "        df.drop(i, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WordID</th>\n",
       "      <th>SegmentationResult</th>\n",
       "      <th>GrayLevel</th>\n",
       "      <th>BoundingBox</th>\n",
       "      <th>GrammaticalTag</th>\n",
       "      <th>Transcription</th>\n",
       "      <th>ImageData</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4152</th>\n",
       "      <td>a01-117-05-02</td>\n",
       "      <td>ok</td>\n",
       "      <td>160</td>\n",
       "      <td>(868, 1648, 217, 86)</td>\n",
       "      <td>NP</td>\n",
       "      <td>Powell</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113621</th>\n",
       "      <td>r06-022-03-05</td>\n",
       "      <td>ok</td>\n",
       "      <td>184</td>\n",
       "      <td>(924, 1304, 132, 29)</td>\n",
       "      <td>QL</td>\n",
       "      <td>more</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               WordID SegmentationResult  GrayLevel           BoundingBox  \\\n",
       "4152    a01-117-05-02                 ok        160  (868, 1648, 217, 86)   \n",
       "113621  r06-022-03-05                 ok        184  (924, 1304, 132, 29)   \n",
       "\n",
       "       GrammaticalTag Transcription ImageData  \n",
       "4152               NP        Powell      None  \n",
       "113621             QL          more      None  "
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the row in which imagdate is none\n",
    "df[df['ImageData'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['ImageData'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageData\n",
      "<class 'numpy.ndarray'>    115317\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['ImageData'].apply(type).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13549\n"
     ]
    }
   ],
   "source": [
    "print(len(df['Transcription'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', '!', '\"', '#', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "vocabulary = sorted(set(''.join(df['Transcription'].values)))\n",
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle\n",
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consider only words that do not contain spaces or pontuation\n",
    "punctuation = [' ', '.', ',', '!', '?', \"'\", '\"', '(', ')', '[', ']', '{', '}', '/', '\\\\', '|', '*', '+', '=', '_', '#', '@', '%', '&', '^', '~', '`', '<', '>', ':', ';']\n",
    "df = df[df['Transcription'].apply(lambda x: all(char not in x for char in punctuation))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and validation sets\n",
    "X = np.stack(df['ImageData'].values)  # Convert the list of images to a numpy array\n",
    "y = np.array(df['Transcription'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(83831, 21)\n"
     ]
    }
   ],
   "source": [
    "def encode_to_labels(y):\n",
    "    global vocabulary, char_to_num\n",
    "    # create a list of the chartcaters vocabulary ordered alphabetically\n",
    "    vocabulary = sorted(set(''.join(y)))\n",
    "\n",
    "    # create a dictionary mapping each character to the vocabulary list index. do not use 0.\n",
    "    char_to_num = {char:idx+1 for idx, char in enumerate(vocabulary)}\n",
    "\n",
    "    # transform y values to numerical using the char_to_num dictionary, using 0 for padding. the length of each word is the maximum length of the words in the dataset\n",
    "    y_encoded = []\n",
    "    for word in y:\n",
    "        word_encoded = [char_to_num[char] for char in word]\n",
    "        y_encoded.append(word_encoded)\n",
    "\n",
    "    # pad the encoded values (fill with 0s to the right)\n",
    "    y_encoded = tf.keras.preprocessing.sequence.pad_sequences(y_encoded, padding='post')\n",
    "\n",
    "    # normalize the values\n",
    "    # y_encoded = y_encoded / np.array(len(vocabulary))\n",
    "\n",
    "    return y_encoded\n",
    "\n",
    "y = encode_to_labels(y)\n",
    "\n",
    "# one-hot enconde instead of encode_to_labels\n",
    "# y = to_categorical(y, num_classes=len(vocabulary)+1)\n",
    "\n",
    "# print(y.shape)\n",
    "\n",
    "# add padding to y to match the image size\n",
    "# y = np.pad(y, ((0,0),(0,32-y.shape[1]),(0,0)), mode='constant', constant_values=0)\n",
    "\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46 51  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "print(y[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(83831, 32, 128, 1)\n",
      "(83831, 21)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67064, 32, 128, 1)\n",
      "(67064, 21)\n",
      "(8383, 32, 128, 1)\n",
      "(8383, 21)\n",
      "(8384, 32, 128, 1)\n",
      "(8384, 21)\n"
     ]
    }
   ],
   "source": [
    "TRAIN_SPLIT = 0.8\n",
    "VAL_SPLIT = 0.1\n",
    "TEST_SPLIT = 0.1\n",
    "\n",
    "# split the data into training, validation and test sets\n",
    "X_train = X[:int(X.shape[0]*TRAIN_SPLIT)]\n",
    "y_train = y[:int(y.shape[0]*TRAIN_SPLIT)]\n",
    "\n",
    "X_val = X[int(X.shape[0]*TRAIN_SPLIT):int(X.shape[0]*(TRAIN_SPLIT+VAL_SPLIT))]\n",
    "y_val = y[int(y.shape[0]*TRAIN_SPLIT):int(y.shape[0]*(TRAIN_SPLIT+VAL_SPLIT))]\n",
    "\n",
    "X_test = X[int(X.shape[0]*(TRAIN_SPLIT+VAL_SPLIT)):]\n",
    "y_test = y[int(y.shape[0]*(TRAIN_SPLIT+VAL_SPLIT)):]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save value_counts of transcription of df to a df and export it to txt\n",
    "df['Transcription'].value_counts().to_csv('data/transcription_value_counts_all.txt', header=None, sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67064, 32, 128, 1)\n",
      "(67064, 21)\n"
     ]
    }
   ],
   "source": [
    "# print the shapes of training x and y\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31 45 42 55 42  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67064, 21, 64)\n"
     ]
    }
   ],
   "source": [
    "# one hot encode y\n",
    "y_train = to_categorical(y_train, num_classes=len(vocabulary)+1)\n",
    "y_val = to_categorical(y_val, num_classes=len(vocabulary)+1)\n",
    "y_test = to_categorical(y_test, num_classes=len(vocabulary)+1)\n",
    "\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save y_train[0] to txt file\n",
    "np.savetxt('data/y_train_0.txt', y_train[2], fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 30, 126, 32)       320       \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPooli  (None, 15, 63, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 13, 61, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPooli  (None, 6, 30, 64)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 4, 28, 128)        73856     \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPooli  (None, 2, 14, 128)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 3584)              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 256)               917760    \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1344)              345408    \n",
      "                                                                 \n",
      " reshape_4 (Reshape)         (None, 21, 64)            0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1355840 (5.17 MB)\n",
      "Trainable params: 1355840 (5.17 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.7950 - accuracy: 0.7948\n",
      "Epoch 1: val_loss improved from inf to 0.67016, saving model to best_model_word.h5\n",
      "524/524 [==============================] - 57s 108ms/step - loss: 0.7950 - accuracy: 0.7948 - val_loss: 0.6702 - val_accuracy: 0.8106\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - ETA: 0s - loss: 0.6564 - accuracy: 0.8164\n",
      "Epoch 2: val_loss improved from 0.67016 to 0.61911, saving model to best_model_word.h5\n",
      "524/524 [==============================] - 60s 114ms/step - loss: 0.6564 - accuracy: 0.8164 - val_loss: 0.6191 - val_accuracy: 0.8224\n",
      "Epoch 3/50\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.6146 - accuracy: 0.8251\n",
      "Epoch 3: val_loss improved from 0.61911 to 0.58120, saving model to best_model_word.h5\n",
      "524/524 [==============================] - 60s 114ms/step - loss: 0.6146 - accuracy: 0.8251 - val_loss: 0.5812 - val_accuracy: 0.8303\n",
      "Epoch 4/50\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.5832 - accuracy: 0.8314\n",
      "Epoch 4: val_loss improved from 0.58120 to 0.55343, saving model to best_model_word.h5\n",
      "524/524 [==============================] - 59s 112ms/step - loss: 0.5832 - accuracy: 0.8314 - val_loss: 0.5534 - val_accuracy: 0.8381\n",
      "Epoch 5/50\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.5583 - accuracy: 0.8371\n",
      "Epoch 5: val_loss improved from 0.55343 to 0.52417, saving model to best_model_word.h5\n",
      "524/524 [==============================] - 59s 113ms/step - loss: 0.5583 - accuracy: 0.8371 - val_loss: 0.5242 - val_accuracy: 0.8435\n",
      "Epoch 6/50\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.5367 - accuracy: 0.8421\n",
      "Epoch 6: val_loss improved from 0.52417 to 0.50503, saving model to best_model_word.h5\n",
      "524/524 [==============================] - 62s 119ms/step - loss: 0.5367 - accuracy: 0.8421 - val_loss: 0.5050 - val_accuracy: 0.8492\n",
      "Epoch 7/50\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.5173 - accuracy: 0.8470\n",
      "Epoch 7: val_loss improved from 0.50503 to 0.49311, saving model to best_model_word.h5\n",
      "524/524 [==============================] - 61s 117ms/step - loss: 0.5173 - accuracy: 0.8470 - val_loss: 0.4931 - val_accuracy: 0.8548\n",
      "Epoch 8/50\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.5000 - accuracy: 0.8511\n",
      "Epoch 8: val_loss improved from 0.49311 to 0.47845, saving model to best_model_word.h5\n",
      "524/524 [==============================] - 60s 115ms/step - loss: 0.5000 - accuracy: 0.8511 - val_loss: 0.4785 - val_accuracy: 0.8561\n",
      "Epoch 9/50\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.4841 - accuracy: 0.8551\n",
      "Epoch 9: val_loss improved from 0.47845 to 0.45654, saving model to best_model_word.h5\n",
      "524/524 [==============================] - 62s 117ms/step - loss: 0.4841 - accuracy: 0.8551 - val_loss: 0.4565 - val_accuracy: 0.8637\n",
      "Epoch 10/50\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.4705 - accuracy: 0.8583\n",
      "Epoch 10: val_loss improved from 0.45654 to 0.44699, saving model to best_model_word.h5\n",
      "524/524 [==============================] - 61s 116ms/step - loss: 0.4705 - accuracy: 0.8583 - val_loss: 0.4470 - val_accuracy: 0.8649\n",
      "Epoch 11/50\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.4567 - accuracy: 0.8621\n",
      "Epoch 11: val_loss improved from 0.44699 to 0.43293, saving model to best_model_word.h5\n",
      "524/524 [==============================] - 61s 117ms/step - loss: 0.4567 - accuracy: 0.8621 - val_loss: 0.4329 - val_accuracy: 0.8698\n",
      "Epoch 12/50\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.4471 - accuracy: 0.8643\n",
      "Epoch 12: val_loss improved from 0.43293 to 0.42637, saving model to best_model_word.h5\n",
      "524/524 [==============================] - 62s 119ms/step - loss: 0.4471 - accuracy: 0.8643 - val_loss: 0.4264 - val_accuracy: 0.8714\n",
      "Epoch 13/50\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.4360 - accuracy: 0.8670\n",
      "Epoch 13: val_loss improved from 0.42637 to 0.42064, saving model to best_model_word.h5\n",
      "524/524 [==============================] - 66s 126ms/step - loss: 0.4360 - accuracy: 0.8670 - val_loss: 0.4206 - val_accuracy: 0.8740\n",
      "Epoch 14/50\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.4287 - accuracy: 0.8687\n",
      "Epoch 14: val_loss improved from 0.42064 to 0.41284, saving model to best_model_word.h5\n",
      "524/524 [==============================] - 62s 119ms/step - loss: 0.4287 - accuracy: 0.8687 - val_loss: 0.4128 - val_accuracy: 0.8762\n",
      "Epoch 15/50\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.4195 - accuracy: 0.8713\n",
      "Epoch 15: val_loss improved from 0.41284 to 0.41035, saving model to best_model_word.h5\n",
      "524/524 [==============================] - 61s 117ms/step - loss: 0.4195 - accuracy: 0.8713 - val_loss: 0.4103 - val_accuracy: 0.8769\n",
      "Epoch 16/50\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.4120 - accuracy: 0.8731\n",
      "Epoch 16: val_loss improved from 0.41035 to 0.40272, saving model to best_model_word.h5\n",
      "524/524 [==============================] - 64s 123ms/step - loss: 0.4120 - accuracy: 0.8731 - val_loss: 0.4027 - val_accuracy: 0.8797\n",
      "Epoch 17/50\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.4050 - accuracy: 0.8749\n",
      "Epoch 17: val_loss improved from 0.40272 to 0.40087, saving model to best_model_word.h5\n",
      "524/524 [==============================] - 62s 118ms/step - loss: 0.4050 - accuracy: 0.8749 - val_loss: 0.4009 - val_accuracy: 0.8807\n",
      "Epoch 18/50\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.3982 - accuracy: 0.8766\n",
      "Epoch 18: val_loss improved from 0.40087 to 0.39578, saving model to best_model_word.h5\n",
      "524/524 [==============================] - 57s 109ms/step - loss: 0.3982 - accuracy: 0.8766 - val_loss: 0.3958 - val_accuracy: 0.8822\n",
      "Epoch 19/50\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.3923 - accuracy: 0.8779\n",
      "Epoch 19: val_loss did not improve from 0.39578\n",
      "524/524 [==============================] - 61s 117ms/step - loss: 0.3923 - accuracy: 0.8779 - val_loss: 0.3994 - val_accuracy: 0.8818\n",
      "Epoch 20/50\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.3863 - accuracy: 0.8796\n",
      "Epoch 20: val_loss improved from 0.39578 to 0.39197, saving model to best_model_word.h5\n",
      "524/524 [==============================] - 62s 119ms/step - loss: 0.3863 - accuracy: 0.8796 - val_loss: 0.3920 - val_accuracy: 0.8837\n",
      "Epoch 21/50\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.3810 - accuracy: 0.8808\n",
      "Epoch 21: val_loss did not improve from 0.39197\n",
      "524/524 [==============================] - 61s 117ms/step - loss: 0.3810 - accuracy: 0.8808 - val_loss: 0.3924 - val_accuracy: 0.8841\n",
      "Epoch 22/50\n",
      "524/524 [==============================] - ETA: 0s - loss: nan - accuracy: 0.8329\n",
      "Epoch 22: val_loss did not improve from 0.39197\n",
      "524/524 [==============================] - 64s 121ms/step - loss: nan - accuracy: 0.8329 - val_loss: nan - val_accuracy: 0.7800\n",
      "Epoch 23/50\n",
      "524/524 [==============================] - ETA: 0s - loss: nan - accuracy: 0.7820\n",
      "Epoch 23: val_loss did not improve from 0.39197\n",
      "524/524 [==============================] - 58s 111ms/step - loss: nan - accuracy: 0.7820 - val_loss: nan - val_accuracy: 0.7800\n"
     ]
    }
   ],
   "source": [
    "# ---- DESCRIPTION OF THE INPUT DATA ----\n",
    "# X_train shape: (num_samples, 32, 128, 1)\n",
    "# y_train shape: (num_samples, max(len(words)),len(vocabulary))\n",
    "# example of a X_train value: matrix of 32x128 with values between 0 and 1\n",
    "# example of a y_train value: matrix of 17x63 with values between 0 and 1. first column is the padding, the rest are the one-hot encoded values of the transcription\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.layers import Reshape\n",
    "\n",
    "def create_cnn_model(input_shape, num_classes, sequence_length):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "        Flatten(),\n",
    "        \n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.1),\n",
    "        \n",
    "        Dense(sequence_length * num_classes, activation='softmax'),\n",
    "        Reshape((sequence_length, num_classes))\n",
    "\n",
    "\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "create_cnn_model(input_shape=(32, 128, 1), num_classes=len(vocabulary)+1, sequence_length=y_train.shape[1]).summary()\n",
    "\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Stop training when there is no improvement in the validation loss for 3 consecutive epochs\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "# Save the best model during the training\n",
    "best_model_path = 'best_model_word.h5'  \n",
    "model_checkpoint = ModelCheckpoint(best_model_path, \n",
    "                                   monitor='val_loss', \n",
    "                                   save_best_only=True, \n",
    "                                   verbose=1)\n",
    "\n",
    "# Assume create_cnn_model is a function you've defined to create your model\n",
    "model = create_cnn_model(input_shape=(32, 128, 1), num_classes=len(vocabulary)+1, sequence_length=y_train.shape[1])\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=50,  # Set a high number because early stopping will halt the training\n",
    "    batch_size=128,\n",
    "    callbacks=[early_stopping, model_checkpoint]  # Add the model checkpoint callback here\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGwCAYAAABVdURTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABaAklEQVR4nO3deXhM9x4G8HcSSSQhYwlZiLX2JTRI7VRIULW19rXUpahWtaglVFtavapVRV1LtVrbRbXUFkvVFsQuoiqESmJNIiGJZM7943tnIiSRZWbOzOT9PM88Zs6cOfMdE83b36pRFEUBERERkY2wU7sAIiIiImNiuCEiIiKbwnBDRERENoXhhoiIiGwKww0RERHZFIYbIiIisikMN0RERGRTiqhdgLnpdDrcvHkTxYsXh0ajUbscIiIiygVFUfDgwQN4e3vDzi7ntplCF25u3rwJHx8ftcsgIiKifLh+/TrKly+f4zmFLtwUL14cgPzluLm5qVwNERER5UZCQgJ8fHwMv8dzUujCjb4rys3NjeGGiIjIyuRmSAkHFBMREZFNYbghIiIim8JwQ0RERDal0I25ISIideh0OqSmpqpdBlkwR0fH507zzg2GGyIiMrnU1FRERkZCp9OpXQpZMDs7O1SuXBmOjo4Fug7DDRERmZSiKIiOjoa9vT18fHyM8n/mZHv0i+xGR0ejQoUKBVpoV/Vws3DhQsydOxcxMTHw9fXFggUL0KRJk2zPnz9/PhYtWoSoqCi4u7vjtddew+zZs1G0aFEzVk1ERLmVlpaGhw8fwtvbGy4uLmqXQxasTJkyuHnzJtLS0uDg4JDv66gan9euXYvx48cjODgYYWFh8PX1RWBgIG7dupXl+T/99BMmTZqE4OBghIeHY9myZVi7di0+/PBDM1dORES5lZ6eDgAF7mog26f/GdH/zOSXquFm3rx5ePPNNzF06FDUrl0bixcvhouLC5YvX57l+YcOHULz5s3Rr18/VKpUCR06dEDfvn0RGhpq5sqJiCivuJ8fPY+xfkZUCzepqak4ceIEAgICMoqxs0NAQAAOHz6c5WuaNWuGEydOGMLMlStXsG3bNnTq1Cnb90lJSUFCQkKmGxEREdku1cbc3LlzB+np6fDw8Mh03MPDAxcvXszyNf369cOdO3fQokULKIqCtLQ0jBw5MsduqdmzZ2PmzJlGrZ2IiIgsl1UNWd+3bx8+/fRTfPvttwgLC8PGjRuxdetWzJo1K9vXTJ48GfHx8Ybb9evXzVgxERFRhkqVKmH+/Pm5Pn/fvn3QaDSIi4szWU22SLWWG3d3d9jb2yM2NjbT8djYWHh6emb5mmnTpmHgwIEYPnw4AKBevXpISkrCiBEjMGXKlCynFzo5OcHJycn4H4CIiGzW88Z+BAcHY8aMGXm+7rFjx+Dq6prr85s1a4bo6Ghotdo8v1de7Nu3D23btsX9+/dRokQJk76XOajWcuPo6Ag/Pz+EhIQYjul0OoSEhKBp06ZZvubhw4fPBBh7e3sAso6C6h49As6eVbsKIiIqoOjoaMNt/vz5cHNzy3RswoQJhnP1wyRyo0yZMnmaDu/o6AhPT08Oxs4jVbulxo8fj6VLl+L7779HeHg4Ro0ahaSkJAwdOhQAMGjQIEyePNlwfpcuXbBo0SKsWbMGkZGR2LVrF6ZNm4YuXboYQo5q/vkHKF4c8PMDUlLUrYWIyBokJWV/S07O/bmPHuXu3Dzw9PQ03LRaLTQajeHxxYsXUbx4cfz+++/w8/ODk5MT/vzzT/z999/o2rUrPDw8UKxYMTRu3Bi7d+/OdN2nu6U0Gg3+85//oHv37nBxcUG1atWwZcsWw/NPd0utXLkSJUqUwI4dO1CrVi0UK1YMQUFBiI6ONrwmLS0Nb7/9NkqUKIHSpUtj4sSJGDx4MLp165anv4Mn3b9/H4MGDULJkiXh4uKCjh074q+//jI8f+3aNXTp0gUlS5aEq6sr6tSpg23bthle279/f5QpUwbOzs6oVq0aVqxYke9ackPVcNO7d2988cUXmD59Oho0aIBTp05h+/bthkHGUVFRmb6wqVOn4r333sPUqVNRu3ZtDBs2DIGBgViyZIlaHyGDtzeg1QKPHwPnzqldDRGR5StWLPtbz56Zzy1bNvtzO3bMfG6lSlmfZ2STJk3CnDlzEB4ejvr16yMxMRGdOnVCSEgITp48iaCgIHTp0gVRUVE5XmfmzJno1asXzpw5g06dOqF///64d+9etuc/fPgQX3zxBX744Qf88ccfiIqKytSS9Nlnn2H16tVYsWIFDh48iISEBGzevLlAn3XIkCE4fvw4tmzZgsOHD0NRFHTq1AmPHz8GAIwePRopKSn4448/cPbsWXz22Wco9v+/82nTpuHChQv4/fffER4ejkWLFsHd3b1A9TyXUsjEx8crAJT4+HjjX7x9e0UBFGXxYuNfm4jISj169Ei5cOGC8ujRo8xPANnfOnXKfK6LS/bntm6d+Vx396zPy6cVK1YoWq3W8Hjv3r0KAGXz5s3PfW2dOnWUBQsWGB5XrFhR+fLLLw2PAShTp041PE5MTFQAKL///num97p//76hFgDK5cuXDa9ZuHCh4uHhYXjs4eGhzJ071/A4LS1NqVChgtK1a9ds63z6fZ506dIlBYBy8OBBw7E7d+4ozs7Oyrp16xRFUZR69eopM2bMyPLaXbp0UYYOHZrtez8p258VJW+/v1XffsGm+PkBu3YBJ06oXQkRkeVLTMz+uaeHGmSzcj0A4OnJJFev5rukvGjUqFGmx4mJiZgxYwa2bt2K6OhopKWl4dGjR89tualfv77hvqurK9zc3LJdqR8AXFxcULVqVcNjLy8vw/nx8fGIjY3NtI2Rvb09/Pz88r1paXh4OIoUKQJ/f3/DsdKlS6NGjRoIDw8HALz99tsYNWoUdu7ciYCAAPTs2dPwuUaNGoWePXsiLCwMHTp0QLdu3dCsWbN81ZJbVjUV3OLpf9AZboiIns/VNfvb0/sF5nSus3PuzjV6+ZmvOWHCBGzatAmffvopDhw4gFOnTqFevXpITU3N8TpP76Gk0WhyDCJZna+oPKlm+PDhuHLlCgYOHIizZ8+iUaNGWLBgAQCgY8eOuHbtGt59913cvHkT7dq1y9SNZgoMN8bk5yd/nj3LQcVERIXMwYMHMWTIEHTv3h316tWDp6cnrpqpFUlPq9XCw8MDx44dMxxLT09HWFhYvq9Zq1YtpKWl4ejRo4Zjd+/eRUREBGrXrm045uPjg5EjR2Ljxo147733sHTpUsNzZcqUweDBg/Hjjz9i/vz5+O677/JdT26wW8qYKlYESpUC7t2TgPNUkyUREdmuatWqYePGjejSpQs0Gg2mTZuW766gghg7dixmz56NF154ATVr1sSCBQtw//79XE0nP3v2LIoXL254rNFo4Ovri65du+LNN9/EkiVLULx4cUyaNAnlypVD165dAQDvvPMOOnbsiOrVq+P+/fvYu3cvatWqBQCYPn06/Pz8UKdOHaSkpOC3334zPGcqDDfGpNEA778PODgAXl5qV0NERGY0b948vPHGG2jWrBnc3d0xceJEVfYznDhxImJiYjBo0CDY29tjxIgRCAwMzNWSKa1atcr02N7eHmlpaVixYgXGjRuHV155BampqWjVqhW2bdtm6CJLT0/H6NGjcePGDbi5uSEoKAhffvklAFmrZ/Lkybh69SqcnZ3RsmVLrFmzxvgf/AkaRe2OOjNLSEiAVqtFfHw83Nzc1C6HiMjmJScnIzIyEpUrV0bRp8fSkMnpdDrUqlULvXr1ynG7IkuQ089KXn5/s+WGiIjIhly7dg07d+5E69atkZKSgm+++QaRkZHo16+f2qWZDQcUG5uiABcvAqtXP7vCJhERkYnZ2dlh5cqVaNy4MZo3b46zZ89i9+7dJh/nYknYcmMKLVoAd+8C1asDjRurXQ0RERUiPj4+OHjwoNplqIotN8am0XC9GyIiIhUx3JiCfr0bhhsiIiKzY7gxBX24OX5c3TqIiIgKIYYbU9B3S507x0HFREREZsZwYwo+PoC7O5CWJisVExERkdkw3JiCRsNxN0REhDZt2uCdd95Ru4xCh+HGVCZMADZvBnr2VLsSIiLKoy5duiAoKCjL5w4cOACNRoMzZ84U+H1WrlyJEiVKFPg6lBnXuTGVgAC1KyAionwaNmwYevbsiRs3bqB8+fKZnluxYgUaNWqE+vXrq1QdPQ9bboiIiJ7yyiuvoEyZMli5cmWm44mJiVi/fj2GDRuGu3fvom/fvihXrhxcXFxQr149/Pzzz0atIyoqCl27dkWxYsXg5uaGXr16ITY21vD86dOn0bZtWxQvXhxubm7w8/PD8f/P1L127Rq6dOmCkiVLwtXVFXXq1MG2bduMWp+lYsuNKYWEAH/+CfTpA9SooXY1REQWQVGAhw/VeW8XFxkW+TxFihTBoEGDsHLlSkyZMgWa/79o/fr1SE9PR9++fZGYmAg/Pz9MnDgRbm5u2Lp1KwYOHIiqVauiSZMmBa5Vp9MZgs3+/fuRlpaG0aNHo3fv3ti3bx8AoH///mjYsCEWLVoEe3t7nDp1yrBT9+jRo5Gamoo//vgDrq6uuHDhAooVK1bguqwBw40pzZ0L7NgBlC3LcENE9H8PHwJq/Y5NTARcXXN37htvvIG5c+di//79aNOmDQDpkurZsye0Wi20Wi0mTJhgOH/s2LHYsWMH1q1bZ5RwExISgrNnzyIyMhI+Pj4AgFWrVqFOnTo4duwYGjdujKioKLz//vuoWbMmAKBatWqG10dFRaFnz56oV68eAKBKlSoFrslasFvKlDhjiojIatWsWRPNmjXD8uXLAQCXL1/GgQMHMGzYMABAeno6Zs2ahXr16qFUqVIoVqwYduzYgaioKKO8f3h4OHx8fAzBBgBq166NEiVKIDw8HAAwfvx4DB8+HAEBAZgzZw7+/vtvw7lvv/02Pv74YzRv3hzBwcFGGQBtLRhuTIl7TBERPcPFRVpQ1Li5uOSt1mHDhuG///0vHjx4gBUrVqBq1apo3bo1AGDu3Ln46quvMHHiROzduxenTp1CYGAgUlNTTfC3lrUZM2bg/Pnz6Ny5M/bs2YPatWtj06ZNAIDhw4fjypUrGDhwIM6ePYtGjRphwYIFZqtNTQw3pqRvueFKxUREBhqNdA2pccvNeJsn9erVC3Z2dvjpp5+watUqvPHGG4bxNwcPHkTXrl0xYMAA+Pr6okqVKrh06ZLR/p5q1aqF69ev4/r164ZjFy5cQFxcHGrXrm04Vr16dbz77rvYuXMnevTogRUrVhie8/HxwciRI7Fx40a89957WLp0qdHqs2Qcc2NKPj5AmTLA7dvAmTOAEfpgiYjIfIoVK4bevXtj8uTJSEhIwJAhQwzPVatWDRs2bMChQ4dQsmRJzJs3D7GxsZmCR26kp6fj1KlTmY45OTkhICAA9erVQ//+/TF//nykpaXhrbfeQuvWrdGoUSM8evQI77//Pl577TVUrlwZN27cwLFjx9Dz/+urvfPOO+jYsSOqV6+O+/fvY+/evahVq1ZB/0qsAltuTIkrFRMRWb1hw4bh/v37CAwMhLe3t+H41KlT8eKLLyIwMBBt2rSBp6cnunXrlufrJyYmomHDhpluXbp0gUajwS+//IKSJUuiVatWCAgIQJUqVbB27VoAgL29Pe7evYtBgwahevXq6NWrFzp27IiZM2cCkNA0evRo1KpVC0FBQahevTq+/fZbo/ydWDqNoiiK2kWYU0JCArRaLeLj4+Hm5mb6N5w6FfjkE+DNN4HvvjP9+xERWZjk5GRERkaicuXKKFq0qNrlkAXL6WclL7+/2S1laiNGAH37Av+fpkdERESmxXBjahUqqF0BERFRocIxN0RERGRTGG7MYcsWYOBA4P+DwIiIiMh0GG7M4dgx4McfZSsGIqJCqpDNX6F8MNbPCMONOXA6OBEVYvb29gBg1pV7yTrpf0b0PzP5xQHF5qAPN+fPA48eAc7O6tZDRGRGRYoUgYuLC27fvg0HBwfY2fH/q+lZOp0Ot2/fhouLC4oUKVg8Ybgxh/LlZWfwW7dkpWJ/f7UrIiIyG41GAy8vL0RGRuLatWtql0MWzM7ODhUqVDBscZFfDDfmoF+p+PffgePHGW6IqNBxdHREtWrV2DVFOXJ0dDRKyx7Djbnoww3H3RBRIWVnZ8cVisks2PFpLn5+gJ0dkJCgdiVEREQ2jS035hIUJMHG1VXtSoiIiGwaw425sCmWiIjILNgtRURERDaF4cactm4FmjUDRo9WuxIiIiKbxW4pc0pLAw4fBhIT1a6EiIjIZrHlxpz0KxVfuCArFRMREZHRMdyYU7lygIcHkJ4OnD6tdjVEREQ2ieHGnPQrFQOyUjEREREZHcONuXGHcCIiIpNiuDG3Ro3kT4YbIiIik2C4MTc/Pxl7U60aoNOpXQ0REZHN4VRwcytXDrhxQ+0qiIiIbBZbboiIiMimMNyoRVGAuDi1qyAiIrI5DDdqOHJE1rtp2VLtSoiIiGwOx9yooUIF4PZt4O5dICkJcHVVuyIiIiKbwZYbNXh7A56eMluKKxUTEREZFcONWriYHxERkUkw3KiF4YaIiMgkGG7UwpWKiYiITILhRi36lpsLF2RQMRERERkFZ0upxdsb6N4dqFIFSE7mjCkiIiIjYbhR08aNaldARERkc9gtRURERDaF4UZt8fGyYjEREREZBbul1HTrlmzDYGcHJCRw3A0REZERsOVGTWXLAl5eXKmYiIjIiBhu1KafEn78uLp1EBER2QiGG7VxpWIiIiKjYrhRG1cqJiIiMiqGG7XpW27Cw7lSMRERkREw3KjNyytjUPGpU2pXQ0REZPU4FdwSTJ4MFCkiWzEQERFRgVhEy83ChQtRqVIlFC1aFP7+/ggNDc323DZt2kCj0Txz69y5sxkrNrKxY4FRo6QFh4iIiApE9XCzdu1ajB8/HsHBwQgLC4Ovry8CAwNx69atLM/fuHEjoqOjDbdz587B3t4er7/+upkrJyIiIkukeriZN28e3nzzTQwdOhS1a9fG4sWL4eLiguXLl2d5fqlSpeDp6Wm47dq1Cy4uLtYdbhQFCAsDli7loGIiIqICUjXcpKam4sSJEwgICDAcs7OzQ0BAAA4fPpyrayxbtgx9+vSBazZbF6SkpCAhISHTzeJoNECXLsCIEcDJk2pXQ0REZNVUDTd37txBeno6PDw8Mh338PBATEzMc18fGhqKc+fOYfjw4dmeM3v2bGi1WsPNx8enwHWbBNe7ISIiMgrVu6UKYtmyZahXrx6aNGmS7TmTJ09GfHy84Xb9+nUzVpgHXKmYiIjIKFSdCu7u7g57e3vExsZmOh4bGwtPT88cX5uUlIQ1a9bgo48+yvE8JycnODk5FbhWk+MeU0REREahasuNo6Mj/Pz8EBISYjim0+kQEhKCpk2b5vja9evXIyUlBQMGDDB1meahDzcXLwKJierWQkREZMVU75YaP348li5diu+//x7h4eEYNWoUkpKSMHToUADAoEGDMHny5Gdet2zZMnTr1g2lS5c2d8mm4ekJeHvLzCmuVExERJRvqq9Q3Lt3b9y+fRvTp09HTEwMGjRogO3btxsGGUdFRcHOLnMGi4iIwJ9//omdO3eqUbLpNGoEbNki425atFC7GiIiIqukURRFUbsIc0pISIBWq0V8fDzc3NzULiezgweBhw+Bxo2BEiXUroaIiMhi5OX3t+otN/SE5s3VroCIiMjqqT7mhoiIiMiYGG4szbZtwMSJwJkzaldCRERkldgtZWmWLJFBxV5eQP36aldDRERkddhyY2m4DQMREVGBMNxYGq5UTEREVCAMN5ZGH24iIoAHD9SthYiIyAox3FgaDw+gfHmuVExERJRPDDeWiF1TRERE+cZwY4n04eb8eXXrICIiskKcCm6Jhg8HBgwAKlVSuxIiIiKrw3Bjiby81K6AiIjIarFbioiIiGwKw42l2rgR6NkT+P57tSshIiKyKgw3lurCBQk4u3apXQkREZFVYbgxIkUBUlKMdDH9jCluw0BERJQnDDdGcuYM8PLLwLhxRrogVyomIiLKF4YbI4mLA/btA/7zH8kjBVa2LODjI81BJ08a4YJERESFA8ONkbRqBXTpAqSnA5MnG+mi7JoiIiLKM4YbI5ozB7CzAzZtAg4dMsIFuQ0DERFRnjHcGFHt2sDQoXL//felR6lA/PwAJycgLa3AtRERERUWGkUp8K9gq5KQkACtVov4+Hi4ubkZ/fr//ANUqwY8eiQtON26FeBijx/Lnw4OxiiNiIjIauXl9zdbboysXDng3Xfl/uTJBWx0cXBgsCEiIsojhhsT+OADoHRp4OJFYPlyI120cDWwERER5RvDjQlotcC0aXI/OBhISirAxX77DWjQABgyxAiVERER2T6GGxMZNQqoUgWIiQHmzSvAhYoUAU6fBo4cMVptREREtozhxkQcHYFPPpH7n38O3LqVzwvpp4NfugQkJBilNiIiIlvGcGNCvXpJNklMBD76KJ8XKVMGqFBB7oeFGa02IiIiW8VwY0J2dsDcuXJ/yRLgr7/yeSF/f/nz6685sJiIiOg5GG5MrG1boGNHmRI+ZUo+L/LhhzL2ZtMmYO1ao9ZHRERkaxhuzGDOHECjAdavB44ezccFGjQApk6V+5MmccViIiKiHDDcmEH9+sCgQXL/gw/y2bM0ebJMwdq3T1pxiIiIKEvcfsFMrl+XbRlSUoBffwVeecVsb01ERGT1uP2CBfLxAcaNk/uTJgHp6QW84J49wO3bBa6LiIjI1jDcmNGkSUDJksD588D33xfgQp9/DrRrB4webbTaiIiIbAXDjRmVLJkxLnjaNODhw3xeqH17wN5eRiivX2+0+oiIiGwBw42ZjR4NVKwI3LwJfPVVPi/SsKFMD9dfkN1TREREBgw3ZubkBHz8sdyfMwe4cyefF5o6FahXT4LN2LFGq4+IiMjaMdyooF8/WbomISFj/6k8c3QEVqyQ7qm1a4H//teYJRIREVkthhsV2NnJmGAAWLgQuHIlnxfy85NRygDw1ltAfLxR6iMiIrJmDDcqad9ebo8fZwwyzpdp04DWrWUAjxnX7SEiIrJUXMRPRSdPAi++KPePH5eGmHxRFNnfgYiIyEZxET8r0bAhMGCA3M/3tgxA5mBz5w5w716BayMiIrJWDDcqmzVLxgbv2QPs2FHAi+3cCdSpw9lTRERUqDHcqKxSJWDMGLk/cWIBt2UoWVJabn76Cdi82QjVERERWR+GGwvw4YeAVgucOQOsXl2ACzVuLP1bADByJLuniIioUGK4sQClS2csODx1KpCcXICLBQcDtWsDsbEZO3USEREVIgw3FmLsWKB8eeD6dWDBggJcqGhRWdzPzg748Udgyxaj1UhERGQNGG4shLOzDC4GgE8/LWCPUpMmwPvvy/1//YvdU0REVKgw3FiQgQNlu6i4OGD27AJebMYMoFYtoFMn2aKBiIiokOAifhbm998ljzg6ApcuyQ7i+fbgAVC8uNFqIyIiUgsX8bNiQUFA27ZAaqrsrFAgTwYbRSngSGUiIiLrwHBjYTSajE01f/wROH3aCBe9cUOag0aONMLFiIiILBvDjQVq1Ajo00caWyZONMIFo6Jk+ePvvwe2bjXCBYmIiCwXw42F+uQTwMFBMsnu3QW8WLNmwPjxcn/ECOD+/QLXR0REZKkYbixUlSrAqFFy/4MPAJ2ugBecNQuoXh24eTMj6BAREdkghhsLNnUq4OYGnDwJrFlTwIs5OwPLl8ugnpUrgW3bjFEiERGRxWG4sWBlymSMuZkyBUhJKeAFmzcH3n1X7o8YIQvqEBER2RiGGwv3zjuAtzdw9Srw8cdGuOCsWUC1aoCLi3RRERER2RiGGwvn4gJ8+aXc/+QTYO9eI1xw61bg1CnZYJOIiMjGMNxYgV69gGHDZGr4gAHA7dsFvKC+5YaIiMgGMdxYia++AmrWlJ6koUMl6BRYero0C40ebaQLEhERqY/hxkq4ugJr1wJOTtKr9NVXRrjoqVPAe+8B334LzJtnhAsSERGpj+HGitSvn5FBPvgAOHGigBf08wPmzpX7EyYYYb45ERGR+hhurMyoUUD37sDjx7JFw4MHBbzg+PHAuHFyf/BgYN++gpZIRESkKoYbK6PRAMuWARUqAJcvS9gp0HAZjQb497+Bnj1lK/Ju3YBz54xVLhERkdkx3FihkiWBn34C7O2B1auBVasKeEF7e+CHH2SRv/h4oGNHIzQJERERqYPhxko1bw7MnCn3R48GIiIKeEFnZ+CXX4A6dWTfh+LFC1wjERGRGjSKUrjmACckJECr1SI+Ph5ubm5ql1Mg6elAhw7Anj1AgwbA4cNA0aIFvGhqKuDoaIzyiIiIjCYvv7/ZcmPF9L1J7u4yq/uDD4xw0SeDzZ07wKefcg0cIiKyKgw3Vs7bG/j+e7m/YAGwZYuRLvz4MdCmjezYOWWKkS5KRERkeqqHm4ULF6JSpUooWrQo/P39ERoamuP5cXFxGD16NLy8vODk5ITq1atj27ZtZqrWMnXqJDO6AVm9+MYNI1zUwUEW+AOA2bOBRYuMcFEiIiLTUzXcrF27FuPHj0dwcDDCwsLg6+uLwMBA3Lp1K8vzU1NT0b59e1y9ehUbNmxAREQEli5dinLlypm5cssze7asyXfvHtCvH5CWZoSLDh2aMWp5zBgZcExERGTh8jWg+Pr169BoNChfvjwAIDQ0FD/99BNq166NESNG5Po6/v7+aNy4Mb755hsAgE6ng4+PD8aOHYtJkyY9c/7ixYsxd+5cXLx4EQ4ODrl6j5SUFKSkpBgeJyQkwMfHxyYGFD/t8mXgxRdlFndwMDBjhhEuqijAv/4FLF0qM6r27AFeeskIFyYiIso9kw8o7tevH/bu3QsAiImJQfv27REaGoopU6bgo48+ytU1UlNTceLECQQEBGQUY2eHgIAAHD58OMvXbNmyBU2bNsXo0aPh4eGBunXr4tNPP0V6enq27zN79mxotVrDzcfHJw+f1Lq88AKweLHcnzUL2L/fCBfVaGTvqU6dgEePgC5dgL/+MsKFiYiITCNf4ebcuXNo0qQJAGDdunWoW7cuDh06hNWrV2PlypW5usadO3eQnp4ODw+PTMc9PDwQExOT5WuuXLmCDRs2ID09Hdu2bcO0adPw73//Gx9//HG27zN58mTEx8cbbtevX8/dh7RS/fpJb5JOB/TvLxOeCqxIEdm1s1EjwMZau4iIyPYUyc+LHj9+DCcnJwDA7t278eqrrwIAatasiejoaONV9xSdToeyZcviu+++g729Pfz8/PDPP/9g7ty5CA4OzvI1Tk5OhloLiwULgEOHZGG/oUNlBpVGU8CLFism25ErCvBUICUiIrIk+Wq5qVOnDhYvXowDBw5g165dCAoKAgDcvHkTpUuXztU13N3dYW9vj9jY2EzHY2Nj4enpmeVrvLy8UL16ddjb2xuO1apVCzExMUhNTc3PR7FJrq6ywbeTE/Dbb8DXXxvpwmXLZg42oaFGGrlMRERkPPkKN5999hmWLFmCNm3aoG/fvvD19QUgY2L03VXP4+joCD8/P4SEhBiO6XQ6hISEoGnTplm+pnnz5rh8+TJ0Op3h2KVLl+Dl5QVHrqqbSYMGsh8mIIv7hYUZ+Q1WrZI9IN56i4v8ERGRZVHyKS0tTbl3716mY5GRkUpsbGyur7FmzRrFyclJWblypXLhwgVlxIgRSokSJZSYmBhFURRl4MCByqRJkwznR0VFKcWLF1fGjBmjREREKL/99ptStmxZ5eOPP871e8bHxysAlPj4+Fy/xlrpdIrSrZuiAIpSrZqiJCQY8eKbNyuKnZ1cfNYsI16YiIjoWXn5/Z2vlptHjx4hJSUFJUuWBABcu3YN8+fPR0REBMqWLZvr6/Tu3RtffPEFpk+fjgYNGuDUqVPYvn27YZBxVFRUpjE8Pj4+2LFjB44dO4b69evj7bffxrhx47KcNk4yzmbZMsDHRyY4jRljxIt37SqDewBg2jQglwPJiYiITC1f69x06NABPXr0wMiRIxEXF4eaNWvCwcEBd+7cwbx58zBq1ChT1GoUtrRxZm4dOCA7Keh0slXDoEFGvPjkycCcOTKj6rffgMBAI16ciIhImHydm7CwMLRs2RIAsGHDBnh4eODatWtYtWoVvjba6FUylpYtMxb0e+st4NIlI17800+BAQNkYPFrr5lgcA8REVHe5CvcPHz4EMWLFwcA7Ny5Ez169ICdnR1eeuklXLt2zagFknF8+KG03iQlAX36AE8s2lww+r6vdu2AxESZpkVERKSifIWbF154AZs3b8b169exY8cOdOjQAQBw69atQtPVY23s7YEffwRKlwZOngQmTjTixR0dgf/+F1i4EPjsMyNemIiIKO/yFW6mT5+OCRMmoFKlSmjSpIlh6vbOnTvRsGFDoxZIxlOunIy5AYCvvgJ+/dWIF9dqpc9Lv1pgWhqQnGzENyAiIsqdfA0oBmRPqejoaPj6+sLOTjJSaGgo3NzcULNmTaMWaUyFcUDx08aPB778UlpxTp0C/r//qfEkJQF9+0qLzrp1gJ2qm88TEZENyMvv73yHG70bN24AgGGHcEvHcCPjbZo1k7G/rVsDISHSbWU0R48CrVoBqaky2HjZMgk6RERE+WTy2VI6nQ4fffQRtFotKlasiIoVK6JEiRKYNWtWptWDyTI5Ocm432LFZOfwWbOM/Ab+/sAPP2QM9OnSBXjwwMhvQkRElLV8hZspU6bgm2++wZw5c3Dy5EmcPHkSn376KRYsWIBp06YZu0YygWrVgEWL5P7MmcA33xj5DXr1kkE9Li7Azp1A27bArVtGfhMiIqJn5atbytvbG4sXLzbsBq73yy+/4K233sI///xjtAKNjd1SmU2alDHBacECI69iDMjmmp07A3fuAFWrAjt2yJ9ERER5YPJuqXv37mU5aLhmzZq4d+9efi5JKpk9O2Na+NixJmjBadIEOHgQqFQJuH1b1sIhIiIyoXyFG19fX3yTxW/Bb775BvXr1y9wUWQ+Go0ZAk716sDhw8DvvwP/30GeiIjIVIrk50Wff/45OnfujN27dxvWuDl8+DCuX7+Obdu2GbVAMj19wAGki2rsWLlv1C4qT0+56R06BFy9CvTrZ8Q3ISIiymfLTevWrXHp0iV0794dcXFxiIuLQ48ePXD+/Hn88MMPxq6RzMAsLTh6UVHAK68A/fsD//63id6EiIgKqwKvc/Ok06dP48UXX0R6erqxLml0HFCcM0WRjb5NOshYpwPeew+YP18ejx8PzJ3Lxf6IiChbJh9QTLbLLC04dnbAvHkSaAC5P2CALPpHRERUQAw39Ax9wJk0SR6bJOBoNMCECbLYX5EiwM8/y5TxhAQjvxERERU2DDeUJY0G+PRTEwccQFpsfvsNcHUFdu/OGNlMRESUT3maLdWjR48cn4+LiytILWRh9AEHAObMMdEsKgAIDAT27ZOBPsHBRr44EREVNnkKN1qt9rnPDxo0qEAFkWXJKuAoSkbQMZpGjYD16zMe63TAlSvACy8Y+Y2IiMjW5SncrFixwlR1kAV7OuC8/bbcN3rAedLkycDChcCGDUBQkAnfiIiIbA3H3FCuPD0G5+23ZZq4STx+DJw8CSQlyY7iXDuJiIjygOGGcs1sAcfBQQYZ9+8PpKUBgwYBn38u/WFERETPwXBDeWK2gOPoCKxaJdPFAVl4Z/x4GYtDRESUA4YbyjN9wJk8WR6bLODY2clCf/otGubPB4YONcEbERGRLWG4oXzRaIBPPjFDwAGkxWb1asDJCejY0URvQkREtiJfu4ITARkBB5C190w6i6pfP6BVK6B8+Yxj6emAvb0J3oyIiKwZW26oQMzagvNksPnnH6BOHeDXX030ZkREZK0YbqjAzBpw9ObMASIigFdfBaZMkVYcIiIiMNyQkZg94Pz73xn9X59+Kls43L5twjckIiJrwXBDRpNVwFm40ERv5ugIfP018NNPgIsLEBICvPgicOSIid6QiIisBcMNGdXTAWfMGOD77034hn37AqGhQPXqwI0bMuh4504TviEREVk6hhsyOn3AGTdOHr/xhmwRZTJ16gDHjgGvvSYhp3lzE74ZERFZOoYbMgmNBvjyS2DYMFlUuF8/YNs2E76hmxuwbh2wfz/g6irHdDrg+nUTvikREVkihhsyGY0GWLIE6NNH9sLs2RPYt8/Eb1i6dMbjzz+XVp2NG034pkREZGkYbsik7O1li6guXYDkZPnz6FEzvHF6uoy9efBAUtX778smnEREZPMYbsjkHBykx6hdOyAxEQgKAk6fNvGb2tsDO3YA770nj7/4QgqIiTHxGxMRkdoYbsgsihYFNm8GmjUD4uKA9u1lDT6TcnCQULN+PVCsGPDHHzJd/M8/TfzGRESkJoYbMptixYCtW4GGDWW9vYAA4OpVM7zxa68Bx48DtWsD0dGy4N+dO2Z4YyIiUgPDDZlViRLSW1SrlixL064dcPOmGd64Rg0Z7NO3r7TmuLub4U2JiEgNGkVRFLWLMKeEhARotVrEx8fDzc1N7XIKrZs3gZYtgStXpEFl/34z5Q39j7tGI3+ePSvjc2rXNsObExFRfuXl9zdbbkgV3t6yY0K5csCFC9JTFB9vhjfWaDKCTVwc0K0b0KQJsHatGd6ciIjMgeGGVFOpErB7N1CmDBAWBnTuDCQlmbGAtDQpIilJFuN55x1ZkIeIiKwaww2pqmZNYNcuGYtz8KA0pCQnm+nN3d1lAJB+I6yvvgLatpXBQEREZLUYbkh1vr7A77/Lrgm7dwO9e5uxAaVIEeDTT2WeulYrCat+fVmYh4iIrBLDDVmEl14Cfv1V1sPZsgUYPFgWGTabrl1lunjjxsD9+8APP2QMPiYiIqvCcEMWo21b2T28SBHg55+BkSPNnC9eeEFabj7+GPjPfzIGHjPkEBFZFYYbsiidOwM//QTY2Um+eO89M2cLBwdgyhTAwyPj2JAhwMSJQEqKGQshIqL8Yrghi/P668CyZXL/yy+BGTNULCY0VHb+/Pxz6Ts7f17FYoiIKDcYbsgiDRkCLFgg9z/6CJg7V6VCmjQBNm0CSpcGTp0C/PxkVpVOp1JBRET0PAw3ZLHGjJGJTADwwQfAokUqFdKtm6xkHBQkXVPvvCP3//lHpYKIiCgnDDdk0SZPzliG5q23ZBKTKry8gG3bgIULAWdnWZwnMJAtOEREFojhhizeJ58AY8fK/SFDgI0bVSpEo5GEFRYGNGokfWV2/CdERGRp+F9msngaDTB/vgQbnU52Sti+XcWCataUHcY7dsw4tnkzcOCAaiUREVEGhhuyCvqp4b16yerFXbrIcjRpaSoWpHftmqw62Lq19KGlpqpUFBERAQw3ZEXs7WXMTd++EmqmTQNatAAuXVK5sJIlgZ49ZUGeOXNkynh4uMpFEREVXgw3ZFUcHYHVqyXkaLXSO9SggYzzVW0hYTc3YPly4L//BUqVAk6eBF58Ueayc3VjIiKzY7ghq6PRAAMGyOzsdu2AR49k2nhgoMobevfoIUUFBsrW5m+/DXTqpGLfGRFR4cRwQ1bLxwfYuRP4+mvZcHPXLqBePdm+QbUGE29v2eJ8wQIpqlYt2SyLiIjMRqMohavdPCEhAVqtFvHx8XBzc1O7HDKSixeBQYOAY8fkca9ewLffysLCqhZVqZKEHACIjJQuLFWLIiKyTnn5/c2WG7IJNWsChw4BM2fKwON164C6daURRdWi9MFGpwP695djq1ZxLA4RkQkx3JDNKFIEmD4dOHJEMkRMjAx5GTkSSExUubjYWODBA+DOHZk2/vLL0rJDRERGx3BDNqdRI1lE+J135PGSJYCvL3DwoIpFeXlJUXPmyPYN+/YB9evLfPZHj1QsjIjI9jDckE1ydga+/BIICZGBx1euAK1ayRp7KSkqFeXgAEycCJw/L01Kjx/LSoT16sl4HCIiMgqGG7JpL78ss7MHD5ZhL3PmAE2aAGfOqFhU5crAb78BGzbI7Co3N0lgRERkFAw3ZPO0WmDlStlw091dgk3jxsDnnwPp6SoVpdHIqsbh4cD69RnTxZOTpVjVCiMisn4MN1RodO8OnDsn+1KlpkoPUZs20mWlGjc3oGrVjMezZwNDhwLNmgGnTqlWFhGRNWO4oULFwwP45Rdg2TKgWDHgzz9lXO/SpRYyO9vbGyheHAgNBfz8gPHjZZYVERHlGsMNFToaDfDGG9I91aoVkJQEjBghLToxMSoX969/yRTx3r1lkNCXXwK1awObNllI+iIisnwMN1RoVa4M7N0LfPGFbMi5dass/DdvHhAXp2Jh3t7AmjWyAmGVKrJhVo8ewKefqlgUEZH1YLihQs3ODnjvPeDECdld/O5deVy+PPDWWzLeVzVBQTJIaMoUGRXdr5+KxRARWQ+LCDcLFy5EpUqVULRoUfj7+yM0NDTbc1euXAmNRpPpVlS/xD1RPtWtCxw9Cnz3ndxPSgIWLZIeoQ4dZOa2TqdCYc7OshbOtWvS1KT3ySey3wQRET1D9XCzdu1ajB8/HsHBwQgLC4Ovry8CAwNx69atbF/j5uaG6Ohow+3atWtmrJhslaMj8OabMhZnzx6gWzdp2dm1S8bjVK8uQ2BU6bLSajPuHzgATJ0KNG8uY3Tu3VOhICIiy6V6uJk3bx7efPNNDB06FLVr18bixYvh4uKC5cuXZ/sajUYDT09Pw83DwyPbc1NSUpCQkJDpRpQTjQZo21bG8F6+DEyYAJQoAfz9t0xeKl8eGD1axa2hatWS6eKANDXVrClr46jStEREZHlUDTepqak4ceIEAgICDMfs7OwQEBCAw4cPZ/u6xMREVKxYET4+PujatSvOnz+f7bmzZ8+GVqs13Hy4EizlQeXKwNy5MqZ38WKgTh3psvr2W8kYgYEyENmsucLdHVi+HNi/X4q4fVvCjr8/u6qIiKByuLlz5w7S09OfaXnx8PBATDZzcmvUqIHly5fjl19+wY8//gidTodmzZrhxo0bWZ4/efJkxMfHG27Xr183+ucg2+fqKj1AZ8/KflVdu0oLz86dwCuvSJfVV18B8fFmLKpVK1no7/PPZW2c48eB115TcfMsIiLLoHq3VF41bdoUgwYNQoMGDdC6dWts3LgRZcqUwZIlS7I838nJCW5ubpluRPml0ch+VZs3S5fVe+/JcJi//5ZdyMuXB8aMMWOXlaMj8P77wF9/AcOGyQrHTk7ynE7HHceJqFBSNdy4u7vD3t4esbGxmY7HxsbC09MzV9dwcHBAw4YNcfnyZVOUSJStKlVkjZx//pEuq9q1gcREYOFC6S0KCgK2bTNTl5WHB/Cf/8gOoXo//QTUqCFr5nABQCIqRFQNN46OjvDz80NISIjhmE6nQ0hICJo2bZqra6Snp+Ps2bPw8vIyVZlEOdJ3WZ07B+zeDbz6qrTw7NgBdO4s+eLrrwGzj2VftAi4fh3o2xdo2VK6rYiICgHVu6XGjx+PpUuX4vvvv0d4eDhGjRqFpKQkDP3/bJBBgwZh8uTJhvM/+ugj7Ny5E1euXEFYWBgGDBiAa9euYfjw4Wp9BCIAEmjatZO9qy5flplVWq3cHzcOqFBBlqdJTDRTQbt3Ax99BLi4AAcPylboQ4cC0dFmKoCISB2qh5vevXvjiy++wPTp09GgQQOcOnUK27dvNwwyjoqKQvQT/zG+f/8+3nzzTdSqVQudOnVCQkICDh06hNq1a6v1EYieUaUK8O9/yyyrb7+V2drx8bI8TdWqwIIFZhj36+wMTJsGREQAAwbIsZUrZfTzqlUmfnMiIvVoFKVwdcYnJCRAq9UiPj6eg4vJbHQ6GfoybRpw5Yocq1QJmDkT6N8fsLc3QxFHjkgTUmioTCNv1coMb0pEZBx5+f2tessNUWFgZydbQ128KENhvLyAq1dl/K+vr8y+Mvn/Zrz0EnD4sOwW+mSwWb1almUmIrIRDDdEZuTgAIwcKeNw5swBSpYEzp8HuncHmjaVbR9Mys4OaNMm4/H167LnRMOGwKhRsiAgEZGVY7ghUoGLCzBxonRRffihPD56VAYkt28PHDtmpkLs7GQVQp1O5rNXqyYbaKWmmqkAIiLjY7ghUlGJEjKD6u+/ZfE/BweZ5NSkiSw2HB5u4gLKlQPWrZMxOA0ayKjn8eOBevVkkR4iIivEcENkATw9ZQZVRAQwaJBMK//vf4G6dYE33gBMvvF9q1ayDs7SpUCZMsClS9JXdvOmid+YiMj4GG6ILEjlysD338seVt26SW/RihUye3vcOODWLRO+ub09MHy4bOUwYQIwaRLg7Z3x/NmzJnxzIiLjYbghskB16gCbNsns7bZtZQjM11/L+jnTp5t4g06tVrZCnzkz49iRI0D9+lLMnj3czoGILBrDDZEF8/eXXch37gQaNQKSkoBZszL2tTLbvphhYTIgaN8+GfXcogWwfTtDDhFZJIYbIgun0cgMqtBQYMMGWe343j3ZDLxaNeC774C0NBMX8dZbMup59GjZdfzQIaBjRxn5vGULQw4RWRSuUExkZdLSgB9+AGbMAKKi5FizZsD69ZmHyJhMdLR0Wy1eLE1HFSrIOB1HRzO8OREVVlyhmMiGFSki+19eugTMny9DZA4dAvz8gD//NEMBXl7AvHmyxPLEiTI2Rx9sHj+W5qX0dDMUQkSUNYYbIivl5CQzqI4flynjMTEy3vebb8zUS1S2rCyzPGRIxrGffgJefx2oVUs26Xz82AyFEBFlxnBDZOVeeEEmM/XpI11WY8fKnlUPH6pQzOPHQKlS0k01dChQo4YMCuKKx0RkRgw3RDbA1VUaTebNk+VqfvgBaN4ciIw0cyHDh0t31eefS8tOZCTwr38BVatKk5JOZ+aCiKgwYrghshEaDfDuu7J9Q9mywKlTMg5nxw4zF1K8uEzlioyUQUHe3sCNG8DGjbKXFRGRifG/NEQ2pk0b4MQJWSPn/n2Zsf3JJyo0mri4yKCgv/8Gvv1WFujRu31bWncSE81cFBEVBgw3RDaofHnZC/Nf/5LBxVOnAj16mHhl4+wULQqMGiX9ZHrz5slMq0qVZFDygwcqFEZEtorhhshGOTnJUjT/+Y/M1P7lF1lz78IFtSsD0LChrEB49y4webKEnNmzGXKIyCgYbohs3LBhsv6Nj4+sjdOkiSxFo6pevSRlrVolu4Leuwd8+KGEnC++ULk4IrJ2DDdEhUDjxjIO5+WXZX+q11+XXiGTb9uQkyJFgIEDJeT8+KNMG793T8boEBEVAMMNUSFRpozMnHr/fXn8+edAUJCM7VWVvT3Qvz9w/jywerV0U+mdOiUDkVUZLERE1orhhqgQKVJEQs26dbI2TkiI7DZ+/LjalUFCTr9+sleV3syZwPTp0l310UdAXJxa1RGRFWG4ISqEXn8dOHpUxvRGRQEtWgDLl6tdVRb69gVq15ZQExwsIWfGDIYcIsoRww1RIVWnDnDsGPDqq0BKigw8HjlS7luMXr2As2eBtWul4Ph4ac2pVAn46iu1qyMiC8VwQ1SIabXApk0yrEWjAZYskUUA//lH7cqeYGcnIefMGelPq1tXQo5ZdgclImvEcENUyNnZySJ/W7cCJUvKJpwvviiLAFoUOzvpTzt9Gvjvf2WFQr1Nm+RD3LunXn1EZDEYbogIgGzTcPw44OsL3LoFtGtnoTsk2NnJcsvOzvJYp5Ng88knQMWKwKRJsqAPERVaDDdEZFClCnDokMzMTk+XtXDKlpVeoY0bgUeP1K4wCxqNBBtfX0lin30ma+a8+KKks2vX1K6QiMxMoyiFq+M6ISEBWq0W8fHxcHNzU7scIoukKMB338liwZcvZxwvXhzo1g3o0wcICJBtHSyGTgds2SKF79qVsUJhr14yIJmIrFpefn+z5YaInqHRyJCWS5dkZeP335ftGx48AH74AejcGfDyAkaMAPbskVYe1dnZSfLatg2IjpbR0W3byto5euHhskzzd98Bd+6oVioRmRZbbogoV3Q6GWy8Zo1MWoqNzXjOw0MaSPr0AV56SXKGRQoOlsUAAVnRsH17oHdvCUVaraqlEVHO8vL7m+GGiPIsPV1mU61ZI5tw3r+f8VyFCpIX+vSRzb81GvXqfEZUlHRRrVkDhIVlHHd0BDp1AhYuBLy91auPiLLFcJMDhhsi40pNBXbvlrywebN0XelVqyYhp08fWWjYoly6JEHn55+lu0qrleYoJyd5/uJFoHLljMdEpCqGmxww3BCZzqNHwO+/S9D59VcgOTnjuXr1pEWnd2/ghRfUq/EZigKcOydhp2fPjGPVqsm4nO7dpeh27QAHB3VrJSrEGG5ywHBDZB4PHkjAWbMG2L4dePw447lGjWSrh0GDLDQv3LwJ+PsDN25kHCtdWva6GjFCkhoRmRXDTQ4YbojM7/59WUR4zRrZiVynk+NVqgDTpgEDBsj4Xoui08miP2vWAOvXy8qGetOnyx5XRGQ2nApORBalZEngjTeAnTulUWTuXFkc8MoVYOhQoFYtmWJuEVPK9ezsZLv0b76Rzba2b5duqyJFZDq5XlSUbO5JRBaD4YaIzMrDA5gwQYLN558D7u6yUOCgQbLx908/WVjIASTQBAbK1LAbN4BWrTKe+/e/gfr1gWbNgO+/Bx4+VK9OIgLAcENEKnF1lcUBIyOB2bOBUqWAiAjZ+qFePZnIpO++sigeHpnntz98KOHn8GFgyBCgXDng7bdlkDIRqYJjbojIIiQkAAsWSEOIft2cunVl3b0ePSx4YUBAVkResQJYuhS4ejXjeNeuMj+eiAqMY26IyOq4uQFTpkhLzsyZsuzMuXPA66/LYoCbNskMbYvk5QV8+CHw998yNqdHD8DeHqhePeMcnU7W0yEik2PLDRFZpLg44MsvgfnzpVUHkJAzYwbQpYuFrXyclehoaW7y8JDHO3fKuJ0WLWQ6+WuvAc7O6tZIZEXYckNEVq9ECWnBiYyUFp1ixYCTJ6Wnp0kTYOtWC27JAaQ1Rx9sAOD0aWnN+fNPGT1drhzwzjvAhQuqlUhkq9hyQ0RW4c4dGY+zYAGQlCTHmjSRABQYaAUtOYDMg1++XMbmREVlHG/eXPawKFpUvdqILBxbbojI5ri7y6yqyEiZZeXiAoSGAh07ZmQDi/9fNW9vYOpUmQe/bZvsRm5vD9y7lznYzJoFfPutbAlh8R+KyPKw5YaIrFJsrKyT8+23GXtYtWghKx63aSMbfVuFf/6Rgcj6tXNSUmTVw0eP5HH58kBAgOxt1a6ddHcRFULcfiEHDDdEtiU6GvjsM2DxYskFgIzT9fcHWraUwNO0KVC8uLp15tqDB9L3tns3cPCgbLv+pOHDpVuLqJBhuMkBww2RbfrnH2DOHODnn4G7dzM/Z2cHNGiQEXZatAA8PVUpM28ePpSAs3u33E6elA/5wQfyfEyMTDvXt+y89BLg5KRuzUQmwnCTA4YbItum08lKxwcOyMSkAwcyr6un98ILGWGnZUt5bPGDku/elSJLlZLHq1fLrqN6Li7SvdWunQSe+vUtfPVDotxjuMkBww1R4XPjhgQd/e3MmWfH6Xp4ZLTqtGwJ+Ppa4E7lT4uJkYHJu3fLdutP7lwOyEZdffuqUxuRkTHc5IDhhoji4mQrKH3rTmhoxngdvWLFZKyOPuz4+0vDiMVSFFnSWd+F9ccfwF9/ZfS//ec/EoBefx0ICrLwD0P0LIabHDDcENHTkpOBEycyws7BgxKAnlSkiLTmNG4st0aNgNq1Lbh1Jy0tc3EtW8qHA2TX0s6dZZXkTp3kMZGFY7jJAcMNET2PTgecP5953M6NG8+e5+IiW0I8GXheeMFCh7mEhgLr1wMbNmQehOTsDHTvDvz4oxUMOqLCjOEmBww3RJQf165JPjh+HDh2TP588ODZ87RaCTn6sNO4MeDjY0G5QVGkmWrDBgk7V64Ar7wC/Pprxjlbt0pLD/8bSRaE4SYHDDdEZAw6nSwgrA86x47JTG39goJPKls2c+tO48ZyTHWKApw6JX+++KIcu3oVqFxZVkEMDJSuq1dflc2+iFTEcJMDhhsiMpXHj6U768nAc/asDH95WoUKGWHH318GL1vE1lIHDwLDhsl8ej0HB6B9exmM3LWrrKBMZGYMNzlguCEic3r0SDYEfzLwXLz47FR0Z2egbVuZyBQUpPK6O4oiKU3fdfXkzuVr1wK9esl9nc5CBxiRLWK4yQHDDRGpLSEBCAvLCDt//ikbhj+pSpWMoNO2rUxNV82FCxJ0fv0V2Ls3o5hp04CNG6VVp317oHVrlQslW8ZwkwOGGyKyNPolarZvl9uBA9LFpefgION79WGnbl0LGaDctClw5EjGYwcHOdahg4SdRo3YskNGw3CTA4YbIrJ0iYnSQLJjB/D77zKh6Une3jLWNyhIdlnQ78ZgdvfuAXv2ALt2ATt3Zp5iXqqUrJhsby+P79/nWB0qEIabHDDcEJG1uXw5o1Vnzx4Zx6NnZycDkvWtOn5+GXnCrBQF+PtvCTq7dgGlS2fsXq4oMoLayUladDp0kL42zsCiPGC4yQHDDRFZs+RkGaOjDzvnz2d+vnRpyQ6BgXKziN3Po6KAqlUzTxuzswOaNJGw07WrpDKiHDDc5IDhhohsyfXr0n21fbtsKRUfn/n58uVlU9Dn3UqVMvHwmIQEYP9+6b7atSvzVPNx44D58+V+Sor0w9WsaSEDi8hSMNzkgOGGiGxVWhpw9GhGq87x47l/rb29LCxYtuzzg5C7uxH21IqKkjS2cyfw5ptAu3ZyfM8eue/hAbRpI91XbdoA1asz7BRyDDc5YLghosLizh1pBLl1C4iNzf52717erqvRSPZo0UK6vjp0kCE1RvHdd9KS8/RSz15eEnI+/FCmi1Ghw3CTA4YbIqLMUlOB27dzDkD6gHT79rMLEAJAjRoZQafAy90kJ8tGXnv3Avv2AYcPS3cVINtF+PrK/T/+AP76S1p3Kldmy46NY7jJAcMNEVH+padLi9Dlyxm9SkeOyGLFeg4O0qrToYPcGjQo4Hie5GR5kz//lJYb/cUGDQJ++EHu+/hkdGG1bQtUqlSANyRLxHCTA4YbIiLjiouToTI7d8rg5ieXuwGAMmUyZoC3by/r9BjF/PmycnJoaOZVDwFpyblwwUI27CJjYLjJAcMNEZHpKIq06uzcKbc9e2RRwifVrZvRhdWypeyrVSBJScChQ9KFtXev7GlRp450YekNGiRNSq1by61ixQK+KZkbw00OGG6IiMzn8WMZMqMPO8ePZx6zU7Qo0KpVRheWUbaWSEwE/vlHBgIBsuphiRIyuEivQoWMoNOmjazDQxbN6sLNwoULMXfuXMTExMDX1xcLFixAkyZNnvu6NWvWoG/fvujatSs2b96cq/diuCEiUs/duxljdXbskAzyJC8v2ZKqZElZe6dkyZxvTk65eNPUVCAkRFp1/vhDElZ6esbzXboAW7ZkPI6I4NRzC2RV4Wbt2rUYNGgQFi9eDH9/f8yfPx/r169HREQEypYtm+3rrl69ihYtWqBKlSooVaoUww0RkZVRFCA8PKNVZ9++zFtL5Iaz8/MDkP5WurQ05pRyTJTmpP37Jey8/jowdqxc8No1GYxcpow0KbVqJa079epxE1CVWVW48ff3R+PGjfHNN98AAHQ6HXx8fDB27FhMmjQpy9ekp6ejVatWeOONN3DgwAHExcUx3BARWbnkZBk6c/my7LOZ0y0uLusp6blRvrzMJn/y9sIL/9+Ta8cOoHv3Z1NWiRIyQOidd4CXXy7YB82D9HSV9gqzQHn5/V3QNSYLJDU1FSdOnMDkyZMNx+zs7BAQEIDDhw9n+7qPPvoIZcuWxbBhw3DgwIEc3yMlJQUp+vURIH85RERkeYoWldyQm+yg08mODs8LQU/eYmNlu4obN+S2dWvG9VxcZLyPr28gfGcnwNfhAurH7oLb0V3AwYOSpn79VQYm6505Ixdp3Vr60hwd8/yZ09OBmzdlscXIyGf/jI6WHrL27WUH+LZtAa02z29T6Kgabu7cuYP09HR4eHhkOu7h4YGLFy9m+Zo///wTy5Ytw6knR8HnYPbs2Zg5c2ZBSyUiIgtiZyeNKSVKyKzv3IqPl0xy+nTG7dw54OFDmVEeGgrIr8b6AOqjcuX34NtOB98y0fBNPQbfii1RSff/HqotW4Bp0+TCTk5Aw4ayRbu/v2wKWqUKoNHg/v1ng4v+/tWrz85if9qlS3JbuFBacZo0kaDTvr28VT4ylc1TNdzk1YMHDzBw4EAsXboU7u7uuXrN5MmTMX78eMPjhIQE+Pj4mKpEIiKyYFqt9C61bJlxLD1dusKeDDynT0vrTmQkEBlph80oB6AcsAooXhyoXx/wdesP34bu8L2yCSXiryLyiBaRR1JwBTcQCQdcqemFyBgXxMXlXFORIjLMp3JlyUNP/unpKeOfd++W/UYvXZLhQocPA7NmyUrQrVtL0GnfHqhVi+OgAZXH3KSmpsLFxQUbNmxAt27dDMcHDx6MuLg4/PLLL5nOP3XqFBo2bAj7Jzogdf9fFtPOzg4RERGo+pzpfBxzQ0REuXH37rOtPOfPZ55RnlueznGo/OgCqhS7jcqVFFSp54rKLcqhSvuqKFfFKdfjavT7je7aJX/euZP5eW/vjFaddu1k9pmtsLoBxU2aNMGCBQsASFipUKECxowZ88yA4uTkZFy+fDnTsalTp+LBgwf46quvUL16dTg+p32O4YaIiPLr8WOZKf50K09SkrS0GFpdKqSjSjV7VKkirTIur3cGtm179oIODsCLLwIHDsj9PNDpJHzt2iW3Awee3W+0bt2M8TqtWwOurvn/7GqzqnCzdu1aDB48GEuWLEGTJk0wf/58rFu3DhcvXoSHhwcGDRqEcuXKYfbs2Vm+fsiQIZwtRURElu/evYyBPUePyu3uXelLunAh47yuXSWlPDl+p0yZ514+OVnGPutbdsLCMs8oc3AAmjXLCDuNGsnxtDS5padn3C/o45IlZfCzMVnNbCkA6N27N27fvo3p06cjJiYGDRo0wPbt2w2DjKOiomDHtQWIiMjalSoFBAXJDZDkERkpW67rpaVJOnn4UBb/0atSRYJO+/bA0KFZXr5oUemKatcOmD1buqz27s1o2bl6VZb22b8fmDrVdB8TkBB18KBp3yMnqrfcmBtbboiIyGLpdMDJk9KqExoqu6FHRGQ8/8orMiVd78MPZR8tf3/ZQiKb0cSKIjO09EFnzx7kONDZ3l4GOuv/fPL29LGszqlbF1i0yDh/JXpW1S1lbgw3RERkVe7fl81Ajx6VRW9695bjN24AT87+LV1aurD03Vn+/tI/lIX0dOkRyyqo2Ntb5owrhpscMNwQEZFNuHED+OILCT1hYc9O4xo3Dpg/X+4nJ8uCPvXrW+3COFY15oaIiIjyoXz5jPCSkiLTtvQDlY8eBV56KePc0FCZLuXkBPj5ZQxUbtjwib0nbAdbboiIiGyRomT0L61bB4wcKV1cT3NxAVatAnr2lMcPH8rrnJ3NV2su5OX3N6chERER2aInB8706iWDbCIiJMi89Za03jg7S5gpVy7j3J9+kmWY69YFBgyQrq+QEHm9lWC3FBERUWGg0ciA5OrVgYED5Vh6OvDXX5k36IqIkOPnz8tt9eqM58qXl9laDRrI4+Rk6eqysBHI7JYiIiKiDIoi25GfPAmcOiW3kyeBv/+W52/dylhUcNIkYPFiCTv6m58fUK+e0cvigGIiIiLKH41GNqny9gY6d844npAgLTlPrpZ85oxsta5fHRAAfH0lEKmI4YaIiIiez80NaNo087HNm4Hw8IwWnlOnZLq5ytgtRURERBaPs6WIiIio0GK4ISIiIpvCcENEREQ2heGGiIiIbArDDREREdkUhhsiIiKyKQw3REREZFMYboiIiMimMNwQERGRTWG4ISIiIpvCcENEREQ2heGGiIiIbArDDREREdkUhhsiIiKyKUXULsDcFEUBIFunExERkXXQ/97W/x7PSaELN3fv3gUA+Pj4qFwJERER5dWDBw+g1WpzPKfQhZtSpUoBAKKiop77l2OtEhIS4OPjg+vXr8PNzU3tcoyOn8/62fpn5Oezfrb+Ga3x8ymKggcPHsDb2/u55xa6cGNnJ8OMtFqt1Xyh+eXm5mbTn5Gfz/rZ+mfk57N+tv4Zre3z5bZRggOKiYiIyKYw3BAREZFNKXThxsnJCcHBwXByclK7FJOx9c/Iz2f9bP0z8vNZP1v/jLb++TRKbuZUEREREVmJQtdyQ0RERLaN4YaIiIhsCsMNERER2RSGGyIiIrIpNhluFi5ciEqVKqFo0aLw9/dHaGhojuevX78eNWvWRNGiRVGvXj1s27bNTJXm3ezZs9G4cWMUL14cZcuWRbdu3RAREZHja1auXAmNRpPpVrRoUTNVnDczZsx4ptaaNWvm+Bpr+v4AoFKlSs98Ro1Gg9GjR2d5vqV/f3/88Qe6dOkCb29vaDQabN68OdPziqJg+vTp8PLygrOzMwICAvDXX38997p5/XdsKjl9vsePH2PixImoV68eXF1d4e3tjUGDBuHmzZs5XjM/P+em9LzvcMiQIc/UGxQU9NzrWsN3CCDLf48ajQZz587N9pqW9B3m5vdCcnIyRo8ejdKlS6NYsWLo2bMnYmNjc7xufv/tWgKbCzdr167F+PHjERwcjLCwMPj6+iIwMBC3bt3K8vxDhw6hb9++GDZsGE6ePIlu3bqhW7duOHfunJkrz539+/dj9OjROHLkCHbt2oXHjx+jQ4cOSEpKyvF1bm5uiI6ONtyuXbtmporzrk6dOplq/fPPP7M919q+PwA4duxYps+3a9cuAMDrr7+e7Wss+ftLSkqCr68vFi5cmOXzn3/+Ob7++mssXrwYR48ehaurKwIDA5GcnJztNfP679iUcvp8Dx8+RFhYGKZNm4awsDBs3LgRERERePXVV5973bz8nJva875DAAgKCspU788//5zjNa3lOwSQ6XNFR0dj+fLl0Gg06NmzZ47XtZTvMDe/F9599138+uuvWL9+Pfbv34+bN2+iR48eOV43P/92LYZiY5o0aaKMHj3a8Dg9PV3x9vZWZs+eneX5vXr1Ujp37pzpmL+/v/Kvf/3LpHUay61btxQAyv79+7M9Z8WKFYpWqzVfUQUQHBys+Pr65vp8a//+FEVRxo0bp1StWlXR6XRZPm9N3x8AZdOmTYbHOp1O8fT0VObOnWs4FhcXpzg5OSk///xzttfJ679jc3n682UlNDRUAaBcu3Yt23Py+nNuTll9xsGDBytdu3bN03Ws+Tvs2rWr8vLLL+d4jiV/h0//XoiLi1McHByU9evXG84JDw9XACiHDx/O8hr5/bdrKWyq5SY1NRUnTpxAQECA4ZidnR0CAgJw+PDhLF9z+PDhTOcDQGBgYLbnW5r4+HgAGRuCZicxMREVK1aEj48PunbtivPnz5ujvHz566+/4O3tjSpVqqB///6IiorK9lxr//5SU1Px448/4o033oBGo8n2PGv6/p4UGRmJmJiYTN+RVquFv79/tt9Rfv4dW5L4+HhoNBqUKFEix/Py8nNuCfbt24eyZcuiRo0aGDVqFO7evZvtudb8HcbGxmLr1q0YNmzYc8+11O/w6d8LJ06cwOPHjzN9HzVr1kSFChWy/T7y82/XkthUuLlz5w7S09Ph4eGR6biHhwdiYmKyfE1MTEyezrckOp0O77zzDpo3b466detme16NGjWwfPly/PLLL/jxxx+h0+nQrFkz3Lhxw4zV5o6/vz9WrlyJ7du3Y9GiRYiMjETLli3x4MGDLM+35u8PADZv3oy4uDgMGTIk23Os6ft7mv57yMt3lJ9/x5YiOTkZEydORN++fXPcjDCvP+dqCwoKwqpVqxASEoLPPvsM+/fvR8eOHZGenp7l+db8HX7//fcoXrz4c7tsLPU7zOr3QkxMDBwdHZ8J3M/73ag/J7evsSSFbldwWzJ69GicO3fuuf28TZs2RdOmTQ2PmzVrhlq1amHJkiWYNWuWqcvMk44dOxru169fH/7+/qhYsSLWrVuXq/+TsjbLli1Dx44d4e3tne051vT9FWaPHz9Gr169oCgKFi1alOO51vZz3qdPH8P9evXqoX79+qhatSr27duHdu3aqViZ8S1fvhz9+/d/7qB9S/0Oc/t7wdbZVMuNu7s77O3tnxkBHhsbC09Pzyxf4+npmafzLcWYMWPw22+/Ye/evShfvnyeXuvg4ICGDRvi8uXLJqrOeEqUKIHq1atnW6u1fn8AcO3aNezevRvDhw/P0+us6fvTfw95+Y7y8+9Ybfpgc+3aNezatSvHVpusPO/n3NJUqVIF7u7u2dZrjd8hABw4cAARERF5/jcJWMZ3mN3vBU9PT6SmpiIuLi7T+c/73ag/J7evsSQ2FW4cHR3h5+eHkJAQwzGdToeQkJBM/+f7pKZNm2Y6HwB27dqV7flqUxQFY8aMwaZNm7Bnzx5Urlw5z9dIT0/H2bNn4eXlZYIKjSsxMRF///13trVa2/f3pBUrVqBs2bLo3Llznl5nTd9f5cqV4enpmek7SkhIwNGjR7P9jvLz71hN+mDz119/Yffu3ShdunSer/G8n3NLc+PGDdy9ezfbeq3tO9RbtmwZ/Pz84Ovrm+fXqvkdPu/3gp+fHxwcHDJ9HxEREYiKisr2+8jPv12LovKAZqNbs2aN4uTkpKxcuVK5cOGCMmLECKVEiRJKTEyMoiiKMnDgQGXSpEmG8w8ePKgUKVJE+eKLL5Tw8HAlODhYcXBwUM6ePavWR8jRqFGjFK1Wq+zbt0+Jjo423B4+fGg45+nPOHPmTGXHjh3K33//rZw4cULp06ePUrRoUeX8+fNqfIQcvffee8q+ffuUyMhI5eDBg0pAQIDi7u6u3Lp1S1EU6//+9NLT05UKFSooEydOfOY5a/v+Hjx4oJw8eVI5efKkAkCZN2+ecvLkScNsoTlz5iglSpRQfvnlF+XMmTNK165dlcqVKyuPHj0yXOPll19WFixYYHj8vH/HlvL5UlNTlVdffVUpX768curUqUz/JlNSUrL9fM/7OTe3nD7jgwcPlAkTJiiHDx9WIiMjld27dysvvviiUq1aNSU5OdlwDWv9DvXi4+MVFxcXZdGiRVlew5K/w9z8Xhg5cqRSoUIFZc+ePcrx48eVpk2bKk2bNs10nRo1aigbN240PM7Nv11LZXPhRlEUZcGCBUqFChUUR0dHpUmTJsqRI0cMz7Vu3VoZPHhwpvPXrVunVK9eXXF0dFTq1KmjbN261cwV5x6ALG8rVqwwnPP0Z3znnXcMfx8eHh5Kp06dlLCwMPMXnwu9e/dWvLy8FEdHR6VcuXJK7969lcuXLxuet/bvT2/Hjh0KACUiIuKZ56zt+9u7d2+WP5P6z6DT6ZRp06YpHh4eipOTk9KuXbtnPnfFihWV4ODgTMdy+ndsTjl9vsjIyGz/Te7du9dwjac/3/N+zs0tp8/48OFDpUOHDkqZMmUUBwcHpWLFisqbb775TEix1u9Qb8mSJYqzs7MSFxeX5TUs+TvMze+FR48eKW+99ZZSsmRJxcXFRenevbsSHR39zHWefE1u/u1aKo2iKIpp2oSIiIiIzM+mxtwQERERMdwQERGRTWG4ISIiIpvCcENEREQ2heGGiIiIbArDDREREdkUhhsiIiKyKQw3REREZFMYboio0NNoNNi8ebPaZRCRkTDcEJGqhgwZAo1G88wtKChI7dKIyEoVUbsAIqKgoCCsWLEi0zEnJyeVqiEia8eWGyJSnZOTEzw9PTPdSpYsCUC6jBYtWoSOHTvC2dkZVapUwYYNGzK9/uzZs3j55Zfh7OyM0qVLY8SIEUhMTMx0zvLly1GnTh04OTnBy8sLY8aMyfT8nTt30L17d7i4uKBatWrYsmWLaT80EZkMww0RWbxp06ahZ8+eOH36NPr3748+ffogPDwcAJCUlITAwECULFkSx44dw/r167F79+5M4WXRokUYPXo0RowYgbNnz2LLli144YUXMr3HzJkz0atXL5w5cwadOnVC//79ce/ePbN+TiIyErW3JSeiwm3w4MGKvb294urqmun2ySefKIqiKACUkSNHZnqNv7+/MmrUKEVRFOW7775TSpYsqSQmJhqe37p1q2JnZ6fExMQoiqIo3t7eypQpU7KtAYAydepUw+PExEQFgPL7778b7XMSkflwzA0Rqa5t27ZYtGhRpmOlSpUy3G/atGmm55o2bYpTp04BAMLDw+Hr6wtXV1fD882bN4dOp0NERAQ0Gg1u3ryJdu3a5VhD/fr1DfddXV3h5uaGW7du5fcjEZGKGG6ISHWurq7PdBMZi7Ozc67Oc3BwyPRYo9FAp9OZoiQiMjGOuSEii3fkyJFnHteqVQsAUKtWLZw+fRpJSUmG5w8ePAg7OzvUqFEDxYsXR6VKlRASEmLWmolIPWy5ISLVpaSkICYmJtOxIkWKwN3dHQCwfv16NGrUCC1atMDq1asRGhqKZcuWAQD69++P4OBgDB48GDNmzMDt27cxduxYDBw4EB4eHgCAGTNmYOTIkShbtiw6duyIBw8e4ODBgxg7dqx5PygRmQXDDRGpbvv27fDy8sp0rEaNGrh48SIAmcm0Zs0avPXWW/Dy8sLPP/+M2rVrAwBcXFywY8cOjBs3Do0bN4aLiwt69uyJefPmGa41ePBgJCcn48svv8SECRPg7u6O1157zXwfkIjMSqMoiqJ2EURE2dFoNNi0aRO6deumdilEZCU45oaIiIhsCsMNERER2RSOuSEii8aecyLKK7bcEBERkU1huCEiIiKbwnBDRERENoXhhoiIiGwKww0RERHZFIYbIiIisikMN0RERGRTGG6IiIjIpvwPtulKNATDSKEAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper Parameter Tuning - 1 or more chareter word Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Building Functio to be used under Keras TUuer.\n",
    "\n",
    "- Testing 1 Input CNN Layer. Neurous between 32 and 128 with a step of 32.\n",
    "- Testing between 2 and 4 CNN layers. Neurous between 32 and 128 with a step of 32.\n",
    "- Testing 1 DEnse layer. Neurous between 32 and 128 with a step of 32.\n",
    "- Testing different dropout rates betqeen 0 and 0,5 with a step of 0,1.\n",
    "- Testing 3 different learning rates [1e-1, 1e-2, 1e-3, 1e-4]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    seq_to_seq_model = Sequential()\n",
    "    \n",
    "    seq_to_seq_model.add(Conv2D(hp.Int('Input CNN units', min_value=32, max_value=128, step=32), kernel_size=(3, 3), input_shape=(32, 128, 1), activation=\"relu\"))\n",
    "    seq_to_seq_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    for i in range(hp.Int(\"layers\", 2 , 4)):\n",
    "        seq_to_seq_model.add(Conv2D(hp.Int('CNN units ' + str(i), min_value=32, max_value=128, step=32), kernel_size=(3, 3), activation=\"relu\"))\n",
    "        seq_to_seq_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    seq_to_seq_model.add(Flatten())\n",
    "    seq_to_seq_model.add(Dense(hp.Int('dense_units', min_value=64, max_value=256, step=64), activation='relu'))\n",
    "    seq_to_seq_model.add(Dropout(hp.Float('dropout', 0, 0.5, step=0.1, default=0.5)))\n",
    "    seq_to_seq_model.add(Dense((17 * (len(vocabulary)+1)), activation=\"softmax\"))\n",
    "    seq_to_seq_model.add(Reshape((17,len(vocabulary)+1)))\n",
    "\n",
    "    seq_to_seq_model.compile(optimizer=keras.optimizers.Adam(hp.Choice(\"learning rate\", values=[1e-1, 1e-2, 1e-3, 1e-4])), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return seq_to_seq_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuner using a max of 20 trials (combinations). Using Val accuracy as objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 Complete [00h 12m 41s]\n",
      "val_accuracy: 0.8344508409500122\n",
      "\n",
      "Best val_accuracy So Far: 0.8344508409500122\n",
      "Total elapsed time: 00h 12m 41s\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.RandomSearch(\n",
    "    model_builder,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=20,  #Number of experiments\n",
    "    directory='my_dir',\n",
    "    project_name='seq_to_seq_model',\n",
    "    seed=24\n",
    ")\n",
    "\n",
    "tuner.search(X_train, y_train, epochs=50, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trials Summary Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New Model with the best Hyper-Parametera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 30, 126, 32)       320       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPoolin  (None, 15, 63, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 13, 61, 96)        27744     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPoolin  (None, 6, 30, 96)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 4, 28, 96)         83040     \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPoolin  (None, 2, 14, 96)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 2688)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 192)               516288    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 192)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1071)              206703    \n",
      "                                                                 \n",
      " reshape_2 (Reshape)         (None, 17, 63)            0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 834095 (3.18 MB)\n",
      "Trainable params: 834095 (3.18 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(num_trials=2)[0]\n",
    "seq_to_seq_model2 = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "seq_to_seq_model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'Input CNN units': 32, 'layers': 2, 'CNN units 0': 96, 'CNN units 1': 96, 'dense_units': 192, 'dropout': 0.1, 'learning rate': 0.001, 'CNN units 2': 96}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best hyperparameters:\", best_hps.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Save the best model during the training\n",
    "best_hyper_model_path = 'best_hyper_model.h5'  # Specify the path where you want to save the best model\n",
    "model_checkpoint = ModelCheckpoint(best_hyper_model_path, \n",
    "                                   monitor='val_loss', \n",
    "                                   save_best_only=True, \n",
    "                                   verbose=1)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "2435/2435 [==============================] - ETA: 0s - loss: 0.8067 - accuracy: 0.7777\n",
      "Epoch 1: val_loss improved from inf to 0.67339, saving model to best_hyper_model.h5\n",
      "2435/2435 [==============================] - 370s 152ms/step - loss: 0.8067 - accuracy: 0.7777 - val_loss: 0.6734 - val_accuracy: 0.8046\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\t.ferreira\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2435/2435 [==============================] - ETA: 0s - loss: 0.6367 - accuracy: 0.8146\n",
      "Epoch 2: val_loss improved from 0.67339 to 0.57208, saving model to best_hyper_model.h5\n",
      "2435/2435 [==============================] - 403s 165ms/step - loss: 0.6367 - accuracy: 0.8146 - val_loss: 0.5721 - val_accuracy: 0.8319\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "history_2 = seq_to_seq_model2.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),  # replace with your validation data\n",
    "    epochs=2,  # Set a high number because early stopping will halt the training\n",
    "    batch_size=32,  # Adjust based on your data and computing resources\n",
    "    callbacks=[early_stopping, model_checkpoint]  # Add the model checkpoint callback here\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_32 (Conv2D)          (None, 30, 126, 96)       960       \n",
      "                                                                 \n",
      " max_pooling2d_32 (MaxPooli  (None, 15, 63, 96)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_33 (Conv2D)          (None, 13, 61, 96)        83040     \n",
      "                                                                 \n",
      " max_pooling2d_33 (MaxPooli  (None, 6, 30, 96)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_34 (Conv2D)          (None, 4, 28, 96)         83040     \n",
      "                                                                 \n",
      " max_pooling2d_34 (MaxPooli  (None, 2, 14, 96)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_12 (Flatten)        (None, 2688)              0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 192)               516288    \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 192)               0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 1344)              259392    \n",
      "                                                                 \n",
      " reshape_8 (Reshape)         (None, 21, 64)            0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 942720 (3.60 MB)\n",
      "Trainable params: 942720 (3.60 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.7714 - accuracy: 0.7984\n",
      "Epoch 1: val_loss improved from inf to 0.66902, saving model to best_model_word_hyper.h5\n",
      "524/524 [==============================] - 143s 273ms/step - loss: 0.7714 - accuracy: 0.7984 - val_loss: 0.6690 - val_accuracy: 0.8123\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - ETA: 0s - loss: 0.6328 - accuracy: 0.8212\n",
      "Epoch 2: val_loss improved from 0.66902 to 0.60074, saving model to best_model_word_hyper.h5\n",
      "524/524 [==============================] - 148s 283ms/step - loss: 0.6328 - accuracy: 0.8212 - val_loss: 0.6007 - val_accuracy: 0.8268\n",
      "Epoch 3/50\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.5722 - accuracy: 0.8342\n",
      "Epoch 3: val_loss improved from 0.60074 to 0.54641, saving model to best_model_word_hyper.h5\n",
      "524/524 [==============================] - 148s 282ms/step - loss: 0.5722 - accuracy: 0.8342 - val_loss: 0.5464 - val_accuracy: 0.8388\n",
      "Epoch 4/50\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.5243 - accuracy: 0.8451\n",
      "Epoch 4: val_loss improved from 0.54641 to 0.50884, saving model to best_model_word_hyper.h5\n",
      "524/524 [==============================] - 141s 269ms/step - loss: 0.5243 - accuracy: 0.8451 - val_loss: 0.5088 - val_accuracy: 0.8486\n",
      "Epoch 5/50\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.4897 - accuracy: 0.8535\n",
      "Epoch 5: val_loss improved from 0.50884 to 0.48811, saving model to best_model_word_hyper.h5\n",
      "524/524 [==============================] - 143s 273ms/step - loss: 0.4897 - accuracy: 0.8535 - val_loss: 0.4881 - val_accuracy: 0.8538\n",
      "Epoch 6/50\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.4593 - accuracy: 0.8615\n",
      "Epoch 6: val_loss improved from 0.48811 to 0.46340, saving model to best_model_word_hyper.h5\n",
      "524/524 [==============================] - 139s 265ms/step - loss: 0.4593 - accuracy: 0.8615 - val_loss: 0.4634 - val_accuracy: 0.8608\n",
      "Epoch 7/50\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.4347 - accuracy: 0.8678\n",
      "Epoch 7: val_loss improved from 0.46340 to 0.43760, saving model to best_model_word_hyper.h5\n",
      "524/524 [==============================] - 125s 239ms/step - loss: 0.4347 - accuracy: 0.8678 - val_loss: 0.4376 - val_accuracy: 0.8682\n",
      "Epoch 8/50\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.4133 - accuracy: 0.8738\n",
      "Epoch 8: val_loss improved from 0.43760 to 0.42391, saving model to best_model_word_hyper.h5\n",
      "524/524 [==============================] - 141s 269ms/step - loss: 0.4133 - accuracy: 0.8738 - val_loss: 0.4239 - val_accuracy: 0.8727\n",
      "Epoch 9/50\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.3954 - accuracy: 0.8785\n",
      "Epoch 9: val_loss improved from 0.42391 to 0.41238, saving model to best_model_word_hyper.h5\n",
      "524/524 [==============================] - 148s 283ms/step - loss: 0.3954 - accuracy: 0.8785 - val_loss: 0.4124 - val_accuracy: 0.8760\n",
      "Epoch 10/50\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.3793 - accuracy: 0.8831\n",
      "Epoch 10: val_loss improved from 0.41238 to 0.40820, saving model to best_model_word_hyper.h5\n",
      "524/524 [==============================] - 142s 270ms/step - loss: 0.3793 - accuracy: 0.8831 - val_loss: 0.4082 - val_accuracy: 0.8772\n",
      "Epoch 11/50\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.3654 - accuracy: 0.8868\n",
      "Epoch 11: val_loss improved from 0.40820 to 0.40090, saving model to best_model_word_hyper.h5\n",
      "524/524 [==============================] - 140s 266ms/step - loss: 0.3654 - accuracy: 0.8868 - val_loss: 0.4009 - val_accuracy: 0.8799\n",
      "Epoch 12/50\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.3526 - accuracy: 0.8903\n",
      "Epoch 12: val_loss improved from 0.40090 to 0.39425, saving model to best_model_word_hyper.h5\n",
      "524/524 [==============================] - 130s 249ms/step - loss: 0.3526 - accuracy: 0.8903 - val_loss: 0.3943 - val_accuracy: 0.8818\n",
      "Epoch 13/50\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.3413 - accuracy: 0.8932\n",
      "Epoch 13: val_loss improved from 0.39425 to 0.39106, saving model to best_model_word_hyper.h5\n",
      "524/524 [==============================] - 129s 246ms/step - loss: 0.3413 - accuracy: 0.8932 - val_loss: 0.3911 - val_accuracy: 0.8833\n",
      "Epoch 14/50\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.3313 - accuracy: 0.8960\n",
      "Epoch 14: val_loss improved from 0.39106 to 0.38733, saving model to best_model_word_hyper.h5\n",
      "524/524 [==============================] - 138s 263ms/step - loss: 0.3313 - accuracy: 0.8960 - val_loss: 0.3873 - val_accuracy: 0.8839\n",
      "Epoch 15/50\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.3213 - accuracy: 0.8990\n",
      "Epoch 15: val_loss improved from 0.38733 to 0.38388, saving model to best_model_word_hyper.h5\n",
      "524/524 [==============================] - 137s 261ms/step - loss: 0.3213 - accuracy: 0.8990 - val_loss: 0.3839 - val_accuracy: 0.8855\n",
      "Epoch 16/50\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.3137 - accuracy: 0.9014\n",
      "Epoch 16: val_loss did not improve from 0.38388\n",
      "524/524 [==============================] - 132s 252ms/step - loss: 0.3137 - accuracy: 0.9014 - val_loss: 0.3858 - val_accuracy: 0.8860\n",
      "Epoch 17/50\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.3060 - accuracy: 0.9032\n",
      "Epoch 17: val_loss did not improve from 0.38388\n",
      "524/524 [==============================] - 131s 250ms/step - loss: 0.3060 - accuracy: 0.9032 - val_loss: 0.3849 - val_accuracy: 0.8867\n",
      "Epoch 18/50\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.2988 - accuracy: 0.9056\n",
      "Epoch 18: val_loss improved from 0.38388 to 0.38252, saving model to best_model_word_hyper.h5\n",
      "524/524 [==============================] - 134s 255ms/step - loss: 0.2988 - accuracy: 0.9056 - val_loss: 0.3825 - val_accuracy: 0.8872\n",
      "Epoch 19/50\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.2920 - accuracy: 0.9073\n",
      "Epoch 19: val_loss improved from 0.38252 to 0.38238, saving model to best_model_word_hyper.h5\n",
      "524/524 [==============================] - 132s 252ms/step - loss: 0.2920 - accuracy: 0.9073 - val_loss: 0.3824 - val_accuracy: 0.8869\n",
      "Epoch 20/50\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.2864 - accuracy: 0.9088\n",
      "Epoch 20: val_loss did not improve from 0.38238\n",
      "524/524 [==============================] - 134s 257ms/step - loss: 0.2864 - accuracy: 0.9088 - val_loss: 0.3912 - val_accuracy: 0.8872\n",
      "Epoch 21/50\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.2805 - accuracy: 0.9103\n",
      "Epoch 21: val_loss did not improve from 0.38238\n",
      "524/524 [==============================] - 125s 238ms/step - loss: 0.2805 - accuracy: 0.9103 - val_loss: 0.3885 - val_accuracy: 0.8872\n",
      "Epoch 22/50\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.2751 - accuracy: 0.9121\n",
      "Epoch 22: val_loss did not improve from 0.38238\n",
      "524/524 [==============================] - 125s 239ms/step - loss: 0.2751 - accuracy: 0.9121 - val_loss: 0.3919 - val_accuracy: 0.8884\n"
     ]
    }
   ],
   "source": [
    "# ---- DESCRIPTION OF THE INPUT DATA ----\n",
    "# X_train shape: (num_samples, 32, 128, 1)\n",
    "# y_train shape: (num_samples, max(len(words)),len(vocabulary))\n",
    "# example of a X_train value: matrix of 32x128 with values between 0 and 1\n",
    "# example of a y_train value: matrix of 17x63 with values between 0 and 1. first column is the padding, the rest are the one-hot encoded values of the transcription\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.layers import Reshape\n",
    "\n",
    "def create_cnn_model(input_shape, num_classes, sequence_length):\n",
    "    model_hyper = Sequential([\n",
    "        # Input CNN layer with 32 units\n",
    "        Conv2D(96, (3, 3), activation='relu', input_shape=input_shape),  # Updated the number of filters to 96\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "        # Second CNN layer with 96 units\n",
    "        Conv2D(96, (3, 3), activation='relu'),  # Updated the number of filters to 96\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        # Third CNN layer with 96 units (as per 'CNN units 2')\n",
    "        Conv2D(96, (3, 3), activation='relu'),  # Updated the number of filters to 96\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        # Flattening the 2D arrays for fully connected layers\n",
    "        Flatten(),\n",
    "\n",
    "        # First Dense layer with 192 units\n",
    "        Dense(192, activation='relu'),  # Updated number of units to 192\n",
    "        Dropout(0.1),  # Dropout with 0.1 rate\n",
    "        \n",
    "        # Output layer with sequence_length * num_classes units and softmax activation\n",
    "        Dense(sequence_length * num_classes, activation='softmax'),\n",
    "        Reshape((sequence_length, num_classes))\n",
    "\n",
    "    ])\n",
    "    \n",
    "    # Compiling the model with Adam optimizer and a learning rate of 0.001\n",
    "    model_hyper.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model_hyper\n",
    "\n",
    "create_cnn_model(input_shape=(32, 128, 1), num_classes=len(vocabulary)+1, sequence_length=y_train.shape[1]).summary()\n",
    "\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Stop training when there is no improvement in the validation loss for 3 consecutive epochs\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "# Save the best model during the training\n",
    "best_model_path = 'best_model_word_hyper.h5'  \n",
    "model_checkpoint = ModelCheckpoint(best_model_path, \n",
    "                                   monitor='val_loss', \n",
    "                                   save_best_only=True, \n",
    "                                   verbose=1)\n",
    "\n",
    "# Assume create_cnn_model is a function you've defined to create your model\n",
    "model_hyper_word = create_cnn_model(input_shape=(32, 128, 1), num_classes=len(vocabulary)+1, sequence_length=y_train.shape[1])\n",
    "\n",
    "history = model_hyper_word.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=50,  # Set a high number because early stopping will halt the training\n",
    "    batch_size=128,\n",
    "    callbacks=[early_stopping, model_checkpoint]  # Add the model checkpoint callback here\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CRNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67064, 32, 128, 1)\n",
      "(67064, 21, 64)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from tensorflow.keras.models import Model, \n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dense, Dropout, Reshape, LSTM, Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"class CTCLayer(Layer):\n",
    "    def __init__(self, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.loss_fn = tf.keras.backend.ctc_batch_cost\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
    "        input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
    "        label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
    "\n",
    "        input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "        label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "\n",
    "        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n",
    "        self.add_loss(loss)\n",
    "\n",
    "        return y_pred\"\"\"\n",
    "\n",
    "def ctc_batch_cost(y_true, y_pred, input_length, label_length):\n",
    "    label_length = tf.cast(tf.squeeze(label_length, axis=-1), tf.int32)\n",
    "    input_length = tf.cast(tf.squeeze(input_length, axis=-1), tf.int32)\n",
    "    sparse_labels = tf.cast(ctc_label_dense_to_sparse(y_true, label_length), tf.int32)\n",
    "\n",
    "    y_pred = tf.math.log(tf.transpose(y_pred, perm=[1, 0, 2]) + keras.backend.epsilon())\n",
    "\n",
    "    return tf.expand_dims(\n",
    "        tf.compat.v1.nn.ctc_loss(\n",
    "            inputs=y_pred, labels=sparse_labels, sequence_length=input_length\n",
    "        ),\n",
    "        1,\n",
    "    )\n",
    "\n",
    "\n",
    "def ctc_label_dense_to_sparse(labels, label_lengths):\n",
    "    label_shape = tf.shape(labels)\n",
    "    num_batches_tns = tf.stack([label_shape[0]])\n",
    "    max_num_labels_tns = tf.stack([label_shape[1]])\n",
    "\n",
    "    def range_less_than(old_input, current_input):\n",
    "        return tf.expand_dims(tf.range(tf.shape(old_input)[1]), 0) < tf.fill(\n",
    "            max_num_labels_tns, current_input\n",
    "        )\n",
    "\n",
    "    init = tf.cast(tf.fill([1, label_shape[1]], 0), tf.bool)\n",
    "    dense_mask = tf.compat.v1.scan(\n",
    "        range_less_than, label_lengths, initializer=init, parallel_iterations=1\n",
    "    )\n",
    "    dense_mask = dense_mask[:, 0, :]\n",
    "\n",
    "    label_array = tf.reshape(\n",
    "        tf.tile(tf.range(0, label_shape[1]), num_batches_tns), label_shape\n",
    "    )\n",
    "    label_ind = tf.compat.v1.boolean_mask(label_array, dense_mask)\n",
    "\n",
    "    batch_array = tf.transpose(\n",
    "        tf.reshape(\n",
    "            tf.tile(tf.range(0, label_shape[0]), max_num_labels_tns),\n",
    "            tf.reverse(label_shape, [0]),\n",
    "        )\n",
    "    )\n",
    "    batch_ind = tf.compat.v1.boolean_mask(batch_array, dense_mask)\n",
    "    indices = tf.transpose(\n",
    "        tf.reshape(tf.concat([batch_ind, label_ind], axis=0), [2, -1])\n",
    "    )\n",
    "\n",
    "    vals_sparse = tf.compat.v1.gather_nd(labels, indices)\n",
    "\n",
    "    return tf.SparseTensor(\n",
    "        tf.cast(indices, tf.int64), vals_sparse, tf.cast(label_shape, tf.int64)\n",
    "    )\n",
    "\n",
    "\n",
    "## Ref: https://keras.io/examples/vision/captcha_ocr/\n",
    "class CTCLayer(layers.Layer):\n",
    "    def __init__(self, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.loss_fn = ctc_batch_cost\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        # Compute the training-time loss value and add it\n",
    "        # to the layer using `self.add_loss()`.\n",
    "        batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
    "        input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
    "        label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
    "\n",
    "        input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "        label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "\n",
    "        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n",
    "        self.add_loss(loss)\n",
    "\n",
    "        # At test time, just return the computed predictions\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_img (InputLayer)      [(None, 32, 128, 1)]         0         []                            \n",
      "                                                                                                  \n",
      " conv2d_72 (Conv2D)          (None, 30, 126, 96)          960       ['input_img[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling2d_71 (MaxPooli  (None, 15, 63, 96)           0         ['conv2d_72[0][0]']           \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv2d_73 (Conv2D)          (None, 13, 61, 96)           83040     ['max_pooling2d_71[0][0]']    \n",
      "                                                                                                  \n",
      " max_pooling2d_72 (MaxPooli  (None, 6, 30, 96)            0         ['conv2d_73[0][0]']           \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv2d_74 (Conv2D)          (None, 4, 28, 96)            83040     ['max_pooling2d_72[0][0]']    \n",
      "                                                                                                  \n",
      " max_pooling2d_73 (MaxPooli  (None, 4, 14, 96)            0         ['conv2d_74[0][0]']           \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " flatten_25 (Flatten)        (None, 5376)                 0         ['max_pooling2d_73[0][0]']    \n",
      "                                                                                                  \n",
      " dense_48 (Dense)            (None, 1344)                 7226688   ['flatten_25[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_25 (Dropout)        (None, 1344)                 0         ['dense_48[0][0]']            \n",
      "                                                                                                  \n",
      " reshape_30 (Reshape)        (None, 1344, 1)              0         ['dropout_25[0][0]']          \n",
      "                                                                                                  \n",
      " lstm_22 (LSTM)              (None, 1344, 128)            66560     ['reshape_30[0][0]']          \n",
      "                                                                                                  \n",
      " lstm_23 (LSTM)              (None, 128)                  131584    ['lstm_22[0][0]']             \n",
      "                                                                                                  \n",
      " dense_49 (Dense)            (None, 1344)                 173376    ['lstm_23[0][0]']             \n",
      "                                                                                                  \n",
      " labels (InputLayer)         [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " reshape_31 (Reshape)        (None, 21, 64)               0         ['dense_49[0][0]']            \n",
      "                                                                                                  \n",
      " ctc_loss (CTCLayer)         (None, 21, 64)               0         ['labels[0][0]',              \n",
      "                                                                     'reshape_31[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 7765248 (29.62 MB)\n",
      "Trainable params: 7765248 (29.62 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_cnn_rnn_model(input_shape, num_classes, sequence_length):\n",
    "    # Define the input layers\n",
    "    inputs = Input(shape=input_shape, name=\"input_img\")\n",
    "    labels = Input(name=\"labels\", shape=(None,))  # input for CTC\n",
    "\n",
    "    # First CNN layer with 96 units\n",
    "    x = Conv2D(96, (3, 3), activation='relu')(inputs)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    # Second CNN layer with 96 units\n",
    "    x = Conv2D(96, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    # Third CNN layer with 96 units\n",
    "    x = Conv2D(96, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(1, 2))(x)\n",
    "\n",
    "    # Flatten the output of the CNN layers\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "\n",
    "    # Dense layer with sequence_length * num_classes units\n",
    "    x = Dense(sequence_length * num_classes, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "\n",
    "    # Reshape the output for the RNN layers\n",
    "    # (batch_size, time_steps, units)\n",
    "    x = Reshape((sequence_length*num_classes,1))(x)\n",
    "\n",
    "    # First RNN (LSTM) layer, 128 units, returns sequences for the next LSTM layer\n",
    "    x = LSTM(128, return_sequences=True)(x)\n",
    "\n",
    "    # Second RNN (LSTM) layer, 128 units, this time we do not return sequences\n",
    "    x = LSTM(128)(x)\n",
    "\n",
    "    \"\"\"# Final Dense layer\n",
    "    x = Dense(sequence_length * num_classes, activation='softmax')(x)\n",
    "\n",
    "    # Reshape the output to match the target shape\n",
    "    outputs = Reshape((sequence_length, num_classes))(x)\n",
    "\n",
    "    # Create the model\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))\"\"\"\n",
    "\n",
    "    # Compile the model with Adam optimizer and a learning rate of 0.001\n",
    "    # model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    #               loss='categorical_crossentropy',\n",
    "    #               metrics=['accuracy'])\n",
    "\n",
    "    # Final Dense layer, note that we're not applying softmax here\n",
    "    x = Dense(num_classes*sequence_length, activation=None)(x)  # logits for CTC\n",
    "    x = Reshape((sequence_length, num_classes))(x)\n",
    "\n",
    "    # Define the CTC layer and get the loss\n",
    "    ctc_output = CTCLayer(name='ctc_loss')(labels, x)\n",
    "\n",
    "    # Create the model\n",
    "    model = Model(inputs=[inputs, labels], outputs=ctc_output)\n",
    "\n",
    "    # Compile the model with a dummy optimizer and loss since CTC loss is computed in the CTC layer\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))\n",
    "  \n",
    "    return model\n",
    "\n",
    "create_cnn_rnn_model(input_shape=(32, 128, 1), num_classes=len(vocabulary)+1, sequence_length=y_train.shape[1]).summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/opt/homebrew/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/homebrew/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/homebrew/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/homebrew/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"/opt/homebrew/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/var/folders/6q/0yfg3pwd67d3xrqsp_16lm680000gn/T/__autograph_generated_file637bgqsg.py\", line 15, in tf__call\n        loss = ag__.converted_call(ag__.ld(self).loss_fn, (ag__.ld(y_true), ag__.ld(y_pred), ag__.ld(input_length), ag__.ld(label_length)), None, fscope)\n    File \"/var/folders/6q/0yfg3pwd67d3xrqsp_16lm680000gn/T/__autograph_generated_filenublfcqr.py\", line 12, in tf__ctc_batch_cost\n        sparse_labels = ag__.converted_call(ag__.ld(tf).cast, (ag__.converted_call(ag__.ld(ctc_label_dense_to_sparse), (ag__.ld(y_true), ag__.ld(label_length)), None, fscope), ag__.ld(tf).int32), None, fscope)\n    File \"/var/folders/6q/0yfg3pwd67d3xrqsp_16lm680000gn/T/__autograph_generated_filegz1e8zob.py\", line 40, in tf__ctc_label_dense_to_sparse\n        raise\n\n    ValueError: Exception encountered when calling layer 'ctc_loss' (type CTCLayer).\n    \n    in user code:\n    \n        File \"/var/folders/6q/0yfg3pwd67d3xrqsp_16lm680000gn/T/ipykernel_4481/3426663172.py\", line 89, in call  *\n            loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n        File \"/var/folders/6q/0yfg3pwd67d3xrqsp_16lm680000gn/T/ipykernel_4481/3426663172.py\", line 22, in ctc_batch_cost  *\n            sparse_labels = tf.cast(ctc_label_dense_to_sparse(y_true, label_length), tf.int32)\n        File \"/var/folders/6q/0yfg3pwd67d3xrqsp_16lm680000gn/T/ipykernel_4481/3426663172.py\", line 69, in ctc_label_dense_to_sparse  *\n            tf.cast(indices, tf.int64), vals_sparse, tf.cast(label_shape, tf.int64)\n    \n        ValueError: Shape (None, 64) must have rank 1\n    \n    \n    Call arguments received by layer 'ctc_loss' (type CTCLayer):\n       y_true=tf.Tensor(shape=(None, 21, 64), dtype=float32)\n       y_pred=tf.Tensor(shape=(None, 21, 64), dtype=float32)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[230], line 22\u001b[0m\n\u001b[1;32m     12\u001b[0m model_test \u001b[38;5;241m=\u001b[39m create_cnn_rnn_model(input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m1\u001b[39m), num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(vocabulary)\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, sequence_length\u001b[38;5;241m=\u001b[39my_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03m\"\"\"history = model_test.fit(\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m    X_train, y_train,\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m    validation_data=(X_val, y_val),\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m    callbacks=[early_stopping, model_checkpoint]  # Add the model checkpoint callback here\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03m)\"\"\"\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Provide both inputs and labels\u001b[39;49;00m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#y_train,  # The true labels for CTC loss\u001b[39;49;00m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Provide inputs & labels for validation\u001b[39;49;00m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_checkpoint\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/6q/0yfg3pwd67d3xrqsp_16lm680000gn/T/__autograph_generated_fileki9cy3o4.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/var/folders/6q/0yfg3pwd67d3xrqsp_16lm680000gn/T/__autograph_generated_file637bgqsg.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, y_true, y_pred)\u001b[0m\n\u001b[1;32m     13\u001b[0m input_length \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(input_length) \u001b[38;5;241m*\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mones, (), \u001b[38;5;28mdict\u001b[39m(shape\u001b[38;5;241m=\u001b[39m(ag__\u001b[38;5;241m.\u001b[39mld(batch_len), \u001b[38;5;241m1\u001b[39m), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint64\u001b[39m\u001b[38;5;124m'\u001b[39m), fscope)\n\u001b[1;32m     14\u001b[0m label_length \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(label_length) \u001b[38;5;241m*\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mones, (), \u001b[38;5;28mdict\u001b[39m(shape\u001b[38;5;241m=\u001b[39m(ag__\u001b[38;5;241m.\u001b[39mld(batch_len), \u001b[38;5;241m1\u001b[39m), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint64\u001b[39m\u001b[38;5;124m'\u001b[39m), fscope)\n\u001b[0;32m---> 15\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_length\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel_length\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39madd_loss, (ag__\u001b[38;5;241m.\u001b[39mld(loss),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/var/folders/6q/0yfg3pwd67d3xrqsp_16lm680000gn/T/__autograph_generated_filenublfcqr.py:12\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__ctc_batch_cost\u001b[0;34m(y_true, y_pred, input_length, label_length)\u001b[0m\n\u001b[1;32m     10\u001b[0m label_length \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mcast, (ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39msqueeze, (ag__\u001b[38;5;241m.\u001b[39mld(label_length),), \u001b[38;5;28mdict\u001b[39m(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), fscope), ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mint32), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     11\u001b[0m input_length \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mcast, (ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39msqueeze, (ag__\u001b[38;5;241m.\u001b[39mld(input_length),), \u001b[38;5;28mdict\u001b[39m(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), fscope), ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mint32), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m---> 12\u001b[0m sparse_labels \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mcast, (\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctc_label_dense_to_sparse\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel_length\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m, ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mint32), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     13\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mlog, (ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mtranspose, (ag__\u001b[38;5;241m.\u001b[39mld(y_pred),), \u001b[38;5;28mdict\u001b[39m(perm\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m]), fscope) \u001b[38;5;241m+\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(keras)\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39mepsilon, (), \u001b[38;5;28;01mNone\u001b[39;00m, fscope),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/var/folders/6q/0yfg3pwd67d3xrqsp_16lm680000gn/T/__autograph_generated_filegz1e8zob.py:37\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__ctc_label_dense_to_sparse\u001b[0;34m(labels, label_lengths)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     36\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mSparseTensor, (ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mcast, (ag__\u001b[38;5;241m.\u001b[39mld(indices), ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mint64), \u001b[38;5;28;01mNone\u001b[39;00m, fscope), ag__\u001b[38;5;241m.\u001b[39mld(vals_sparse), ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mcast, (ag__\u001b[38;5;241m.\u001b[39mld(label_shape), ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mint64), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/opt/homebrew/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/homebrew/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/homebrew/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/homebrew/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"/opt/homebrew/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/var/folders/6q/0yfg3pwd67d3xrqsp_16lm680000gn/T/__autograph_generated_file637bgqsg.py\", line 15, in tf__call\n        loss = ag__.converted_call(ag__.ld(self).loss_fn, (ag__.ld(y_true), ag__.ld(y_pred), ag__.ld(input_length), ag__.ld(label_length)), None, fscope)\n    File \"/var/folders/6q/0yfg3pwd67d3xrqsp_16lm680000gn/T/__autograph_generated_filenublfcqr.py\", line 12, in tf__ctc_batch_cost\n        sparse_labels = ag__.converted_call(ag__.ld(tf).cast, (ag__.converted_call(ag__.ld(ctc_label_dense_to_sparse), (ag__.ld(y_true), ag__.ld(label_length)), None, fscope), ag__.ld(tf).int32), None, fscope)\n    File \"/var/folders/6q/0yfg3pwd67d3xrqsp_16lm680000gn/T/__autograph_generated_filegz1e8zob.py\", line 40, in tf__ctc_label_dense_to_sparse\n        raise\n\n    ValueError: Exception encountered when calling layer 'ctc_loss' (type CTCLayer).\n    \n    in user code:\n    \n        File \"/var/folders/6q/0yfg3pwd67d3xrqsp_16lm680000gn/T/ipykernel_4481/3426663172.py\", line 89, in call  *\n            loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n        File \"/var/folders/6q/0yfg3pwd67d3xrqsp_16lm680000gn/T/ipykernel_4481/3426663172.py\", line 22, in ctc_batch_cost  *\n            sparse_labels = tf.cast(ctc_label_dense_to_sparse(y_true, label_length), tf.int32)\n        File \"/var/folders/6q/0yfg3pwd67d3xrqsp_16lm680000gn/T/ipykernel_4481/3426663172.py\", line 69, in ctc_label_dense_to_sparse  *\n            tf.cast(indices, tf.int64), vals_sparse, tf.cast(label_shape, tf.int64)\n    \n        ValueError: Shape (None, 64) must have rank 1\n    \n    \n    Call arguments received by layer 'ctc_loss' (type CTCLayer):\n       y_true=tf.Tensor(shape=(None, 21, 64), dtype=float32)\n       y_pred=tf.Tensor(shape=(None, 21, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Stop training when there is no improvement in the validation loss for 3 consecutive epochs\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "# Save the best model during the training\n",
    "best_model_path = 'test2.h5'\n",
    "model_checkpoint = ModelCheckpoint(best_model_path,\n",
    "                                   monitor='val_loss',\n",
    "                                   save_best_only=True,\n",
    "                                   verbose=1)\n",
    "\n",
    "# Assume create_cnn_model is a function you've defined to create your model\n",
    "model_test = create_cnn_rnn_model(input_shape=(32, 128, 1), num_classes=len(vocabulary)+1, sequence_length=y_train.shape[1])\n",
    "\n",
    "\"\"\"history = model_test.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=50,  # Set a high number because early stopping will halt the training\n",
    "    batch_size=128,\n",
    "    callbacks=[early_stopping, model_checkpoint]  # Add the model checkpoint callback here\n",
    ")\"\"\"\n",
    "\n",
    "history = model_test.fit(\n",
    "    [X_train, y_train],  # Provide both inputs and labels\n",
    "    #y_train,  # The true labels for CTC loss\n",
    "    validation_data=([X_val, y_val], y_val),  # Provide inputs & labels for validation\n",
    "    epochs=50,\n",
    "    batch_size=128,\n",
    "    callbacks=[early_stopping, model_checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262/262 [==============================] - 5s 18ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# now that the model is trained, let's make predictions on the test set\n",
    "# first, load the model best_model.h5\n",
    "from keras.models import load_model\n",
    "model = load_model('best_model_word_hyper.h5')\n",
    "\n",
    "# make predictions on the test set\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "def decode_predictions(predictions, num_to_char):\n",
    "    predicted_words = []\n",
    "    \n",
    "    for prediction in predictions:\n",
    "        # Convert prediction probabilities to character indices\n",
    "        char_indices = np.argmax(prediction, axis=-1)\n",
    "        \n",
    "        # Decode indices to characters\n",
    "        decoded_chars = [num_to_char.get(idx, '') for idx in char_indices]\n",
    "        \n",
    "        # Convert sequence of characters to a single word\n",
    "        decoded_word = ''.join(decoded_chars).rstrip(num_to_char.get(0, ''))\n",
    "        \n",
    "        # Append the decoded word to the list\n",
    "        predicted_words.append(decoded_word)\n",
    "    \n",
    "    return predicted_words\n",
    "\n",
    "num_to_char = {idx: char for char, idx in char_to_num.items()}\n",
    "\n",
    "predicted_words = decode_predictions(predictions, num_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8384, 21, 64)\n"
     ]
    }
   ],
   "source": [
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8384, 21, 64)\n"
     ]
    }
   ],
   "source": [
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def decode_y(y, num_to_char):\n",
    "    # Decoding the one-hot encoded y_test to characters\n",
    "    decoded_words = []\n",
    "    for sample in y:\n",
    "        char_indices = np.argmax(sample, axis=-1)\n",
    "        decoded_chars = [num_to_char.get(idx, '') for idx in char_indices]\n",
    "        decoded_word = ''.join(decoded_chars).rstrip(num_to_char.get(0, ''))\n",
    "        decoded_words.append(decoded_word)\n",
    "    return decoded_words\n",
    "\n",
    "# Get the indices for the test set\n",
    "test_indices = range(int(len(df) * (TRAIN_SPLIT + VAL_SPLIT)), len(df))\n",
    "\n",
    "# Ensure that the lengths of your test labels and indices match\n",
    "assert len(test_indices) == len(y_test), \"Mismatch in test set size and actual labels\"\n",
    "\n",
    "# Extract WordIDs and ImgageData for the test set using the correct indices\n",
    "test_word_ids = df.iloc[test_indices]['WordID'].values\n",
    "test_img_data = df.iloc[test_indices]['ImageData'].values\n",
    "\n",
    "\n",
    "# Assuming y_test is already one-hot encoded and you have a num_to_char dictionary\n",
    "real_words = decode_y(y_test, num_to_char)\n",
    "\n",
    "# Assuming you have a 'WordID' column in your initial dataframe (df)\n",
    "results = pd.DataFrame({\n",
    "    'WordID': test_word_ids,\n",
    "    'real': real_words,\n",
    "    'predicted': predicted_words,\n",
    "    'ImageData': test_img_data \n",
    "})\n",
    "\n",
    "# Calculate the 'correct' column (1 if the predicted word matches the real word, 0 otherwise)\n",
    "results['correct'] = (results['predicted'] == results['real']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WordID</th>\n",
       "      <th>real</th>\n",
       "      <th>predicted</th>\n",
       "      <th>ImageData</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a04-054-02-00</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a06-114-00-00</td>\n",
       "      <td>If</td>\n",
       "      <td>It</td>\n",
       "      <td>[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f04-096-05-02</td>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "      <td>[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>k02-093-04-01</td>\n",
       "      <td>quick</td>\n",
       "      <td>griic</td>\n",
       "      <td>[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d06-008-04-05</td>\n",
       "      <td>still</td>\n",
       "      <td>wooll</td>\n",
       "      <td>[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>e04-030-01-00</td>\n",
       "      <td>inside</td>\n",
       "      <td>winde</td>\n",
       "      <td>[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>g04-077-03-08</td>\n",
       "      <td>fortunate</td>\n",
       "      <td>fommnnee</td>\n",
       "      <td>[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>f07-000b-01-04</td>\n",
       "      <td>was</td>\n",
       "      <td>was</td>\n",
       "      <td>[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>d01-056-06-02</td>\n",
       "      <td>There</td>\n",
       "      <td>Thrr</td>\n",
       "      <td>[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>n04-068-04-00</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>d04-037-02-02</td>\n",
       "      <td>my</td>\n",
       "      <td>voy</td>\n",
       "      <td>[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>k02-117-06-03</td>\n",
       "      <td>as</td>\n",
       "      <td>as</td>\n",
       "      <td>[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>g05-094-07-01</td>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "      <td>[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>h04-055-01-01</td>\n",
       "      <td>per</td>\n",
       "      <td>por</td>\n",
       "      <td>[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>e07-101-07-07</td>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "      <td>[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>h06-082-01-06</td>\n",
       "      <td>devices</td>\n",
       "      <td>Sovve</td>\n",
       "      <td>[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>f07-042a-05-05</td>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "      <td>[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>c03-016e-08-03</td>\n",
       "      <td>is</td>\n",
       "      <td>is</td>\n",
       "      <td>[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>g06-047e-02-08</td>\n",
       "      <td>had</td>\n",
       "      <td>had</td>\n",
       "      <td>[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>c04-089-00-09</td>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "      <td>[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            WordID       real predicted  \\\n",
       "0    a04-054-02-00        the       the   \n",
       "1    a06-114-00-00         If        It   \n",
       "2    f04-096-05-02         in        in   \n",
       "3    k02-093-04-01      quick     griic   \n",
       "4    d06-008-04-05      still     wooll   \n",
       "5    e04-030-01-00     inside     winde   \n",
       "6    g04-077-03-08  fortunate  fommnnee   \n",
       "7   f07-000b-01-04        was       was   \n",
       "8    d01-056-06-02      There      Thrr   \n",
       "9    n04-068-04-00        the       the   \n",
       "10   d04-037-02-02         my       voy   \n",
       "11   k02-117-06-03         as        as   \n",
       "12   g05-094-07-01         of        of   \n",
       "13   h04-055-01-01        per       por   \n",
       "14   e07-101-07-07         to        to   \n",
       "15   h06-082-01-06    devices     Sovve   \n",
       "16  f07-042a-05-05        and       and   \n",
       "17  c03-016e-08-03         is        is   \n",
       "18  g06-047e-02-08        had       had   \n",
       "19   c04-089-00-09         of        of   \n",
       "\n",
       "                                            ImageData  correct  \n",
       "0   [[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...        1  \n",
       "1   [[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...        0  \n",
       "2   [[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...        1  \n",
       "3   [[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...        0  \n",
       "4   [[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...        0  \n",
       "5   [[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...        0  \n",
       "6   [[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...        0  \n",
       "7   [[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...        1  \n",
       "8   [[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...        0  \n",
       "9   [[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...        1  \n",
       "10  [[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...        0  \n",
       "11  [[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...        1  \n",
       "12  [[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...        1  \n",
       "13  [[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...        0  \n",
       "14  [[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...        1  \n",
       "15  [[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...        0  \n",
       "16  [[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...        1  \n",
       "17  [[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...        1  \n",
       "18  [[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...        1  \n",
       "19  [[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...        1  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate a metric that considers the number of correct characters in the predicted word and add the column of the metric to the results df\n",
    "def calculate_metric(row):\n",
    "    correct_chars = 0\n",
    "    for pred_char, real_char in zip(row['predicted'], row['real']):\n",
    "        if pred_char == real_char:\n",
    "            correct_chars += 1\n",
    "    return correct_chars\n",
    "\n",
    "def count_chars(row):\n",
    "    return len(row['real'])\n",
    "\n",
    "results['char_correct'] = results.apply(calculate_metric, axis=1)\n",
    "\n",
    "# total chars\n",
    "results['total_chars'] = results.apply(count_chars, axis=1)\n",
    "\n",
    "# accuracy\n",
    "results['char_accuracy'] = results['char_correct'] / results['total_chars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WordID</th>\n",
       "      <th>real</th>\n",
       "      <th>predicted</th>\n",
       "      <th>ImageData</th>\n",
       "      <th>correct</th>\n",
       "      <th>char_correct</th>\n",
       "      <th>total_chars</th>\n",
       "      <th>char_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a04-054-02-00</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a06-114-00-00</td>\n",
       "      <td>If</td>\n",
       "      <td>It</td>\n",
       "      <td>[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f04-096-05-02</td>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "      <td>[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>k02-093-04-01</td>\n",
       "      <td>quick</td>\n",
       "      <td>griic</td>\n",
       "      <td>[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d06-008-04-05</td>\n",
       "      <td>still</td>\n",
       "      <td>wooll</td>\n",
       "      <td>[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>e04-030-01-00</td>\n",
       "      <td>inside</td>\n",
       "      <td>winde</td>\n",
       "      <td>[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>g04-077-03-08</td>\n",
       "      <td>fortunate</td>\n",
       "      <td>fommnnee</td>\n",
       "      <td>[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>f07-000b-01-04</td>\n",
       "      <td>was</td>\n",
       "      <td>was</td>\n",
       "      <td>[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>d01-056-06-02</td>\n",
       "      <td>There</td>\n",
       "      <td>Thrr</td>\n",
       "      <td>[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>n04-068-04-00</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>d04-037-02-02</td>\n",
       "      <td>my</td>\n",
       "      <td>voy</td>\n",
       "      <td>[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>k02-117-06-03</td>\n",
       "      <td>as</td>\n",
       "      <td>as</td>\n",
       "      <td>[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>g05-094-07-01</td>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "      <td>[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>h04-055-01-01</td>\n",
       "      <td>per</td>\n",
       "      <td>por</td>\n",
       "      <td>[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>e07-101-07-07</td>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "      <td>[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>h06-082-01-06</td>\n",
       "      <td>devices</td>\n",
       "      <td>Sovve</td>\n",
       "      <td>[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>f07-042a-05-05</td>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "      <td>[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>c03-016e-08-03</td>\n",
       "      <td>is</td>\n",
       "      <td>is</td>\n",
       "      <td>[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>g06-047e-02-08</td>\n",
       "      <td>had</td>\n",
       "      <td>had</td>\n",
       "      <td>[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>c04-089-00-09</td>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "      <td>[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            WordID       real predicted  \\\n",
       "0    a04-054-02-00        the       the   \n",
       "1    a06-114-00-00         If        It   \n",
       "2    f04-096-05-02         in        in   \n",
       "3    k02-093-04-01      quick     griic   \n",
       "4    d06-008-04-05      still     wooll   \n",
       "5    e04-030-01-00     inside     winde   \n",
       "6    g04-077-03-08  fortunate  fommnnee   \n",
       "7   f07-000b-01-04        was       was   \n",
       "8    d01-056-06-02      There      Thrr   \n",
       "9    n04-068-04-00        the       the   \n",
       "10   d04-037-02-02         my       voy   \n",
       "11   k02-117-06-03         as        as   \n",
       "12   g05-094-07-01         of        of   \n",
       "13   h04-055-01-01        per       por   \n",
       "14   e07-101-07-07         to        to   \n",
       "15   h06-082-01-06    devices     Sovve   \n",
       "16  f07-042a-05-05        and       and   \n",
       "17  c03-016e-08-03         is        is   \n",
       "18  g06-047e-02-08        had       had   \n",
       "19   c04-089-00-09         of        of   \n",
       "\n",
       "                                            ImageData  correct  char_correct  \\\n",
       "0   [[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...        1             3   \n",
       "1   [[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...        0             1   \n",
       "2   [[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...        1             2   \n",
       "3   [[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...        0             1   \n",
       "4   [[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...        0             2   \n",
       "5   [[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...        0             0   \n",
       "6   [[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...        0             3   \n",
       "7   [[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...        1             3   \n",
       "8   [[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...        0             3   \n",
       "9   [[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...        1             3   \n",
       "10  [[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...        0             0   \n",
       "11  [[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...        1             2   \n",
       "12  [[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...        1             2   \n",
       "13  [[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...        0             2   \n",
       "14  [[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...        1             2   \n",
       "15  [[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...        0             1   \n",
       "16  [[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...        1             3   \n",
       "17  [[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...        1             2   \n",
       "18  [[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...        1             3   \n",
       "19  [[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...        1             2   \n",
       "\n",
       "    total_chars  char_accuracy  \n",
       "0             3       1.000000  \n",
       "1             2       0.500000  \n",
       "2             2       1.000000  \n",
       "3             5       0.200000  \n",
       "4             5       0.400000  \n",
       "5             6       0.000000  \n",
       "6             9       0.333333  \n",
       "7             3       1.000000  \n",
       "8             5       0.600000  \n",
       "9             3       1.000000  \n",
       "10            2       0.000000  \n",
       "11            2       1.000000  \n",
       "12            2       1.000000  \n",
       "13            3       0.666667  \n",
       "14            2       1.000000  \n",
       "15            7       0.142857  \n",
       "16            3       1.000000  \n",
       "17            2       1.000000  \n",
       "18            3       1.000000  \n",
       "19            2       1.000000  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51.67299786647239"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(results['char_correct']) / sum(results['total_chars'])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6316014570959214\n"
     ]
    }
   ],
   "source": [
    "# average total_chars\n",
    "print(results['char_accuracy'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WordID</th>\n",
       "      <th>SegmentationResult</th>\n",
       "      <th>GrayLevel</th>\n",
       "      <th>BoundingBox</th>\n",
       "      <th>GrammaticalTag</th>\n",
       "      <th>Transcription</th>\n",
       "      <th>ImageData</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50597</th>\n",
       "      <td>p02-022-05-06</td>\n",
       "      <td>err</td>\n",
       "      <td>182</td>\n",
       "      <td>(1694, 1613, 294, 164)</td>\n",
       "      <td>VBG</td>\n",
       "      <td>knowing</td>\n",
       "      <td>[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              WordID SegmentationResult  GrayLevel             BoundingBox  \\\n",
       "50597  p02-022-05-06                err        182  (1694, 1613, 294, 164)   \n",
       "\n",
       "      GrammaticalTag Transcription  \\\n",
       "50597            VBG       knowing   \n",
       "\n",
       "                                               ImageData  \n",
       "50597  [[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['WordID'] == 'p02-022-05-06']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct\n",
      "0    0.609017\n",
      "1    0.390983\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(results['correct'].value_counts()/len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- DESCRIPTION OF THE INPUT DATA ----\n",
    "# X_train shape: (num_samples, 32, 128, 1)\n",
    "# y_train shape: (num_samples, max(len(words)),len(vocabulary))\n",
    "# example of a X_train value: matrix of 32x128 with values between 0 and 1\n",
    "# example of a y_train value: matrix of 17x63 with values between 0 and 1. first column is the padding, the rest are the one-hot encoded values of the transcription\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.layers import Reshape\n",
    "\n",
    "def create_cnn_model(input_shape, num_classes, sequence_length):\n",
    "    model = Sequential([\n",
    "        # Input CNN layer with 32 units\n",
    "        Conv2D(96, (3, 3), activation='relu', input_shape=input_shape),  # Updated the number of filters to 96\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "        # Second CNN layer with 96 units\n",
    "        Conv2D(96, (3, 3), activation='relu'),  # Updated the number of filters to 96\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        # Third CNN layer with 96 units (as per 'CNN units 2')\n",
    "        Conv2D(96, (3, 3), activation='relu'),  # Updated the number of filters to 96\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        # Flattening the 2D arrays for fully connected layers\n",
    "        Flatten(),\n",
    "\n",
    "        # First Dense layer with 192 units\n",
    "        Dense(192, activation='relu'),  # Updated number of units to 192\n",
    "        Dropout(0.1),  # Dropout with 0.1 rate\n",
    "        \n",
    "        # Output layer with sequence_length * num_classes units and softmax activation\n",
    "        Dense(sequence_length * num_classes, activation='softmax'),\n",
    "        Reshape((sequence_length, num_classes))\n",
    "\n",
    "    ])\n",
    "    \n",
    "    # Compiling the model with Adam optimizer and a learning rate of 0.001\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "create_cnn_model(input_shape=(32, 128, 1), num_classes=len(vocabulary)+1, sequence_length=y_train.shape[1]).summary()\n",
    "\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Stop training when there is no improvement in the validation loss for 3 consecutive epochs\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "# Save the best model during the training\n",
    "best_model_path = 'best_model_word.h5'  \n",
    "model_checkpoint = ModelCheckpoint(best_model_path, \n",
    "                                   monitor='val_loss', \n",
    "                                   save_best_only=True, \n",
    "                                   verbose=1)\n",
    "\n",
    "# Assume create_cnn_model is a function you've defined to create your model\n",
    "model = create_cnn_model(input_shape=(32, 128, 1), num_classes=len(vocabulary)+1, sequence_length=y_train.shape[1])\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=50,  # Set a high number because early stopping will halt the training\n",
    "    batch_size=128,\n",
    "    callbacks=[early_stopping, model_checkpoint]  # Add the model checkpoint callback here\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
